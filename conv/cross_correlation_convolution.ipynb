{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Correlation\n",
    "\n",
    "Each output unit is a linear function of localized subset of input units\n",
    "\n",
    "\n",
    "![SegmentLocal](images/no_padding_no_strides.gif \"segment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H[x,y]=\\sum_{v=-k}^{k} \\sum_{u=-k}^{k} I[x+u,y+v] F[u,v]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refs: [1](https://github.com/vdumoulin/conv_arithmetic) [2](https://theblog.github.io/post/convolution-in-autoregressive-neural-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape of the Convolution Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_{out} =\\left \\lfloor \\frac{ H_{in} +2 \\times \\text{padding[0]}-\\text{dilation[0]} \\times(\\text{kernel_size}[0]-1)-1}{stride[0]}   +1\\right \\rfloor$\n",
    "\n",
    "\n",
    "\n",
    "$W_{out} =\\left \\lfloor \\frac{ W_{in} +2\\times \\text{padding[1]}-\\text{dilation[1]} \\times(\\text{kernel_size}[1]-1)-1}{stride[1]}   +1\\right \\rfloor$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Convolution as Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write 2D Convolution as Matrix Multiplication. There are several way to do that\n",
    "\n",
    "## 1) Discrete convolution\n",
    "You should use a **doubly block circulant matrix** which is a special case of **Toeplitz matrix**.\n",
    "\n",
    "The following matrix is a Toeplitz matrix:\n",
    "\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "a & b & c & d & e \\\\\n",
    "f & a & b & c & d \\\\\n",
    "g & f & a & b & c \\\\\n",
    "h & g & f & a & b \\\\\n",
    "i & h & g & f & a \n",
    "\\end{bmatrix}$\n",
    "\n",
    "Toeplitz matrix of a $n√ón$ matrix A is:\n",
    "\n",
    "\n",
    "${\\displaystyle {\\begin{bmatrix}a_{0}&a_{-1}&a_{-2}&\\cdots &\\cdots &a_{-(n-1)}\\\\a_{1}&a_{0}&a_{-1}&\\ddots &&\\vdots \\\\a_{2}&a_{1}&\\ddots &\\ddots &\\ddots &\\vdots \\\\\\vdots &\\ddots &\\ddots &\\ddots &a_{-1}&a_{-2}\\\\\\vdots &&\\ddots &a_{1}&a_{0}&a_{-1}\\\\a_{n-1}&\\cdots &\\cdots &a_{2}&a_{1}&a_{0}\\end{bmatrix}}}$\n",
    "\n",
    "\n",
    "If the i,j element of A is denoted $A_{i,j}$, then we have\n",
    "\n",
    "${\\displaystyle A_{i,j}=A_{i+1,j+1}=a_{i-j}.\\ }$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\displaystyle y=k\\ast x={\\begin{bmatrix}k_{1}&0&\\cdots &0&0\\\\k_{2}&k_{1}&&\\vdots &\\vdots \\\\k_{3}&k_{2}&\\cdots &0&0\\\\\\vdots &k_{3}&\\cdots &k_{1}&0\\\\k_{m-1}&\\vdots &\\ddots &k_{2}&k_{1}\\\\k_{m}&k_{m-1}&&\\vdots &k_{2}\\\\0&k_{m}&\\ddots &k_{m-2}&\\vdots \\\\0&0&\\cdots &k_{m-1}&k_{m-2}\\\\\\vdots &\\vdots &&k_{m}&k_{m-1}\\\\0&0&0&\\cdots &k_{m}\\end{bmatrix}}{\\begin{bmatrix}x_{1}\\\\x_{2}\\\\x_{3}\\\\\\vdots \\\\x_{n}\\end{bmatrix}}}$\n",
    "\n",
    "Refs: [1](https://en.wikipedia.org/wiki/Toeplitz_matrix#Discrete_convolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Using im2col\n",
    "\n",
    "Suppose we have a single channel 4 x 4 image, X, and its pixel values are as follows:\n",
    "\n",
    "<img src='images/im2col_1.png'>\n",
    "\n",
    "and our weight is:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1 &2 \\\\ \n",
    " 3& 4\n",
    "\\end{bmatrix}$\n",
    "\n",
    "This means that there will be 9 2 x 2 image patches that will be element-wise multiplied with the matrix W, like so:\n",
    "<img src='images/im2col_2.png'>\n",
    "\n",
    "\n",
    "These image patches can be represented as 4-dimensional column vectors and concatenated to form a single 4 x 9 matrix, P, like so:\n",
    "\n",
    "\n",
    "<img src='images/im2col_3.png'>\n",
    "\n",
    "To perform the convolution, we first matrix multiply K with P to get a 9-dimensional row vector (1 x 9 matrix) which gives us:\n",
    "\n",
    "<img src='images/im2col_4.png'>\n",
    "\n",
    "\n",
    "Then we reshape the result of K P to the correct shape, which is a 3 x 3 x 1\n",
    "\n",
    "Refs: [1](https://medium.com/@_init_/an-illustrated-explanation-of-performing-2d-convolutions-using-matrix-multiplications-1e8de8cd2544)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Using Doubly Block Circulant Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a filter $k$ of size $ m\\times m$ and your input data $\\times$ is of size $n\\timesn$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/input.png'>  <img src='images/k.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should unroll $k$ into a sparse matrix of size $(n-m+1)^2 \\times  n^2$, and unroll x into a long vector $n^2 \\times 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/conv_mult.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/conv_result.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end you should reshape your vector. Convert the resulting vector (which will have a size $(n-m+1)^2 \\times 1)$ into a $n-m+1$ square matrix \n",
    "\n",
    "Refs: [1](https://stackoverflow.com/questions/16798888/2-d-convolution-as-a-matrix-matrix-multiplication), [2](https://dsp.stackexchange.com/questions/35373/2d-convolution-as-a-doubly-block-circulant-matrix-operating-on-a-vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution in RGB Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of channels in our image must match the number of channels in our filter, so these two numbers have to be equal. The output of this will be a $4 \\times 4 \\times 1$. We ofetn have $k$ filters of size $3\\times3\\times3$ so the output would be $k$ images of size $4 \\times 4 \\times 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/06_03.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/06_09.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/3_channel_conv.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refs: [1](http://datahacker.rs/convolution-rgb-image/), [2](https://cs231n.github.io/convolutional-networks/#conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transpose Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AKA :\n",
    "- Deconvolution (bad)\n",
    "- Upconvolution\n",
    "- Fractionally strided convolution\n",
    "- Backward strided convolution\n",
    "\n",
    "\n",
    "No padding, no strides, transposed\n",
    "<img src='images/no_padding_no_strides_transposed.gif'>\n",
    "\n",
    "\n",
    "Full padding, no strides, transposed\n",
    "\n",
    "<img src='images/full_padding_no_strides_transposed.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1x1 Convolution: Network-in-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say you have tensor $(N, C, H, W)$, ($N$ is the batch size, $CF$ is the number of channel, $\n",
    "H,W$ are the spatial dimensions). Suppose this output is fed into a conv layer with $F_1$ $1\\times1\\times C$ with zero padding and stride 1. Then the output of this $1\\times1$ conv layer will have shape $(N,1,H,W)$. We dot product every element of the filter with the tensor and apply a RelU function on the output. You can imagine this a single neuron which has $C$ input. Thats why it is called **Network-in-Network**.\n",
    "\n",
    "\n",
    "You can use a $1\\times1$ convolutional layer to reduce $n_C$ but not $n_H, n_W$.\n",
    "\n",
    "You can use a pooling layer to reduce $n_H$, $n_W$, and $n_C$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refs: [1](https://arxiv.org/abs/1312.4400), [2](https://www.youtube.com/watch?v=vcp0XvDAX68), [3](https://stats.stackexchange.com/questions/194142/what-does-1x1-convolution-mean-in-a-neural-network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilated Convolutions\n",
    "\n",
    "\n",
    "This can be very useful in some settings to use in conjunction with 0-dilated filters because it allows you to merge spatial information across the inputs much more agressively with fewer layers. For example, if you stack two 3x3 CONV layers on top of each other then you can convince yourself that the neurons on the 2nd layer are a function of a 5x5 patch of the input (we would say that the effective receptive field of these neurons is 5x5). If we use dilated convolutions then this effective receptive field would grow much quicker.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src='images/dilation.gif'>\n",
    "\n",
    "Refs: [1](https://arxiv.org/abs/1511.07122)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
