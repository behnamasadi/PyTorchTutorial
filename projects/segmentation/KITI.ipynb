{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115c872a-84f1-4900-afa0-6437c0b6c62f",
   "metadata": {},
   "source": [
    "## KITI \n",
    "KITTI has the following strcture:\n",
    "\n",
    "```bash\n",
    ".\n",
    "├── testing\n",
    "│   └── image_2\n",
    "└── training\n",
    "    ├── image_2\n",
    "    ├── instance\n",
    "    ├── semantic\n",
    "    └── semantic_rgb\n",
    "```\n",
    "\n",
    "#### **Semantic Folder**\n",
    "The \"semantic\" folder contains the semantic segmentation ground truth for the training images. Each file is a single channel `uint8` (8-bit) PNG image with each pixel value representing its semantic **label ID**, so values are in `[0-255]`.\n",
    "\n",
    "#### **Instance Folder**\n",
    "The \"instance\" folder contains the combined instance and semantic segmentation ground truth. Each file is a single channel `uint16` (16-bit) PNG image where the lower `8 bits` of each pixel value are its **instance ID**, values are in `[0-255]`, so we can get them by `instance_semantic_gt % 256`, while the higher `8 bits` of each pixel value are in `[256- 2**16-1(=65535)]` its **semantic labels ID**, so we can get them by `instance_semantic_gt // 256`. The `//`\tis the **Floor Division** operator, i.e. `257//256=1`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23729013-5a50-47b2-bed3-9f6ea1e7eb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded image: /home/behnam/workspace/PyTorchTutorial/projects/city_segmentation/data/KITI/data_semantics/training/instance/000000_10.png\n",
      "Image shape: (375, 1242)\n",
      "instance ID\n",
      " [[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 17 17 17]\n",
      " [ 0  0  0 ... 17 17 17]\n",
      " [ 0  0  0 ... 17 17 17]]\n",
      "--------------------------------------------------\n",
      "semantic labels ID\n",
      " [[21 21 21 ... 11 11 11]\n",
      " [21 21 21 ... 11 11 11]\n",
      " [21 21 21 ... 11 11 11]\n",
      " ...\n",
      " [ 7  7  7 ... 26 26 26]\n",
      " [ 7  7  7 ... 26 26 26]\n",
      " [ 7  7  7 ... 26 26 26]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from utils.devkit.helpers.labels import labels, name2label, id2label, trainId2label\n",
    "from utils.file_utils import resource_path\n",
    "\n",
    "\n",
    "image_path = resource_path(\n",
    "    'data/KITI/data_semantics/training/instance/000000_10.png')\n",
    "\n",
    "instance_semantic_gt = np.array(Image.open(image_path))\n",
    "print(f\"Successfully loaded image: {image_path}\")\n",
    "print(f\"Image shape: {instance_semantic_gt.shape}\")\n",
    "\n",
    "instance_gt = instance_semantic_gt % 256\n",
    "semantic_gt = instance_semantic_gt // 256\n",
    "\n",
    "print(\"instance ID\\n\", instance_gt)\n",
    "print(\"-\"*50)\n",
    "print(\"semantic labels ID\\n\",semantic_gt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07367833-63d6-41e0-b908-4aee342a8f6b",
   "metadata": {},
   "source": [
    "- Instance IDs start from `1` for each semantic class (ex. car:1,2,3 ... etc. - buiding:1,2,3 ... etc.). \n",
    "- Instance ID value of `0` means no instance ground truth is available and should be ignored for instance segmentation. An example code for reading the instance and semantic segmentation ground truth from the combined ground truth file in python could look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3972fb8-28e3-4d28-8a67-ba4ec351db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " unlabeled, 0\n",
      " ego vehicle, 1\n",
      " rectification border, 2\n",
      " out of roi, 3\n",
      " static, 4\n",
      " dynamic, 5\n",
      " ground, 6\n",
      " road, 7\n",
      " sidewalk, 8\n",
      " parking, 9\n",
      " rail track, 10\n",
      " building, 11\n",
      " wall, 12\n",
      " fence, 13\n",
      " guard rail, 14\n",
      " bridge, 15\n",
      " tunnel, 16\n",
      " pole, 17\n",
      " polegroup, 18\n",
      " traffic light, 19\n",
      " traffic sign, 20\n",
      " vegetation, 21\n",
      " terrain, 22\n",
      " sky, 23\n",
      " person, 24\n",
      " rider, 25\n",
      " car, 26\n",
      " truck, 27\n",
      " bus, 28\n",
      " caravan, 29\n",
      " trailer, 30\n",
      " train, 31\n",
      " motorcycle, 32\n",
      " bicycle, 33\n",
      " license plate, -1\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(\" {}, {}\".format(label.name, label.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d61aa-fe63-4c55-b900-c469921404df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The **KITTI** reuses conventions from **Cityscapes**, so see these columns:\n",
    "\n",
    "* **name** → human-readable label name (`road`, `sidewalk`, etc.)\n",
    "* **id** → the raw ID used in the original annotation masks (values stored in the ground-truth image pixels)\n",
    "* **trainId** → the **remapped label ID used during training**\n",
    "* **category** → broader grouping (e.g. `flat`, `vehicle`, `human`)\n",
    "* **categoryId** → numeric ID of that category\n",
    "* **hasInstances** → whether this class is instance-level (`car`, `person`) or not (`road`)\n",
    "* **ignoreInEval** → if this label should be ignored during evaluation\n",
    "\n",
    "---\n",
    "\n",
    "####  What is `trainId`?\n",
    "\n",
    "* The **`id`** values in the raw dataset range widely (`0,1,2,...,255`) and include labels that are not useful for training (e.g. `ego vehicle`, `rectification border`).\n",
    "* To simplify training and evaluation, KITTI (and Cityscapes) **map these raw IDs to contiguous `trainId`s**.\n",
    "\n",
    "For example in our snippet:\n",
    "\n",
    "```\n",
    "name               id   trainId   category   ignoreInEval\n",
    "---------------------------------------------------------\n",
    "unlabeled          0    255       void       1\n",
    "road               7    0         flat       0\n",
    "sidewalk           8    1         flat       0\n",
    "parking            9    255       flat       1\n",
    "```\n",
    "\n",
    "* `road` has `id = 7`, but for training we map it to `trainId = 0` → this means \"road is the first valid class\".\n",
    "* `sidewalk` has `id = 8`, mapped to `trainId = 1`.\n",
    "* `unlabeled` and `parking` are given `trainId = 255`.\n",
    "* `255` is a **special value** meaning “ignore” (so the loss function won’t count those pixels).\n",
    "\n",
    "---\n",
    "\n",
    "#### Why do we need `trainId`?\n",
    "\n",
    "1. Training neural nets is easier if labels are contiguous:\n",
    "\n",
    "   ```\n",
    "   road = 0, sidewalk = 1, building = 2, ... car = 13\n",
    "   ```\n",
    "\n",
    "   instead of having gaps like `7, 8, 26, 33...`.\n",
    "\n",
    "2. Evaluation should ignore things like **unlabeled pixels** or **ego vehicle** mask → hence `trainId = 255`.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "The part `{:>21}` is a **format specifier** that means:\n",
    "\n",
    "* `:` → start of a format specifier\n",
    "* `>` → align to the **right** within the given width\n",
    "* `21` → total **minimum field width** (21 characters wide)\n",
    "\n",
    "So:\n",
    "\n",
    "will place `\"name\"` right-aligned inside a 21-character space, padding on the **left** with spaces.\n",
    "This is basically **column formatting for a table**, ensuring everything lines up neatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db36711-b479-42ee-b748-1803cd7e1f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of cityscapes labels:\n",
      "\n",
      "                     name |  id | trainId |       category | categoryId | hasInstances | ignoreInEval\n",
      "    --------------------------------------------------------------------------------------------------\n",
      "                unlabeled |   0 |     255 |           void |          0 |            0 |            1\n",
      "              ego vehicle |   1 |     255 |           void |          0 |            0 |            1\n",
      "     rectification border |   2 |     255 |           void |          0 |            0 |            1\n",
      "               out of roi |   3 |     255 |           void |          0 |            0 |            1\n",
      "                   static |   4 |     255 |           void |          0 |            0 |            1\n",
      "                  dynamic |   5 |     255 |           void |          0 |            0 |            1\n",
      "                   ground |   6 |     255 |           void |          0 |            0 |            1\n",
      "                     road |   7 |       0 |           flat |          1 |            0 |            0\n",
      "                 sidewalk |   8 |       1 |           flat |          1 |            0 |            0\n",
      "                  parking |   9 |     255 |           flat |          1 |            0 |            1\n",
      "               rail track |  10 |     255 |           flat |          1 |            0 |            1\n",
      "                 building |  11 |       2 |   construction |          2 |            0 |            0\n",
      "                     wall |  12 |       3 |   construction |          2 |            0 |            0\n",
      "                    fence |  13 |       4 |   construction |          2 |            0 |            0\n",
      "               guard rail |  14 |     255 |   construction |          2 |            0 |            1\n",
      "                   bridge |  15 |     255 |   construction |          2 |            0 |            1\n",
      "                   tunnel |  16 |     255 |   construction |          2 |            0 |            1\n",
      "                     pole |  17 |       5 |         object |          3 |            0 |            0\n",
      "                polegroup |  18 |     255 |         object |          3 |            0 |            1\n",
      "            traffic light |  19 |       6 |         object |          3 |            0 |            0\n",
      "             traffic sign |  20 |       7 |         object |          3 |            0 |            0\n",
      "               vegetation |  21 |       8 |         nature |          4 |            0 |            0\n",
      "                  terrain |  22 |       9 |         nature |          4 |            0 |            0\n",
      "                      sky |  23 |      10 |            sky |          5 |            0 |            0\n",
      "                   person |  24 |      11 |          human |          6 |            1 |            0\n",
      "                    rider |  25 |      12 |          human |          6 |            1 |            0\n",
      "                      car |  26 |      13 |        vehicle |          7 |            1 |            0\n",
      "                    truck |  27 |      14 |        vehicle |          7 |            1 |            0\n",
      "                      bus |  28 |      15 |        vehicle |          7 |            1 |            0\n",
      "                  caravan |  29 |     255 |        vehicle |          7 |            1 |            1\n",
      "                  trailer |  30 |     255 |        vehicle |          7 |            1 |            1\n",
      "                    train |  31 |      16 |        vehicle |          7 |            1 |            0\n",
      "               motorcycle |  32 |      17 |        vehicle |          7 |            1 |            0\n",
      "                  bicycle |  33 |      18 |        vehicle |          7 |            1 |            0\n",
      "            license plate |  -1 |      -1 |        vehicle |          7 |            0 |            1\n"
     ]
    }
   ],
   "source": [
    "# Print all the labels\n",
    "print(\"List of cityscapes labels:\")\n",
    "print(\"\")\n",
    "print(\"    {:>21} | {:>3} | {:>7} | {:>14} | {:>10} | {:>12} | {:>12}\".format(\n",
    "    'name', 'id', 'trainId', 'category', 'categoryId', 'hasInstances', 'ignoreInEval'))\n",
    "print(\"    \" + ('-' * 98))\n",
    "for label in labels:\n",
    "    print(\"    {:>21} | {:>3} | {:>7} | {:>14} | {:>10} | {:>12} | {:>12}\".format(\n",
    "        label.name, label.id, label.trainId, label.category, label.categoryId, label.hasInstances, label.ignoreInEval))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f353d415-412c-47f9-a7fd-e763e6d960d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example usages:\n",
      "ID of label 'car': 26\n",
      "Category of label with ID '26': vehicle\n",
      "Name of label with trainID '0': road\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "\n",
    "print(\"Example usages:\")\n",
    "\n",
    "# Map from name to label\n",
    "name = 'car'\n",
    "id = name2label[name].id\n",
    "print(\"ID of label '{name}': {id}\".format(name=name, id=id))\n",
    "\n",
    "# Map from ID to label\n",
    "category = id2label[id].category\n",
    "print(\"Category of label with ID '{id}': {category}\".format(\n",
    "    id=id, category=category))\n",
    "\n",
    "# Map from trainID to label\n",
    "trainId = 0\n",
    "name = trainId2label[trainId].name\n",
    "print(\"Name of label with trainID '{id}': {name}\".format(\n",
    "    id=trainId, name=name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fad47a0-837f-4810-8a47-dea644568568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: torch.Size([1, 375, 1242])\n",
      "image padded: torch.Size([1, 384, 1248])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pylab as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def kitti_pad_transform(image: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Pad KITTI images (375x1242) to the next multiple of 32 (384x1248).\n",
    "    Works for both single images [C, H, W] and batches [N, C, H, W].\n",
    "\n",
    "    Input: h=375, w=1242\n",
    "\n",
    "    Target: h=384, w=1248\n",
    "\n",
    "    Padding: bottom=9, right=6\n",
    "\n",
    "    Output shape: 384×1248 ✅ divisible by 32\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # -2: slices the last two dimensions of the shape tuple.\n",
    "\n",
    "    # Regardless of batch, the last two dimensions are always (H, W).\n",
    "    # # Single image\n",
    "    # image = torch.randn(3, 375, 1242)\n",
    "    # print(image.shape[-2:])   # (375, 1242)\n",
    "\n",
    "    # # Batch of images\n",
    "    # batch = torch.randn(4, 3, 375, 1242)\n",
    "    # print(batch.shape[-2:])   # (375, 1242)\n",
    "\n",
    "    h, w = image.shape[-2:]  # Expect [C, H, W] or [H, W]\n",
    "\n",
    "    # Compute target dims (next multiple of 32)\n",
    "    target_h = ((h + 31) // 32) * 32  # ceil to multiple of 32\n",
    "    target_w = ((w + 31) // 32) * 32\n",
    "\n",
    "    pad_h = target_h - h\n",
    "    pad_w = target_w - w\n",
    "\n",
    "    # Order = (left, right, top, bottom)\n",
    "    image = F.pad(image, (0, pad_w, 0, pad_h), mode='reflect')\n",
    "    return image\n",
    "\n",
    "\n",
    "pil_image = Image.open(image_path)\n",
    "transform = transforms.ToTensor()\n",
    "image = transform(pil_image)\n",
    "image_padded = kitti_pad_transform(image)\n",
    "print(\"image:\",image.shape)\n",
    "print(\"image padded:\",image_padded.shape)\n",
    "\n",
    "inv_transform = transforms.ToPILImage()\n",
    "plt.imshow(inv_transform(image_padded))\n",
    "# plt.imshow(pil_image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4253cefa-7ff7-451b-abd9-54ff983f3d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_id_to_trainid_lut(ignore_index: int = 255) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build a lookup table (LUT) to map raw 'id' values from KITTI/Cityscapes label images\n",
    "    into the compact 'trainId' values used for training.\n",
    "\n",
    "    Args:\n",
    "        ignore_index: the value to assign when no valid mapping exists.\n",
    "                      By convention in KITTI/Cityscapes, this is 255 (ignored in loss/eval).\n",
    "\n",
    "    Returns:\n",
    "        lut: a NumPy array of shape (256,), dtype=uint8,\n",
    "             where lut[id] == trainId for all possible id values in [0,255].\n",
    "             This lets us remap an entire mask with one vectorized call:\n",
    "             train_mask = lut[id_mask]\n",
    "    \"\"\"\n",
    "    # 1. Initialize LUT with all entries = ignore_index (default: 255).\n",
    "    #    So if an 'id' is not listed in the label definitions,\n",
    "    #    it will automatically map to ignore (safe default).\n",
    "    lut = np.full(256, ignore_index, dtype=np.uint8)\n",
    "\n",
    "    # 2. Fill in known mappings using the devkit label definitions.\n",
    "    #    Each label has fields: name, id, trainId, category, ...\n",
    "    for lab in LABELS:\n",
    "        if 0 <= lab.id <= 255:     # only valid IDs\n",
    "            lut[lab.id] = lab.trainId\n",
    "\n",
    "    # 3. Return LUT: direct array index gives you the trainId.\n",
    "    return lut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d3d83b-9a27-47e3-b2bc-210aa50e94b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "* **KITTI labels** (like Cityscapes) have:\n",
    "\n",
    "  * `id` → the raw value stored in label PNGs (e.g. `26` for car, `7` for road).\n",
    "  * `trainId` → the compact label used for training (0..18 for valid classes, 255 = ignore).\n",
    "\n",
    "* When you load a label PNG with `PIL`/`numpy`, you get a 2D array of **ids**.\n",
    "  You need to **map every pixel’s id → trainId** before feeding it to a network.\n",
    "\n",
    "* A **lookup table (LUT)** makes this mapping very fast.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e8c630-85f9-4ea8-83d1-de7be405cf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainId for car (id=26): 13\n"
     ]
    }
   ],
   "source": [
    "from utils.devkit.helpers.labels import labels as LABELS\n",
    "\n",
    "lut = _build_id_to_trainid_lut()\n",
    "\n",
    "# Suppose a mask pixel has raw id=26 (car).\n",
    "print(\"trainId for car (id=26):\", lut[26])  # e.g., 13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe901659-1f8e-4e4d-bcfd-8efdc9f5c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def _pad_to_multiple(img_t: torch.Tensor, mask_t: torch.Tensor, multiple: int = 32, ignore_index: int = 255) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Pad image (reflect) and mask (constant=ignore_index) to next multiple of `multiple`.\"\"\"\n",
    "    h, w = img_t.shape[-2:]\n",
    "    th = ((h + multiple - 1) // multiple) * multiple\n",
    "    tw = ((w + multiple - 1) // multiple) * multiple\n",
    "    ph, pw = th - h, tw - w\n",
    "    if ph == 0 and pw == 0:\n",
    "        return img_t, mask_t\n",
    "    # pad = (left, right, top, bottom) — push to right/bottom\n",
    "    img_t = F.pad(img_t,  (0, pw, 0, ph), mode=\"reflect\")\n",
    "    mask_t = F.pad(mask_t, (0, pw, 0, ph), mode=\"constant\", value=ignore_index)\n",
    "    return img_t, mask_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37309907-7989-494d-8066-0d55c204bca5",
   "metadata": {},
   "source": [
    "* In **semantic segmentation**, the **mask** (or label map) is a 2D tensor `[H, W]` where each pixel contains the **class label**.\n",
    "* Example:\n",
    "\n",
    "  * pixel = `0` → road\n",
    "  * pixel = `1` → sidewalk\n",
    "  * pixel = `13` → car\n",
    "  * pixel = `255` → ignore (void, unlabeled, ego-vehicle, etc.)\n",
    "\n",
    "So  `mask_t` is the **label for every pixel**.\n",
    "\n",
    "---\n",
    "\n",
    "####  Why pad image and mask together?\n",
    "\n",
    "* When we pad an image to a larger size, we must **pad the mask identically** so that:\n",
    "\n",
    "  * the pixel `(i, j)` in the image corresponds to the same `(i, j)` in the mask.\n",
    "  * otherwise your training labels wouldn’t align with the image data.\n",
    "\n",
    "So `_pad_to_multiple` takes **both image & mask** and applies the **same spatial padding**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why different padding modes?\n",
    "\n",
    "* **Image (RGB): `reflect` padding**\n",
    "\n",
    "  * Images are continuous signals.\n",
    "  * If we just padded with black (0), the network would see artificial dark borders not present in real data.\n",
    "  * Reflection padding \"mirrors\" the border pixels, which preserves local texture and avoids artifacts.\n",
    "\n",
    "* **Mask (labels): `constant` padding with `ignore_index = 255`**\n",
    "\n",
    "  * Masks are **categorical**, not continuous.\n",
    "  * Reflection would *duplicate class labels* at the boundary → wrong labels!\n",
    "    Example: if the last pixel was \"car\", reflection would create a fake car label outside the image.\n",
    "  * Instead, we want the model to **ignore padded areas during training**.\n",
    "  * That’s why we fill with `255` (the ignore index), so those pixels are excluded from the loss/eval.\n",
    "\n",
    "---\n",
    "\n",
    "#### Visual analogy\n",
    "\n",
    "* **Image padding (reflect):**\n",
    "\n",
    "```\n",
    "... | road road road [road]\n",
    "... | road road road [road]\n",
    "```\n",
    "\n",
    "or in the pixels:\n",
    "\n",
    "```\n",
    "original image edge: [  120 | 123 ]\n",
    "reflection padding:  [ 123 | 120 | 123 | 120 ... ]\n",
    "\n",
    "```\n",
    "\n",
    "→ Edges extend smoothly.\n",
    "\n",
    "* **Mask padding (constant=255):**\n",
    "\n",
    "```\n",
    "... | road road road [IGNORE]\n",
    "... | road road road [IGNORE]\n",
    "```\n",
    "\n",
    "→ Padded region has no ground truth, so the model isn’t penalized for it.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28360251-389d-4fbf-bea3-a9d6c1493511",
   "metadata": {},
   "source": [
    "#### `ignore_index=255` in Loss Functions\n",
    "\n",
    "**Setup: model output vs. ground truth mask**\n",
    "\n",
    "In **semantic segmentation**, your model outputs logits of shape:\n",
    "\n",
    "```\n",
    "[batch_size, num_classes, H, W]\n",
    "```\n",
    "\n",
    "Example: `[4, 19, 384, 1248]` for KITTI with 19 classes.\n",
    "\n",
    "Your **ground truth mask** is:\n",
    "\n",
    "```\n",
    "[batch_size, H, W]\n",
    "```\n",
    "\n",
    "Each pixel contains the **trainId** (`0..18` for valid classes, `255` for ignore).\n",
    "\n",
    "---\n",
    "\n",
    "**CrossEntropyLoss with ignore\\_index**\n",
    "\n",
    "PyTorch’s `nn.CrossEntropyLoss` compares each pixel’s prediction to its ground truth label.\n",
    "But if that label == `ignore_index`, it skips that pixel completely.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "```python\n",
    "# Suppose we have 1 image, 3 classes (road=0, car=1, person=2)\n",
    "logits = torch.randn(1, 3, 2, 2, requires_grad=True)  # [N,C,H,W]\n",
    "\n",
    "# Ground truth mask with one \"ignore\" pixel\n",
    "target = torch.tensor([\n",
    "    [ [0, 1],\n",
    "      [2, 255] ]  # bottom-right = ignore\n",
    "])  # [N,H,W]\n",
    "```\n",
    "\n",
    "Loss:\n",
    "\n",
    "```python\n",
    "loss = criterion(logits, target)\n",
    "print(\"Loss:\", loss.item())\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "* Top-left pixel → compared against class `0` (road).\n",
    "* Top-right pixel → compared against class `1` (car).\n",
    "* Bottom-left pixel → compared against class `2` (person).\n",
    "* Bottom-right pixel → `255` → **ignored** in loss computation.\n",
    "\n",
    "So the loss is averaged over **3 pixels only**, not 4.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb81fb-e78d-4e3c-a8b1-ea0f3261dbf3",
   "metadata": {},
   "source": [
    "### Recommended Datasets for Segmentation with U-Net  \n",
    "\n",
    "\n",
    "| Dataset | Description | # Images (Train/Val/Test) | Classes | Best For | Download Link |\n",
    "|---------|-------------|---------------------------|---------|----------|---------------|\n",
    "| **Cityscapes** | High-quality urban street scenes (pixel-precise annotations). **Top recommendation** for your driving-themed U-Net. | 2,975 / 500 / 1,525 | 19 (e.g., road, car, person) | Autonomous driving segmentation | [Cityscapes Dataset](https://www.cityscapes-dataset.com/) |\n",
    "| **Oxford-IIIT Pet** | Close-up pet images with fine-grained masks. Used in official Keras/TensorFlow U-Net tutorials. | ~3,680 / 368 / 3,669 | 37 breeds (binary: pet vs. background) | Beginner-friendly, precise boundaries | [TFDS or Official](https://www.robots.ox.ac.uk/~vgg/data/pets/) |\n",
    "| **Pascal VOC 2012** | Everyday objects in natural scenes. Classic for segmentation benchmarks. | 1,464 / 1,449 / - | 20 (e.g., person, car, chair) | General object segmentation | [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/) |\n",
    "| **COCO (2017)** | Large-scale everyday scenes with instance masks (convert to semantic). | 118K / 5K / 40K | 80 (e.g., person, traffic light) | Diverse, large-scale training | [COCO Dataset](https://cocodataset.org/) |\n",
    "| **ADE20K** | Indoor/outdoor scenes with detailed parts (e.g., wall, floor). | 20K / 2K / 3K | 150 | Scene parsing | [ADE20K](https://groups.csail.mit.edu/vision/datasets/ADE20K/) |\n",
    "\n",
    "\n",
    "#### Encoder: Use It or Replace?\n",
    "- **Use Your Custom Encoder**: **Yes, keep it!** It's a faithful implementation of the original U-Net contracting path (simple, lightweight, ~31M params with base=64). Great for from-scratch training on smaller datasets like Oxford Pets or KITTI subsets—no need for pretraining. It captures multi-scale features well for segmentation.\n",
    "- **When to Replace**:\n",
    "  - **For Better Performance**: Swap with a **pretrained backbone** (e.g., ResNet-34 or EfficientNet-B0) as the encoder. This adds transfer learning (ImageNet weights), boosting accuracy on limited data (e.g., KITTI's small annotations). U-Net variants like U-Net++ or DeepLab use this.\n",
    "    - **How to Replace** (simple mod to your code):\n",
    "      ```python\n",
    "      import torchvision.models as models\n",
    "      \n",
    "      class UNetWithBackbone(nn.Module):\n",
    "          def __init__(self, base=64, num_classes=19):  # e.g., Cityscapes classes\n",
    "              super().__init__()\n",
    "              # Pretrained encoder (extract features before final layers)\n",
    "              self.encoder = models.resnet34(pretrained=True)\n",
    "              self.encoder = nn.Sequential(*list(self.encoder.children())[:-2])  # Remove FC layers\n",
    "              \n",
    "              # Custom decoder (as before, but adjust in_channels to match ResNet outputs)\n",
    "              # E.g., ResNet outputs: 64, 64, 128, 256, 512 → map to your skips\n",
    "              self.D4upsample = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)  # Adjust dims\n",
    "              # ... rest of decoder\n",
    "          \n",
    "          def forward(self, x):\n",
    "              # Extract skips from encoder\n",
    "              x1 = self.encoder.relu(self.encoder.bn1(self.encoder.conv1(x)))  # 64ch\n",
    "              x2 = self.encoder.layer1(x1)  # 64ch\n",
    "              x3 = self.encoder.layer2(x2)  # 128ch\n",
    "              x4 = self.encoder.layer3(x3)  # 256ch\n",
    "              bottleneck = self.encoder.layer4(x4)  # 512ch\n",
    "              \n",
    "              # Decoder with skips (as before)\n",
    "              # ...\n",
    "      ```\n",
    "    - **Benefits**: +5-10% mIoU on benchmarks; faster convergence. Use for Cityscapes/KITTI.\n",
    "  - **Alternatives**: \n",
    "    - **No Change**: If dataset is small/simple (e.g., Oxford Pets), your encoder is perfect.\n",
    "    - **Advanced**: Segment Anything Model (SAM) adapter for zero-shot, but overkill for full training.\n",
    "- **Training Tip**: Use Dice + CrossEntropy loss for segmentation; augment with flips/rotations. Start with base=32 for faster prototyping.\n",
    "\n",
    "This setup should get you training quickly—let me know if you need data loader code! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa399d06-918a-40bb-bdf7-db08ef814bb9",
   "metadata": {},
   "source": [
    "Refs [1](https://www.cvlibs.net/datasets/kitti/eval_semseg.php?benchmark=semantics2015)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4bc9b8-c0c7-4fd9-b2c1-e975462bfa61",
   "metadata": {},
   "source": [
    "## City Scapes\n",
    "\n",
    "Refs: [1](https://github.com/mcordts/cityscapesScripts), [2](https://github.com/mcordts/cityscapesScripts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd67d15-f259-4513-9f9f-bed3d3b2a873",
   "metadata": {},
   "source": [
    "## Segmentation Models \n",
    "\n",
    "Refs: [1](https://github.com/qubvel-org/segmentation_models.pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267326a-8545-440a-8183-8a6d74511157",
   "metadata": {},
   "source": [
    "## Medical\n",
    "For medical tasks, use **ISIC 2018** (skin lesions) or **Lung Nodule** datasets, as U-Net originated in biomedical imaging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a27fcf-83cc-4bb8-96c1-c08c2490d986",
   "metadata": {},
   "source": [
    "## RF-DETR: SOTA Real-Time Detection and Segmentation Model\n",
    "Refs: [1](https://github.com/roboflow/rf-detr?tab=readme-ov-file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
