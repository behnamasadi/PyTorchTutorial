import torchvision.transforms.functional as TF
from torch.utils.data import Dataset
from typing import Callable, Optional, Tuple, List
from pathlib import Path
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F
import numpy as np
from PIL import Image
from utils.devkit.helpers.labels import labels, name2label, id2label, trainId2label
from utils.file_utils import resource_path
import torch
import torchvision.transforms as transforms
import matplotlib.pylab as plt
import pathlib
import os
import torch.nn as nn
# import torch.nn.modules
# import torch.utils.data.dataset

# Use the devkit's label list (NOT the module)
from utils.devkit.helpers.labels import labels as DEVKIT_LABELS


image_path = resource_path(
    'data/KITI/data_semantics/training/instance/000000_10.png')

instance_semantic_gt = np.array(Image.open(image_path))
print(f"Successfully loaded image: {image_path}")
print(f"Image shape: {instance_semantic_gt.shape}")

instance_gt = instance_semantic_gt % 256
semantic_gt = instance_semantic_gt // 256

print(instance_gt)
print(semantic_gt)

################################################


def build_id_to_trainid_lut(ignore_index: int = 255) -> np.ndarray:
    """Fast vectorized id->trainId mapping LUT based on devkit labels."""
    lut = np.full(256, ignore_index, dtype=np.uint8)
    for lab in DEVKIT_LABELS:
        if 0 <= lab.id <= 255:
            lut[lab.id] = lab.trainId
    return lut


def pad_to_multiple(
    img_t: torch.Tensor,
    mask_t: torch.Tensor,
    multiple: int = 32,
    ignore_index: int = 255,
) -> Tuple[torch.Tensor, torch.Tensor]:
    """Pad image (reflect) & mask (constant=ignore) to next multiple of `multiple`."""
    h, w = img_t.shape[-2:]
    th = ((h + multiple - 1) // multiple) * multiple
    tw = ((w + multiple - 1) // multiple) * multiple
    ph, pw = th - h, tw - w
    if ph == 0 and pw == 0:
        return img_t, mask_t
    # pad=(left, right, top, bottom) -> push to right/bottom
    img_t = F.pad(img_t,  (0, pw, 0, ph), mode="reflect")
    mask_t = F.pad(mask_t, (0, pw, 0, ph), mode="constant", value=ignore_index)
    return img_t, mask_t


class KittiSemanticDataset(Dataset):
    """
    Arguments:
      root: dataset root
      image_dir: relative dir with RGB PNGs
      label_dir: relative dir with label PNGs (values are raw ids)
      transform: image-only transform (e.g., normalization)
      pad_to: if not None (e.g., 32), pads image/mask to next multiple
      ignore_index: fill value for padded/invalid mask pixels (255)
    """

    def __init__(
        self,
        root: str,
        image_dir: str = "images",
        label_dir: str = "labels",
        transform: Optional[Callable] = None,
        pad_to: Optional[int] = 32,
        ignore_index: int = 255,
    ):
        self.root = Path(root)
        self.img_root = self.root.joinpath(image_dir)
        self.lbl_root = self.root.joinpath(label_dir)

        self.transform = transform
        self.pad_to = pad_to
        self.ignore_index = ignore_index

        # Pair PNGs by stem
        self.samples: List[Tuple[Path, Path]] = []
        for img_path in sorted(self.img_root.rglob("*.png")):
            rel = img_path.relative_to(self.img_root)
            lbl_path = self.lbl_root.joinpath(rel)
            if lbl_path.exists():
                self.samples.append((img_path, lbl_path))
        if not self.samples:
            raise RuntimeError(
                f"No PNG pairs under {self.img_root} and {self.lbl_root}")

        # Build id->trainId LUT once
        self.id2train = build_id_to_trainid_lut(ignore_index=self.ignore_index)

    def __len__(self) -> int:
        return len(self.samples)

    def __getitem__(self, idx: int):

        img_path, lbl_path = self.samples[idx]

        # --- Image
        img = Image.open(img_path).convert("RGB")
        if self.transform:
            img_t = self.transform(img)     # user handles ToTensor + Normalize
        else:
            img_t = TF.to_tensor(img)       # just ToTensor

        # --- Mask (raw IDs -> trainIds)
        lbl = Image.open(lbl_path).convert("L")
        lbl_np = np.array(lbl, dtype=np.uint8)
        lbl_train = self.id2train[lbl_np]
        mask_t = torch.from_numpy(lbl_train).long()  # [H,W]

        padded_img_t, padded_mask_t = pad_to_multiple(
            img_t, mask_t, self.pad_to, self.ignore_index)

        return padded_img_t, padded_mask_t


################################################


if __name__ == "__main__":

    project_root = resource_path("")
    project_root = Path(project_root)

    data_path: str = "data/KITI/data_semantics/training"

    root = project_root.joinpath(data_path)

    image_dir: str = "image_2"
    label_dir: str = "semantic"

    img_root = root.joinpath(image_dir)
    lbl_root = root.joinpath(label_dir)

    pad_to = 32
    ignore_index: int = 255

    # Typical image transform
    img_tf = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.485, 0.456, 0.406),
                             std=(0.229, 0.224, 0.225)),
    ])

    dataset = KittiSemanticDataset(
        root, image_dir, label_dir, transform=img_tf, pad_to=pad_to, ignore_index=ignore_index)

    print(len(dataset))

    img, mask = dataset[0]
    print(img.shape)   # torch.Size([3,H,W]), float32
    print(mask.shape)  # torch.Size([H,W]), long with trainIds
    print(torch.unique(mask))  # unique class IDs, 0..18 or 255 (ignore)

    exit()

    # Print all the labels
    print("List of cityscapes labels:")
    print("")
    print("    {:>21} | {:>3} | {:>7} | {:>14} | {:>10} | {:>12} | {:>12}".format(
        'name', 'id', 'trainId', 'category', 'categoryId', 'hasInstances', 'ignoreInEval'))
    print("    " + ('-' * 98))
    for label in labels:
        print("    {:>21} | {:>3} | {:>7} | {:>14} | {:>10} | {:>12} | {:>12}".format(
            label.name, label.id, label.trainId, label.category, label.categoryId, label.hasInstances, label.ignoreInEval))
        # print(" \"{:}\"".format(label.name))
    print("")

    print("Example usages:")

    # Map from name to label
    name = 'car'
    id = name2label[name].id
    print("ID of label '{name}': {id}".format(name=name, id=id))

    # Map from ID to label
    category = id2label[id].category
    print("Category of label with ID '{id}': {category}".format(
        id=id, category=category))

    # Map from trainID to label
    trainId = 0
    name = trainId2label[trainId].name
    print("Name of label with trainID '{id}': {name}".format(
        id=trainId, name=name))

    pil_image = Image.open(image_path)
    transform = transforms.ToTensor()
    image = transform(pil_image)
    image_padded, _ = pad_to_multiple(img_t=image, mask_t=image)
    print(image.shape)
    print(image_padded.shape)

    inv_transform = transforms.ToPILImage()
    plt.imshow(inv_transform(image_padded))
    # plt.imshow(pil_image)
    plt.show()
