# =========================
#  GLOBAL SETTINGS
# =========================

seed: 42

# Set to true to train all models from model.yaml sequentially
# Set to false (or omit) to train only the model specified in the "model" field below
train_all_models: true

performance:
  mixed_precision: true
  channels_last: true
  compile_model: false
  benchmark_cudnn: true
  gradient_accumulation: 4  # Accumulate gradients to maintain effective batch size
  max_grad_norm: 1.0

optimizer:
  name: "AdamW"
  weight_decay: 0.01

loss:
  name: "CrossEntropyLoss"
  label_smoothing: 0.1  # Helps prevent overfitting, especially for medical datasets

training:
  stage1:
    enabled: true
    freeze_backbone: true
    epochs: 5
    learning_rate: 1e-4

  stage2:
    enabled: true
    freeze_backbone: false
    epochs: 15  # Reduced to prevent overfitting - model peaks around epoch 7-13
    learning_rate: 3e-5  # Base LR (used for head if head_lr not specified)
    head_lr: 3e-5  # Head learning rate
    backbone_lr: 5e-6  # Backbone LR (6x smaller to preserve pretrained features)
    early_stop_patience: 5  # Stop if no improvement in val loss for 5 epochs
    lr_schedule: "cosine"
    lr_schedule_params:
      T_max: 15
      eta_min: 1e-7

  total_epochs: 20  # Stage1 (5) + Stage2 (15) = 20 total
  save_every: 5
  output_dir: "./checkpoints"

# =========================
#  MONITORING & LOGGING
# =========================

monitoring:
  tensorboard_log_dir: "./runs"
  wandb:
    project: "lung-disease-classification"  # Your W&B project name
    entity: null  # Leave null to use your default entity, or set to your team name
    name: null  # Leave null for auto-generated name, or set a custom run name
    tags: []  # Optional tags like ["runpod", "efficientnetv2", "medical"]
    notes: ""  # Optional notes about this run

# =========================
#  MODEL-SPECIFIC BATCH SIZES
# =========================

model_config:
  convnextv2_tiny:
    batch_size: 64
  convnextv2_small:
    batch_size: 48
  convnextv2_base:
    batch_size: 32
  convnext_tiny:
    batch_size: 64
  convnext_small:
    batch_size: 48
  convnext_base:
    batch_size: 32
  tf_efficientnetv2_s:
    batch_size: 32
  tf_efficientnetv2_m:
    batch_size: 16  # Works well for 320x320 on RTX 5090 (32GB VRAM)
  tf_efficientnetv2_l:
    batch_size: 8
  vit_small_patch16_224:
    batch_size: 64
  vit_base_patch16_224:
    batch_size: 32
  vit_large_patch16_224:
    batch_size: 16

# Select your model here
model: tf_efficientnetv2_m

# =========================
#  DATA
# =========================

data:
  path: "./data/train"
  val_path: "./data/val"
  # batch_size will be automatically resolved from model_config section above
  # based on the selected model
  img_size: 320  # Match model's input_size (tf_efficientnetv2_m expects 320x320)
  num_workers: 12
  prefetch_factor: 4
  persistent_workers: true
  shuffle: true
  pin_memory: true
  drop_last: true
  augmentation:
    enabled: true
    horizontal_flip: true
    rotation: 10
    color_jitter: 0.2  # Increased from 0.1 for better regularization
