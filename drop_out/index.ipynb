{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cea0dc5-57ec-46fc-aacc-35ec425ea75e",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "The **Dropout** layer is a regularization technique used in deep learning to prevent **overfitting**. Here's a detailed explanation, including how `model.train()` and `model.eval()` affect it in frameworks like PyTorch, and how the dropout probability comes into play:\n",
    "\n",
    "---\n",
    "\n",
    "###  What is Dropout?\n",
    "\n",
    "Dropout works by **randomly setting some of the activations (outputs) of a layer to zero** during training. This forces the network to **not rely on specific neurons** and instead encourages it to **learn more robust features**.\n",
    "\n",
    "Think of it as temporarily \"muting\" some neurons during each training iteration.\n",
    "\n",
    "---\n",
    "\n",
    "###  Dropout Probability\n",
    "\n",
    "- The dropout layer takes a **probability `p`**, which is the **probability of dropping a neuron**.\n",
    "  - For example, `p=0.5` means each neuron's output has a 50% chance of being set to zero during training.\n",
    "\n",
    "- The remaining active neurons' outputs are **scaled by `1/(1-p)`** to maintain the expected value across training and inference.\n",
    "\n",
    "---\n",
    "\n",
    "###  How Does It Work Internally?\n",
    "\n",
    "During training:\n",
    "```python\n",
    "dropout_output = x * mask / (1 - p)\n",
    "```\n",
    "Where:\n",
    "- `x` is the input tensor.\n",
    "- `mask` is a random tensor of 0s and 1s with the same shape as `x`, with each element 1 with probability `(1 - p)` and 0 with probability `p`.\n",
    "- The division by `(1 - p)` ensures that the expected value stays the same.\n",
    "\n",
    "---\n",
    "\n",
    "###  What `model.train()` and `model.eval()` Do\n",
    "\n",
    "In PyTorch:\n",
    "\n",
    "- `model.train()`:\n",
    "  - Activates dropout.\n",
    "  - Each forward pass uses a **new random dropout mask**.\n",
    "  - Only used during training.\n",
    "\n",
    "- `model.eval()`:\n",
    "  - **Deactivates dropout**.\n",
    "  - Neurons are **not dropped**, and the full network is used.\n",
    "  - Outputs are not scaled, because they were already scaled during training.\n",
    "\n",
    "This switch is important because during evaluation/inference, you want **deterministic and full-capacity predictions**, not random noise from dropout.\n",
    "\n",
    "---\n",
    "```\n",
    "Linear ‚Üí Activation ‚Üí Dropout\n",
    "```\n",
    "\n",
    "```python\n",
    "x = F.relu(self.fc1(x))\n",
    "x = self.dropout(x)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Example in PyTorch\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "output_train = model(torch.randn(1, 100))  # Dropout is active\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "output_eval = model(torch.randn(1, 100))  # Dropout is inactive\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Summary Table\n",
    "\n",
    "| Mode         | Dropout Active? | Randomness | Output Scaling |\n",
    "|--------------|------------------|------------|----------------|\n",
    "| `model.train()` | ‚úÖ Yes            | ‚úÖ Yes      | ‚úÖ Scaled up    |\n",
    "| `model.eval()`  | ‚ùå No             | ‚ùå No       | ‚ùå Not needed   |\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you want a visualization or example with numpy or PyTorch!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
