{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0051f91b-9532-4f6c-a337-dfc8739b75f1",
   "metadata": {},
   "source": [
    "## Gradio\n",
    "\n",
    "\n",
    "Gradio is a **Python library** that makes it super easy to build **interactive web UIs for ML/DL models (or any Python function)**.\n",
    "\n",
    "Instead of hand-coding HTML/JS or a FastAPI frontend, you just define inputs/outputs and Gradio auto-generates a web interface.\n",
    "\n",
    "---\n",
    "\n",
    "##  How Gradio Works (step by step)\n",
    "\n",
    "### 1. You write a Python function\n",
    "\n",
    "This could be an ML model inference, an image transformation, or just a calculator.\n",
    "\n",
    "```python\n",
    "def add_numbers(x, y):\n",
    "    return x + y\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. You wrap it in a `gr.Interface`\n",
    "\n",
    "Here, you tell Gradio:\n",
    "\n",
    "* what **inputs** (textbox, slider, image upload, etc.)\n",
    "* what **outputs** (textbox, image, dataframe, etc.)\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=add_numbers,\n",
    "    inputs=[\"number\", \"number\"],   # two numeric inputs\n",
    "    outputs=\"number\"               # one numeric output\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. You launch it\n",
    "\n",
    "```python\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "* This starts a small **FastAPI/Starlette server** behind the scenes.\n",
    "* Gradio auto-generates an HTML/JS UI and serves it on `http://127.0.0.1:7860`.\n",
    "* You can interact with your function through the browser.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Optional: Share it\n",
    "\n",
    "* With `demo.launch(share=True)`, Gradio tunnels your local server via [gradio.live](https://gradio.live) → gives you a public temporary link.\n",
    "* Useful for demos without deploying.\n",
    "\n",
    "---\n",
    "\n",
    "##  Under the Hood\n",
    "\n",
    "* **Backend:** Gradio runs on **FastAPI** / **Starlette** as the server.\n",
    "* **Frontend:** Gradio generates a **React-based UI** with inputs/outputs wired to your Python function.\n",
    "* **Serialization:** Data (text, images, audio, video) is passed as JSON, base64, or file blobs depending on the type.\n",
    "* **Live Updates:** You can use `live=True` for real-time updates (e.g., streaming mic input).\n",
    "\n",
    "---\n",
    "\n",
    "## Example: Image Classification\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load a pretrained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "transform = T.Compose([T.Resize(256), T.CenterCrop(224),\n",
    "                       T.ToTensor(), T.Normalize([0.485,0.456,0.406],\n",
    "                                                 [0.229,0.224,0.225])])\n",
    "\n",
    "def predict(img):\n",
    "    img_t = transform(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        preds = model(img_t)\n",
    "    return preds.argmax(dim=1).item()\n",
    "\n",
    "demo = gr.Interface(fn=predict, inputs=\"image\", outputs=\"label\")\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "* You upload an image in the browser.\n",
    "* Gradio converts it to a PIL image, sends it to your function.\n",
    "* The function runs inference → returns a label.\n",
    "* UI displays the result.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ When to use Gradio\n",
    "\n",
    "* Quick prototyping of ML apps.\n",
    "* Sharing models with non-technical teammates.\n",
    "* Building small internal tools without writing full frontend code.\n",
    "\n",
    "⚡ But: if you need **production-grade APIs** (auth, scaling, CI/CD), you’d wrap your model in **FastAPI** or deploy via frameworks like **TorchServe, Triton, BentoML**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
