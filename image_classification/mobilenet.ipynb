{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca857924-8137-451b-b56f-a510b04f69a2",
   "metadata": {},
   "source": [
    "**MobileNet** is a family of lightweight convolutional neural networks designed for **mobile and embedded vision applications**, where **computational efficiency** and **model size** are crucial.\n",
    "\n",
    "Its key innovation is the **depthwise separable convolution**, which drastically reduces computation and parameters compared to standard convolutions.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Motivation\n",
    "\n",
    "In a standard convolutional layer, for an input feature map of size\n",
    "$$\n",
    "H \\times W \\times M\n",
    "$$\n",
    "(where ( M ) is the number of input channels), and ( N ) output channels, a kernel of size ( K \\times K ) requires:\n",
    "\n",
    "$$\n",
    "\\text{Cost}_{\\text{standard}} = H \\times W \\times M \\times N \\times K^2\n",
    "$$\n",
    "\n",
    "This is computationally expensive, especially for large ( M, N, K ).\n",
    "\n",
    "MobileNet replaces this with **depthwise separable convolution**, which breaks the convolution into two simpler steps:\n",
    "\n",
    "1. **Depthwise Convolution** — apply a single ( K \\times K ) filter per input channel (no mixing between channels).\n",
    "2. **Pointwise Convolution** — a ( 1 \\times 1 ) convolution to combine the output of depthwise convolution across channels.\n",
    "\n",
    "This decomposition reduces computation by roughly:\n",
    "\n",
    "$$\n",
    "\\frac{1}{N} + \\frac{1}{K^2}\n",
    "$$\n",
    "\n",
    "For typical values (e.g., ( K = 3, N \\gg 1 )), this is about **8–9× less computation**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. MobileNet Architecture Overview (V1)\n",
    "\n",
    "| Layer Type            | Input Size | Filters/Stride | Output Size | Notes                |\n",
    "| --------------------- | ---------- | -------------- | ----------- | -------------------- |\n",
    "| Conv 3×3              | 224×224×3  | 32 / s2        | 112×112×32  | Standard conv        |\n",
    "| Depthwise Conv 3×3    | 112×112×32 | s1             | 112×112×32  | Per-channel conv     |\n",
    "| Pointwise Conv 1×1    | 112×112×32 | 64 / s1        | 112×112×64  | Combines channels    |\n",
    "| Depthwise + Pointwise | 112×112×64 | 128 / s2       | 56×56×128   | Repeat with stride 2 |\n",
    "| ...                   | ...        | ...            | ...         | Repeated pattern     |\n",
    "| Avg Pool              | 7×7×1024   | —              | 1×1×1024    | Global avg pooling   |\n",
    "| FC (Softmax)          | —          | —              | 1000        | Classification       |\n",
    "\n",
    "### Building Block\n",
    "\n",
    "Each **MobileNet block** (except the first layer) follows:\n",
    "$$\n",
    "\\text{Conv}*{3\\times3}^{dw} \\rightarrow \\text{BN} \\rightarrow \\text{ReLU6} \\rightarrow \\text{Conv}*{1\\times1}^{pw} \\rightarrow \\text{BN} \\rightarrow \\text{ReLU6}\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "* **ReLU6** is used instead of ReLU to improve robustness on low-precision devices.\n",
    "* **BN** stands for batch normalization.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Width and Resolution Multipliers\n",
    "\n",
    "MobileNet introduces two hyperparameters to trade off accuracy vs. efficiency:\n",
    "\n",
    "1. **Width Multiplier (α)** — scales the number of channels:\n",
    "   $$\n",
    "   M' = \\alpha M, \\quad N' = \\alpha N\n",
    "   $$\n",
    "   Smaller α → fewer parameters and computations.\n",
    "\n",
    "2. **Resolution Multiplier (ρ)** — scales the input image size:\n",
    "   $$\n",
    "   H' = \\rho H, \\quad W' = \\rho W\n",
    "   $$\n",
    "   Lower resolution → faster inference.\n",
    "\n",
    "Example:\n",
    "MobileNet-V1 with α=0.75 and ρ=0.5 runs much faster than the full model but with slightly lower accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. MobileNetV2 – Inverted Residuals and Linear Bottlenecks\n",
    "\n",
    "**MobileNetV2 (2018)** improves over V1 using two new ideas:\n",
    "\n",
    "### (a) Bottleneck Residual Block\n",
    "\n",
    "Instead of a simple depthwise separable block, V2 uses:\n",
    "$$\n",
    "\\text{1×1 expansion} \\rightarrow \\text{3×3 depthwise} \\rightarrow \\text{1×1 projection}\n",
    "$$\n",
    "\n",
    "This expands channels by a factor ( t ) (typically 6), applies depthwise convolution, then projects back to a low-dimensional space.\n",
    "\n",
    "### (b) Linear Bottleneck\n",
    "\n",
    "After projection, **no ReLU** is applied at the end — this preserves information that would otherwise be lost due to non-linearity in a narrow bottleneck space.\n",
    "\n",
    "### Block Structure\n",
    "\n",
    "| Step | Type                            | Purpose           |\n",
    "| ---- | ------------------------------- | ----------------- |\n",
    "| 1    | 1×1 Conv (expand) + BN + ReLU6  | Increase channels |\n",
    "| 2    | 3×3 Depthwise Conv + BN + ReLU6 | Spatial filtering |\n",
    "| 3    | 1×1 Conv (project) + BN         | Compress channels |\n",
    "| 4    | Skip connection (if same shape) | Residual learning |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. MobileNetV3 – Efficient Search and Squeeze-Excitation\n",
    "\n",
    "**MobileNetV3 (2019)** uses **Neural Architecture Search (NAS)** and **Squeeze-and-Excitation (SE)** blocks for improved accuracy/efficiency.\n",
    "\n",
    "Key components:\n",
    "\n",
    "* **SE Block**: channel attention mechanism to reweight features.\n",
    "* **Hard-Swish (h-swish)** activation: a computationally efficient approximation of Swish:\n",
    "  $$\n",
    "  \\text{h-swish}(x) = x \\cdot \\frac{\\text{ReLU6}(x + 3)}{6}\n",
    "  $$\n",
    "* Mix of **bottleneck residuals (from V2)** and **efficient NAS-designed layers**.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Comparison Summary\n",
    "\n",
    "| Version     | Key Innovation                        | Approx. Params | Typical Use                     |\n",
    "| ----------- | ------------------------------------- | -------------- | ------------------------------- |\n",
    "| MobileNetV1 | Depthwise separable conv              | ~4.2M          | Simple, fast models             |\n",
    "| MobileNetV2 | Inverted residual + linear bottleneck | ~3.4M          | Balance accuracy & speed        |\n",
    "| MobileNetV3 | NAS + SE + h-swish                    | ~5.4M          | Most accurate, mobile-optimized |\n",
    "\n",
    "---\n",
    "\n",
    "## 7. When to Use MobileNet\n",
    "\n",
    "* **Real-time inference on edge devices** (phones, drones, embedded systems).\n",
    "* **Feature extractor in lightweight pipelines** (e.g., object detection with SSD or segmentation with DeepLab).\n",
    "* **Transfer learning** for small datasets where training from scratch is impractical.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a1bf5-1296-498d-8526-a5adeedfe190",
   "metadata": {},
   "source": [
    "\n",
    "## 1. MobileNetV1 — Full Architecture\n",
    "\n",
    "MobileNetV1 (2017) is a simple **stack of depthwise-separable convolutions** with gradually increasing channel width and downsampling at certain stages.\n",
    "\n",
    "### Structure\n",
    "\n",
    "|     # | Type                       | Kernel / Stride | Output Channels | Input Size (for 224×224 input) |\n",
    "| ----: | -------------------------- | --------------- | --------------: | ------------------------------ |\n",
    "|     1 | Conv2D                     | 3×3 / 2         |              32 | 112×112×32                     |\n",
    "|     2 | Depthwise Conv             | 3×3 / 1         |              32 | 112×112×32                     |\n",
    "|     3 | Pointwise Conv             | 1×1 / 1         |              64 | 112×112×64                     |\n",
    "|     4 | Depthwise Conv             | 3×3 / 2         |              64 | 56×56×64                       |\n",
    "|     5 | Pointwise Conv             | 1×1 / 1         |             128 | 56×56×128                      |\n",
    "|     6 | Depthwise Conv             | 3×3 / 1         |             128 | 56×56×128                      |\n",
    "|     7 | Pointwise Conv             | 1×1 / 1         |             128 | 56×56×128                      |\n",
    "|     8 | Depthwise Conv             | 3×3 / 2         |             128 | 28×28×128                      |\n",
    "|     9 | Pointwise Conv             | 1×1 / 1         |             256 | 28×28×256                      |\n",
    "|    10 | Depthwise Conv             | 3×3 / 1         |             256 | 28×28×256                      |\n",
    "|    11 | Pointwise Conv             | 1×1 / 1         |             256 | 28×28×256                      |\n",
    "|    12 | Depthwise Conv             | 3×3 / 2         |             256 | 14×14×256                      |\n",
    "|    13 | Pointwise Conv             | 1×1 / 1         |             512 | 14×14×512                      |\n",
    "| 14–18 | [Depthwise + Pointwise] ×5 | 3×3 / 1         |             512 | 14×14×512                      |\n",
    "|    19 | Depthwise Conv             | 3×3 / 2         |             512 | 7×7×512                        |\n",
    "|    20 | Pointwise Conv             | 1×1 / 1         |            1024 | 7×7×1024                       |\n",
    "|    21 | Depthwise Conv             | 3×3 / 1         |            1024 | 7×7×1024                       |\n",
    "|    22 | Pointwise Conv             | 1×1 / 1         |            1024 | 7×7×1024                       |\n",
    "|    23 | AvgPool                    | 7×7             |            1024 | 1×1×1024                       |\n",
    "|    24 | Fully Connected            | —               |            1000 | 1000 classes                   |\n",
    "\n",
    "**Total parameters:** ~4.2 million\n",
    "**FLOPs:** ~569 million\n",
    "\n",
    "So: it’s essentially **a deep stack of depthwise-separable convs**, with downsampling every few layers and a final global average pooling before classification.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. MobileNetV2 — Full Architecture\n",
    "\n",
    "MobileNetV2 (2018) introduced **inverted residual bottlenecks** with expansion and projection.\n",
    "\n",
    "Each block has parameters:\n",
    "\n",
    "* **t**: expansion factor\n",
    "* **c**: output channels\n",
    "* **n**: number of repeats\n",
    "* **s**: stride for the first block\n",
    "\n",
    "### Structure\n",
    "\n",
    "| Stage | Input      | Operator       |  t  |   c  |  n  |  s  |\n",
    "| :---- | :--------- | :------------- | :-: | :--: | :-: | :-: |\n",
    "| 0     | 224×224×3  | Conv2D 3×3     |  —  |  32  |  1  |  2  |\n",
    "| 1     | 112×112×32 | Bottleneck     |  1  |  16  |  1  |  1  |\n",
    "| 2     | 112×112×16 | Bottleneck     |  6  |  24  |  2  |  2  |\n",
    "| 3     | 56×56×24   | Bottleneck     |  6  |  32  |  3  |  2  |\n",
    "| 4     | 28×28×32   | Bottleneck     |  6  |  64  |  4  |  2  |\n",
    "| 5     | 14×14×64   | Bottleneck     |  6  |  96  |  3  |  1  |\n",
    "| 6     | 14×14×96   | Bottleneck     |  6  |  160 |  3  |  2  |\n",
    "| 7     | 7×7×160    | Bottleneck     |  6  |  320 |  1  |  1  |\n",
    "| 8     | 7×7×320    | Conv2D 1×1     |  —  | 1280 |  1  |  1  |\n",
    "| 9     | 7×7×1280   | Global AvgPool |  —  | 1280 |  —  |  —  |\n",
    "| 10    | 1×1×1280   | FC + Softmax   |  —  | 1000 |  —  |  —  |\n",
    "\n",
    "Each *Bottleneck* consists of:\n",
    "$$\n",
    "1\\times1\\ \\text{Conv (expand)} \\rightarrow 3\\times3\\ \\text{Depthwise} \\rightarrow 1\\times1\\ \\text{Conv (project)}\n",
    "$$\n",
    "and uses a **residual connection** if stride = 1 and input/output channels match.\n",
    "\n",
    "**Total parameters:** ~3.4 million\n",
    "**FLOPs:** ~300 million\n",
    "\n",
    "---\n",
    "\n",
    "## 3. MobileNetV3 — Full Architecture (Small & Large Variants)\n",
    "\n",
    "MobileNetV3 (2019) is the result of **Neural Architecture Search** plus **SE blocks** and **h-swish activation**. It has two main variants: **Large** and **Small**.\n",
    "\n",
    "Below is **MobileNetV3-Large** (for 224×224 input):\n",
    "\n",
    "| Stage | Operator         |  k  | exp |   c  |  SE |    NL   |  s  |\n",
    "| :---- | :--------------- | :-: | :-: | :--: | :-: | :-----: | :-: |\n",
    "| 0     | Conv2D           | 3×3 |  —  |  16  |  —  | h-swish |  2  |\n",
    "| 1     | Bottleneck       | 3×3 |  16 |  16  |  No |   ReLU  |  1  |\n",
    "| 2     | Bottleneck       | 3×3 |  64 |  24  |  No |   ReLU  |  2  |\n",
    "| 3     | Bottleneck       | 3×3 |  72 |  24  |  No |   ReLU  |  1  |\n",
    "| 4     | Bottleneck       | 5×5 |  72 |  40  | Yes |   ReLU  |  2  |\n",
    "| 5     | Bottleneck       | 5×5 | 120 |  40  | Yes |   ReLU  |  1  |\n",
    "| 6     | Bottleneck       | 5×5 | 120 |  40  | Yes |   ReLU  |  1  |\n",
    "| 7     | Bottleneck       | 3×3 | 240 |  80  |  No | h-swish |  2  |\n",
    "| 8     | Bottleneck       | 3×3 | 200 |  80  |  No | h-swish |  1  |\n",
    "| 9     | Bottleneck       | 3×3 | 184 |  80  |  No | h-swish |  1  |\n",
    "| 10    | Bottleneck       | 3×3 | 184 |  80  |  No | h-swish |  1  |\n",
    "| 11    | Bottleneck       | 3×3 | 480 |  112 | Yes | h-swish |  1  |\n",
    "| 12    | Bottleneck       | 3×3 | 672 |  160 | Yes | h-swish |  2  |\n",
    "| 13    | Bottleneck       | 3×3 | 960 |  160 | Yes | h-swish |  1  |\n",
    "| 14    | Conv2D           | 1×1 |  —  |  960 |  —  | h-swish |  1  |\n",
    "| 15    | Pool + SE + Conv |  —  |  —  | 1280 |  —  | h-swish |  —  |\n",
    "| 16    | FC + Softmax     |  —  |  —  | 1000 |  —  |    —    |  —  |\n",
    "\n",
    "**MobileNetV3-Small** is similar but optimized for lower latency and smaller memory footprint.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Visualization Summary\n",
    "\n",
    "### MobileNetV1\n",
    "\n",
    "```\n",
    "Input → Conv → [DWConv + PWConv]*13 → AvgPool → FC\n",
    "```\n",
    "\n",
    "### MobileNetV2\n",
    "\n",
    "```\n",
    "Input → Conv → Bottleneck(t=1, c=16)\n",
    "      → Bottleneck(t=6, c=24)*2\n",
    "      → Bottleneck(t=6, c=32)*3\n",
    "      → Bottleneck(t=6, c=64)*4\n",
    "      → Bottleneck(t=6, c=96)*3\n",
    "      → Bottleneck(t=6, c=160)*3\n",
    "      → Conv → Pool → FC\n",
    "```\n",
    "\n",
    "### MobileNetV3\n",
    "\n",
    "```\n",
    "Input → Conv → SE Bottlenecks (ReLU / h-swish mix)\n",
    "      → Conv1x1 → Pool + SE → FC\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
