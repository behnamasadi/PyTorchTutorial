{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9144fc8-c7d6-48de-857b-2402bb94cdd9",
   "metadata": {},
   "source": [
    "## **1. Install YOLOv8**\n",
    "\n",
    "You just need Python ≥3.8 and pip.\n",
    "\n",
    "```bash\n",
    "pip install ultralytics\n",
    "```\n",
    "\n",
    "After installation, you can verify:\n",
    "\n",
    "```bash\n",
    "yolo\n",
    "```\n",
    "\n",
    "This should print YOLOv8’s CLI help menu.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Run a quick test**\n",
    "\n",
    "Download a pretrained YOLOv8 model and run detection on an image:\n",
    "\n",
    "```bash\n",
    "yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'\n",
    "```\n",
    "\n",
    "* `yolov8n.pt` → \"nano\" model (fastest, smallest).\n",
    "* Other versions: `yolov8s.pt` (small), `yolov8m.pt` (medium), `yolov8l.pt` (large), `yolov8x.pt` (extra large).\n",
    "\n",
    "Output will be in a `runs/predict` folder with bounding boxes drawn.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Train on your own dataset**\n",
    "\n",
    "If you have a dataset:\n",
    "\n",
    "```bash\n",
    "yolo train model=yolov8n.pt data=data.yaml epochs=50 imgsz=640\n",
    "```\n",
    "\n",
    "* `data.yaml` should describe:\n",
    "\n",
    "  ```yaml\n",
    "  train: path/to/train/images\n",
    "  val: path/to/val/images\n",
    "  nc: 2   # number of classes\n",
    "  names: ['cat', 'dog']\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Use it from Python**\n",
    "\n",
    "You can also run it as a Python module:\n",
    "\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Predict on an image\n",
    "results = model.predict(\"bus.jpg\")\n",
    "results[0].show()  # show image with boxes\n",
    "\n",
    "# Train on custom data\n",
    "model.train(data=\"data.yaml\", epochs=50, imgsz=640)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Deployment options**\n",
    "\n",
    "YOLOv8 supports exporting models to:\n",
    "\n",
    "```bash\n",
    "yolo export model=yolov8n.pt format=onnx\n",
    "yolo export model=yolov8n.pt format=torchscript\n",
    "yolo export model=yolov8n.pt format=engine  # TensorRT\n",
    "```\n",
    "\n",
    "That means you can deploy it on:\n",
    "\n",
    "* **ONNX Runtime** (cross-platform)\n",
    "* **TorchScript** (PyTorch native)\n",
    "* **TensorRT** (NVIDIA GPUs, super fast)\n",
    "\n",
    "---\n",
    "\n",
    "## **6. License reminder**\n",
    "\n",
    "YOLOv8 is under **AGPL-3.0**:\n",
    "\n",
    "* ✅ Fine for research, personal projects, competitions (e.g., Kaggle).\n",
    "* ⚠ If building a closed-source commercial service → either comply with AGPL (share source) or buy a commercial license from Ultralytics.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727255c-4832-4bc9-8320-362125e5281a",
   "metadata": {},
   "source": [
    "## **End-to-end YOLOv8 workflow**\n",
    "\n",
    "### 1) Install\n",
    "\n",
    "```bash\n",
    "pip install ultralytics\n",
    "yolo  # should print the CLI help\n",
    "```\n",
    "\n",
    "### 2) Dataset layout (YOLO format)\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├─ images/\n",
    "│  ├─ train/   0001.jpg 0002.jpg ...\n",
    "│  ├─ val/     1001.jpg 1002.jpg ...\n",
    "│  └─ test/    2001.jpg 2002.jpg ...   # optional but recommended\n",
    "└─ labels/\n",
    "   ├─ train/   0001.txt 0002.txt ...\n",
    "   ├─ val/     1001.txt 1002.txt ...\n",
    "   └─ test/    2001.txt 2002.txt ...\n",
    "```\n",
    "\n",
    "Each `*.txt` file matches its image name and contains **one line per object**:\n",
    "\n",
    "```\n",
    "<class_id> <x_center> <y_center> <width> <height>\n",
    "```\n",
    "\n",
    "All values are **normalized to \\[0,1]** relative to image width/height. Example (two objects):\n",
    "\n",
    "```\n",
    "0 0.512 0.433 0.120 0.210\n",
    "3 0.245 0.680 0.050 0.090\n",
    "```\n",
    "\n",
    "> If an image has **no objects**, include an **empty** `*.txt` file (present, but 0 lines).\n",
    "\n",
    "### 3) data.yaml\n",
    "\n",
    "Create `data.yaml`:\n",
    "\n",
    "```yaml\n",
    "path: /absolute/or/relative/path/to/dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test          # optional\n",
    "\n",
    "nc: 3\n",
    "names: [cat, dog, rabbit]  # class names in order of IDs 0..nc-1\n",
    "```\n",
    "\n",
    "### 4) Quick sanity checks (strongly recommended)\n",
    "\n",
    "```bash\n",
    "# Verify labels and visualize a few samples\n",
    "yolo data=data.yaml task=detect mode=check\n",
    "```\n",
    "\n",
    "This catches broken paths, missing files, or label format issues.\n",
    "\n",
    "### 5) Train (from pretrained weights)\n",
    "\n",
    "Pick a model size (`n/s/m/l/x` = nano→xlarge):\n",
    "\n",
    "```bash\n",
    "# Fast start\n",
    "yolo train model=yolov8n.pt data=data.yaml epochs=100 imgsz=640 batch=16\n",
    "\n",
    "# Helpful flags you may want:\n",
    "# device=0               # pick a GPU; \"0,1\" for multi-GPU\n",
    "# patience=30            # early stopping patience (epochs)\n",
    "# cos_lr=True            # cosine LR schedule\n",
    "# augment=True           # on by default for detect; can disable with augment=False\n",
    "# project=./runs         # change output root\n",
    "# name=my_yolov8_exp     # run name (folder)\n",
    "```\n",
    "\n",
    "Notes:\n",
    "\n",
    "* **Anchor-free** head → no need to compute anchors.\n",
    "* **Mixed precision** (AMP) is on by default when CUDA is available.\n",
    "* If your images are large and you hit OOM: lower `imgsz` or `batch`.\n",
    "\n",
    "### 6) Monitor & evaluate\n",
    "\n",
    "Training automatically produces:\n",
    "\n",
    "* **mAP\\@0.5** and **mAP\\@0.5:0.95** (the key metrics)\n",
    "* Precision/Recall curves, confusion matrix, PR curves per class\n",
    "* Best/last checkpoints: `runs/detect/train*/weights/best.pt`\n",
    "\n",
    "Validate (e.g., after training or on a new split):\n",
    "\n",
    "```bash\n",
    "yolo val model=runs/detect/train/weights/best.pt data=data.yaml imgsz=640\n",
    "```\n",
    "\n",
    "### 7) Inference on images / folders / videos\n",
    "\n",
    "```bash\n",
    "# Single image or folder\n",
    "yolo predict model=runs/detect/train/weights/best.pt source=path/to/images_or_video\n",
    "\n",
    "# Save results in runs/predict/* with drawn boxes\n",
    "```\n",
    "\n",
    "### 8) Export for deployment\n",
    "\n",
    "```bash\n",
    "# Common targets\n",
    "yolo export model=best.pt format=onnx\n",
    "yolo export model=best.pt format=torchscript\n",
    "yolo export model=best.pt format=engine  # TensorRT (NVIDIA GPUs)\n",
    "\n",
    "# Then run with ONNX Runtime / TorchScript / TensorRT as needed\n",
    "```\n",
    "\n",
    "### 9) Using Python API (train + infer programmatically)\n",
    "\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained detector\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Train\n",
    "model.train(data=\"data.yaml\", epochs=100, imgsz=640, batch=16)\n",
    "\n",
    "# Validate\n",
    "metrics = model.val(data=\"data.yaml\", imgsz=640)\n",
    "\n",
    "# Predict\n",
    "results = model.predict(source=\"path/to/img_or_dir\")\n",
    "for r in results:\n",
    "    boxes = r.boxes.xyxy  # tensor[N, 4]\n",
    "    scores = r.boxes.conf\n",
    "    cls_ids = r.boxes.cls\n",
    "```\n",
    "\n",
    "### 10) Practical tips & gotchas\n",
    "\n",
    "* **Labeling tools**: CVAT, Label Studio, Roboflow can export YOLO format directly.\n",
    "* **Class imbalance**: consider more epochs, stronger augmentation, or focal loss (`--fl_gamma=2.0` via CLI args if exposed) — or oversample minority classes.\n",
    "* **Augmentation**: YOLOv8 includes mosaic/mixup, HSV, flips by default; you can tune/disable in args.\n",
    "* **Input channels**: models expect 3-channel images.\n",
    "\n",
    "  * If you have **grayscale** (e.g., MRI), either save as 3-channel copies or adapt the dataloader (simple replication of the single channel to RGB works well).\n",
    "* **Empty images**: keep empty label files so the trainer learns negatives.\n",
    "* **Overfitting**: watch train vs val mAP; increase augmentation, add more data, or use a smaller model (`n`/`s`).\n",
    "* **Resume training**: `yolo train resume=True` pointing to the last run directory.\n",
    "\n",
    "### 11) Minimal checklist\n",
    "\n",
    "* [ ] Images + YOLO TXT labels aligned by filename\n",
    "* [ ] `data.yaml` with correct paths, `nc`, `names`\n",
    "* [ ] Sanity check: `yolo ... mode=check`\n",
    "* [ ] Train, then validate and inspect mAP/PR curves\n",
    "* [ ] Export to the runtime you need (ONNX/TensorRT/etc.)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
