{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6105e0f5-88b6-4275-8e02-ecfee03fbd0d",
   "metadata": {},
   "source": [
    "# VGG-19\n",
    "\n",
    "VGG-19 has the following pattern in the first block:\n",
    "\n",
    "**Input (RGB image)** → Conv(3 → 64) → Conv(64 → 64) → MaxPool\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Why do we have **two times 64 feature maps**?\n",
    "\n",
    "* The **first conv layer** takes the raw RGB channels (3) and learns 64 different filters, so the output has **64 feature maps**.\n",
    "* The **second conv layer** then applies 64 new filters, each seeing *all 64 previous feature maps* as input. This lets the network build richer, more abstract features without yet reducing spatial resolution.\n",
    "* So it’s not “repeating the same 64 maps,” it’s:\n",
    "\n",
    "  * First layer: detect low-level patterns (edges, colors, textures).\n",
    "  * Second layer: combine them into more complex local structures, still keeping 64 channels so the representational power is larger before downsampling.\n",
    "\n",
    "In other words, **keeping the same number of channels but stacking multiple convs increases depth of processing at the same spatial scale**. This improves expressive power.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. What happens to **H and W**?\n",
    "\n",
    "* Both conv layers in VGG use **3×3 kernels, stride = 1, padding = 1**.\n",
    "* Formula for conv output size:\n",
    "\n",
    "$$\n",
    "H_{out} = \\frac{H_{in} + 2p - k}{s} + 1\n",
    "$$\n",
    "\n",
    "With $k=3, s=1, p=1$, we get:\n",
    "\n",
    "$$\n",
    "H_{out} = \\frac{H_{in} + 2 - 3}{1} + 1 = H_{in}\n",
    "$$\n",
    "\n",
    "Same for $W$.\n",
    " So after each 3×3 conv, the spatial size **stays the same**. Only the **channel depth changes** (3 → 64 → 64).\n",
    "\n",
    "* After the two convs, a **max-pool (2×2, stride=2)** halves the H and W.\n",
    "\n",
    "  * Example: $224×224×3$ input →\n",
    "    Conv → $224×224×64$ →\n",
    "    Conv → $224×224×64$ →\n",
    "    MaxPool → $112×112×64$.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e661df-521b-4791-bb5e-673adcb2a11b",
   "metadata": {},
   "source": [
    "## 1. What does **kernel size** mean?\n",
    "\n",
    "* A **kernel (filter)** is the small sliding window used in a convolution.\n",
    "* Its size is written as $k \\times k$. Examples:\n",
    "\n",
    "  * **3×3 kernel** → looks at a 3×3 patch of the image (or feature map).\n",
    "  * **5×5 kernel** → looks at a 5×5 patch.\n",
    "  * **7×7 kernel** → looks at a 7×7 patch.\n",
    "\n",
    "The choice of kernel size affects the **receptive field**:\n",
    "\n",
    "* 3×3 sees very local details (edges, textures).\n",
    "* 5×5 sees slightly larger structures.\n",
    "* 7×7 sees broader patterns (but costs more parameters).\n",
    "\n",
    " VGG chose **3×3 kernels stacked multiple times** instead of using 5×5 or 7×7, because:\n",
    "\n",
    "* Two 3×3 layers = receptive field of 5×5, but with fewer parameters and more non-linearities (ReLU in between).\n",
    "* Three 3×3 layers = receptive field of 7×7, with even deeper representations.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. How many kernels do we need in the first conv layer of VGG?\n",
    "\n",
    "Input: **RGB image** → $H \\times W \\times 3$.\n",
    "First conv layer: 64 output channels.\n",
    "\n",
    "* Each output channel is produced by **one kernel**.\n",
    "* Since the input has 3 channels, each kernel must also have **3 channels**.\n",
    "* So the shape of one kernel is:\n",
    "\n",
    "  $$\n",
    "  3 \\times 3 \\times 3\n",
    "  $$\n",
    "* To get 64 output channels, we need **64 different kernels** of shape $3 \\times 3 \\times 3$.\n",
    "\n",
    "So total parameters in the first conv =\n",
    "\n",
    "$$\n",
    "(3 \\times 3 \\times 3) \\times 64 + 64 \\quad \\text{(bias terms)}\n",
    "$$\n",
    "\n",
    "\\= 1,792 parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. What about the **second conv layer (64→64)?**\n",
    "\n",
    "Now the input has 64 channels.\n",
    "We want 64 outputs again.\n",
    "\n",
    "* Each kernel is now: $3 \\times 3 \\times 64$.\n",
    "* Each output channel has one such kernel.\n",
    "* We need 64 kernels.\n",
    "\n",
    "So parameters =\n",
    "\n",
    "$$\n",
    "(3 \\times 3 \\times 64) \\times 64 + 64 = 36,928\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    " **Summary**:\n",
    "\n",
    "* Kernel size = spatial window (3×3, 5×5, 7×7).\n",
    "* In conv layers:\n",
    "\n",
    "  * 3 input channels → each kernel has 3 channels.\n",
    "  * 64 output channels → we need 64 kernels.\n",
    "* First VGG conv: 64 kernels of shape $3 \\times 3 \\times 3$.\n",
    "* Second VGG conv: 64 kernels of shape $3 \\times 3 \\times 64$.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe7cf2-a993-4e48-8f1d-66b28a16ff77",
   "metadata": {},
   "source": [
    "<img src='images/06_03.png'/>\n",
    "<img src='images/06_09.png'>\n",
    "<img src='images/3_channel_conv.gif'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
