{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29cc11d5-f966-4355-9eb6-92740f5e2b7a",
   "metadata": {},
   "source": [
    "## Convolutional Block Attention Module (CBAM)\n",
    "\n",
    "Spatial Attention in deep learning is a **mechanism that tells the network *where* to focus in the spatial dimensions** of a feature map (i.e., across height and width).\n",
    "\n",
    "The **CBAM** defines **two submodules** applied sequentially:\n",
    "\n",
    "**CBAM = Channel Attention + Spatial Attention**\n",
    "\n",
    "\n",
    "$$\n",
    "F' = M_s(M_c(F))\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $M_c(F)$ = **Channel Attention Module (CAM)** — focuses on *what* features (channels) are important.\n",
    "* $M_s(F)$ = **Spatial Attention Module (SAM)** — focuses on *where* in the spatial map to attend.\n",
    "\n",
    "So, the CBAM block contains **both** modules — they are not alternatives, they are *stacked*.\n",
    "\n",
    "<img src=\"images/convolutional_block_attention_module.png\" width=\"70%\" height=\"70%\" />\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70842db6-aa9a-4b62-8202-422c308425ac",
   "metadata": {},
   "source": [
    "## **1.Spatial Attention Module (SAM)**\n",
    "\n",
    "Imagine an image with a cat sitting on grass.\n",
    "A convolutional layer will extract features everywhere — cat + grass + background.\n",
    "Spatial Attention helps the model **highlight the cat region** (important spatially) and **suppress the background** (less relevant).\n",
    "\n",
    "In short:\n",
    "\n",
    "$$\n",
    "\\text{Focus on \"where\"} \\quad \\text{→ spatial attention.}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "It computes a 2D attention map $A_s \\in \\mathbb{R}^{H \\times W}$ that highlights important *spatial regions* (the “where”).\n",
    "\n",
    "Formula:\n",
    "\n",
    "$$\n",
    "A_s = \\sigma(\\text{Conv2D}([\\text{AvgPool}(F); \\text{MaxPool}(F)]))\n",
    "$$\n",
    "\n",
    "and the final output:\n",
    "\n",
    "$$\n",
    "F' = A_s \\odot F\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "####  **1.2. General Formula**\n",
    "\n",
    "Spatial Attention generates an **attention map** $A_s \\in \\mathbb{R}^{H \\times W}$ (same spatial size as input) that represents *importance of each spatial location*.\n",
    "\n",
    "Given an input feature map\n",
    "$$\n",
    "F \\in \\mathbb{R}^{C \\times H \\times W}\n",
    "$$\n",
    "\n",
    "we compute:\n",
    "\n",
    "$$\n",
    "F'_i = A_s \\odot F_i\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $\\odot$ is element-wise multiplication broadcast along the channel dimension\n",
    "* $A_s$ is a 2D spatial attention map, usually normalized with sigmoid so that $A_s \\in [0,1]^{H \\times W}$\n",
    "\n",
    "---\n",
    "\n",
    "####  **1.3. How to Compute the Spatial Attention Map**\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. **Aggregate along channels** using average-pooling and max-pooling:\n",
    "   $$\n",
    "   F_{\\text{avg}} = \\text{AvgPool}(F) \\in \\mathbb{R}^{1 \\times H \\times W}\n",
    "   $$\n",
    "   $$\n",
    "   F_{\\text{max}} = \\text{MaxPool}(F) \\in \\mathbb{R}^{1 \\times H \\times W}\n",
    "   $$\n",
    "\n",
    "2. **Concatenate and convolve:**\n",
    "   $$\n",
    "   F_{\\text{cat}} = [F_{\\text{avg}}; F_{\\text{max}}]\n",
    "   $$\n",
    "   $$\n",
    "   A_s = \\sigma(\\text{Conv2D}(F_{\\text{cat}}))\n",
    "   $$\n",
    "\n",
    "   where $\\sigma$ is the sigmoid activation.\n",
    "\n",
    "3. **Apply attention:**\n",
    "   $$\n",
    "   F' = A_s \\odot F\n",
    "   $$\n",
    "\n",
    "Thus, $A_s$ highlights the important *spatial* locations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc7f81-eedd-4e17-9adf-f2f3b174b9e6",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/spatial_attention_module.png\" width=\"70%\" height=\"70%\" />\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.4. Code Example (CBAM-style Spatial Attention)**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, H, W]\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)        # [B, 1, H, W]\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)      # [B, 1, H, W]\n",
    "        x_cat = torch.cat([avg_out, max_out], dim=1)        # [B, 2, H, W]\n",
    "        attn = torch.sigmoid(self.conv(x_cat))              # [B, 1, H, W]\n",
    "        return x * attn                                     # spatially weighted feature map\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.5. Visualization**\n",
    "\n",
    "If you visualize the $A_s$ attention map, you’d typically see:\n",
    "\n",
    "* Bright areas → model focus (object regions)\n",
    "* Dark areas → ignored background\n",
    "\n",
    "This makes the model **more interpretable** and **performance-improving** for detection, segmentation, and recognition tasks.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fbfe88-f973-4fb5-abf3-0cbe2c1b86af",
   "metadata": {},
   "source": [
    "## **2. Spatial Attention Module (SAM) Numerical Example**\n",
    "\n",
    "We’ll use the formula from CBAM:\n",
    "\n",
    "$$\n",
    "A_s = \\sigma(\\text{Conv2D}([\\text{AvgPool}(F); \\text{MaxPool}(F)]))\n",
    "$$\n",
    "\n",
    "and then apply $A_s$ to the input feature map.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.1. Input feature map**\n",
    "\n",
    "Suppose we have an input feature map with 2 channels, 2×2 spatial size:\n",
    "\n",
    "$$\n",
    "F =\n",
    "\\begin{bmatrix}\n",
    "\\text{Channel 1} &\n",
    "\\text{Channel 2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Let’s define it numerically:\n",
    "\n",
    "$$\n",
    "F_1 =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "F_2 =\n",
    "\\begin{bmatrix}\n",
    "2 & 0 \\\\\n",
    "1 & 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So\n",
    "$F$ has shape $[C, H, W] = [2, 2, 2]$.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.2. Average Pooling along channels**\n",
    "\n",
    "We compute the mean for each pixel across channels:\n",
    "\n",
    "$$\n",
    "F_{\\text{avg}}(i,j) = \\frac{F_1(i,j) + F_2(i,j)}{2}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "| Location | Calculation | Result |\n",
    "| -------- | ----------- | ------ |\n",
    "| (0,0)    | (1 + 2)/2   | 1.5    |\n",
    "| (0,1)    | (2 + 0)/2   | 1.0    |\n",
    "| (1,0)    | (3 + 1)/2   | 2.0    |\n",
    "| (1,1)    | (4 + 3)/2   | 3.5    |\n",
    "\n",
    "$$\n",
    "F_{\\text{avg}} =\n",
    "\\begin{bmatrix}\n",
    "1.5 & 1.0 \\\\\n",
    "2.0 & 3.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.3. Max Pooling along channels**\n",
    "\n",
    "We take the maximum across channels:\n",
    "\n",
    "| Location | max(Ch1, Ch2) | Result |\n",
    "| -------- | ------------- | ------ |\n",
    "| (0,0)    | max(1,2)      | 2      |\n",
    "| (0,1)    | max(2,0)      | 2      |\n",
    "| (1,0)    | max(3,1)      | 3      |\n",
    "| (1,1)    | max(4,3)      | 4      |\n",
    "\n",
    "$$\n",
    "F_{\\text{max}} =\n",
    "\\begin{bmatrix}\n",
    "2 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.4. Concatenate and convolve**\n",
    "\n",
    "We stack them along the channel dimension:\n",
    "$$\n",
    "F_{\\text{cat}} = [F_{\\text{avg}}; F_{\\text{max}}]\n",
    "$$\n",
    "so shape becomes `[2, 2, 2]`.\n",
    "\n",
    "Let’s assume the 2D convolution kernel has weights:\n",
    "$$\n",
    "W = [w_1, w_2] = [0.5, 0.5]\n",
    "$$\n",
    "(no bias, kernel size = 1×1).\n",
    "\n",
    "Then convolution output:\n",
    "$$\n",
    "A_s = \\sigma(0.5 \\times F_{\\text{avg}} + 0.5 \\times F_{\\text{max}})\n",
    "$$\n",
    "\n",
    "Compute elementwise:\n",
    "\n",
    "| Location | Equation        | Value | After Sigmoid |\n",
    "| -------- | --------------- | ----- | ------------- |\n",
    "| (0,0)    | 0.5×1.5 + 0.5×2 | 1.75  | 0.85          |\n",
    "| (0,1)    | 0.5×1.0 + 0.5×2 | 1.5   | 0.82          |\n",
    "| (1,0)    | 0.5×2.0 + 0.5×3 | 2.5   | 0.92          |\n",
    "| (1,1)    | 0.5×3.5 + 0.5×4 | 3.75  | 0.98          |\n",
    "\n",
    "$$\n",
    "A_s =\n",
    "\\begin{bmatrix}\n",
    "0.85 & 0.82 \\\\\n",
    "0.92 & 0.98\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.5. Apply Spatial Attention**\n",
    "\n",
    "Multiply each spatial location (broadcasted across channels):\n",
    "\n",
    "For Channel 1:\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{For Channel 1:}\n",
    "$$\n",
    "$$\n",
    "F'_1 = F_1 \\odot A_s =\n",
    "\\begin{bmatrix}\n",
    "1\\times 0.85 & 2\\times 0.82 \\\\\n",
    "3\\times 0.92 & 4\\times 0.98\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.85 & 1.64 \\\\\n",
    "2.76 & 3.92\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{For Channel 2:}\n",
    "$$\n",
    "$$\n",
    "F'_2 = F_2 \\odot A_s =\n",
    "\\begin{bmatrix}\n",
    "2\\times 0.85 & 0\\times 0.82 \\\\\n",
    "1\\times 0.92 & 3\\times 0.98\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1.70 & 0.00 \\\\\n",
    "0.92 & 2.94\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.6. Result**\n",
    "\n",
    "The **final attention-weighted feature map** is:\n",
    "\n",
    "$$\n",
    "F' =\n",
    "\\Bigg[\n",
    "\\begin{bmatrix}\n",
    "0.85 & 1.64 \\\\\n",
    "2.76 & 3.92\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "\\begin{bmatrix}\n",
    "1.70 & 0.00 \\\\\n",
    "0.92 & 2.94\n",
    "\\end{bmatrix}\n",
    "\\Bigg]\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "* Bright regions (bottom-right corner) got **higher attention values** (≈ 0.98)\n",
    "* Top-left corner got **lower attention values** (≈ 0.82)\n",
    "\n",
    "So the model **focuses spatially** on the more informative region of the feature map.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a238f-5db7-4766-b430-1f744aac8183",
   "metadata": {},
   "source": [
    "## **3. Channel Attention Module (CAM)**\n",
    "\n",
    "Let’s now explain the **Channel Attention Module (CAM)**, which comes *before* SAM.\n",
    "\n",
    "This one tells the network **which channels (features)** to emphasize — for example, “edges” or “color” channels.\n",
    "\n",
    "Given a feature map:\n",
    "$$\n",
    "F \\in \\mathbb{R}^{C \\times H \\times W}\n",
    "$$\n",
    "\n",
    "CAM computes a **channel attention vector** $A_c \\in \\mathbb{R}^{C}$:\n",
    "\n",
    "---\n",
    "\n",
    "#### **3.a) Channel Attention Formula**\n",
    "\n",
    "1. **Global Pooling (squeeze spatial info):**\n",
    "\n",
    "Compute both **average** and **max** over spatial dimensions:\n",
    "\n",
    "$$\n",
    "F_{\\text{avg}} = \\text{AvgPool}(F) \\in \\mathbb{R}^{C \\times 1 \\times 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_{\\text{max}} = \\text{MaxPool}(F) \\in \\mathbb{R}^{C \\times 1 \\times 1}\n",
    "$$\n",
    "\n",
    "2. **Shared MLP (two FC layers):**\n",
    "\n",
    "Each passes through a small MLP (with reduction ratio $r$, e.g. 16):\n",
    "\n",
    "$$\n",
    "M_{\\text{avg}} = W_1(\\text{ReLU}(W_0(F_{\\text{avg}})))\n",
    "$$\n",
    "\n",
    "$$\n",
    "M_{\\text{max}} = W_1(\\text{ReLU}(W_0(F_{\\text{max}})))\n",
    "$$\n",
    "\n",
    "3. **Combine and activate:**\n",
    "\n",
    "$$\n",
    "A_c = \\sigma(M_{\\text{avg}} + M_{\\text{max}})\n",
    "$$\n",
    "\n",
    "4. **Apply attention across channels:**\n",
    "\n",
    "$$\n",
    "F' = A_c \\odot F\n",
    "$$\n",
    "\n",
    "(where $\\odot$ means broadcasting multiplication across spatial dims)\n",
    "\n",
    "---\n",
    "\n",
    "#### **3.b) Intuition**\n",
    "\n",
    "* Each channel represents a *type of feature* (edges, color blobs, textures, etc.).\n",
    "* CAM learns which channels are *useful* for the current task.\n",
    "* SAM (later) learns *where* these features matter spatially.\n",
    "\n",
    "---\n",
    "\n",
    "#### . Complete CBAM Flow\n",
    "\n",
    "The full process is:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "F' &= M_c(F) \\\n",
    "F'' &= M_s(F') \\\n",
    "\\text{Output} &= F''\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Order matters**:\n",
    "Channel attention first, spatial attention second.\n",
    "\n",
    "---\n",
    "\n",
    "#### . Visualization\n",
    "\n",
    "| Step                  | Input   | Output  | Focus                    |\n",
    "| --------------------- | ------- | ------- | ------------------------ |\n",
    "| **Channel Attention** | [C×H×W] | [C×1×1] | **What** channels matter |\n",
    "| **Spatial Attention** | [C×H×W] | [1×H×W] | **Where** they matter    |\n",
    "\n",
    "Together, they make the model focus on both *what* and *where* to look.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. PyTorch Overview\n",
    "\n",
    "```python\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(channels, reduction)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_attention(x)  # what\n",
    "        x = self.spatial_attention(x)  # where\n",
    "        return x\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### . Summary Table\n",
    "\n",
    "| Module  | Input Shape | Output Shape | Mechanism           | Focus   | Example Formula                                   |\n",
    "| ------- | ----------- | ------------ | ------------------- | ------- | ------------------------------------------------- |\n",
    "| **CAM** | [C, H, W]   | [C, 1, 1]    | Avg/Max Pool + MLP  | *What*  | $A_c = \\sigma(MLP(AvgPool(F)) + MLP(MaxPool(F)))$ |\n",
    "| **SAM** | [C, H, W]   | [1, H, W]    | Avg/Max Pool + Conv | *Where* | $A_s = \\sigma(Conv2D([AvgPool(F); MaxPool(F)]))$  |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8687d376-55a6-4f33-8c50-011307cd0bd9",
   "metadata": {},
   "source": [
    "#### Channel Attention Module\n",
    "<img src=\"images/channel_attention_module.png\" width=\"70%\" height=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477f3b5-9f0e-43ce-9703-2debf84827be",
   "metadata": {},
   "source": [
    "## **7. Channel Attention Module (CAM) Numerical Example**\n",
    "\n",
    "Input Feature Map:\n",
    "\n",
    "$$\n",
    "F_1 =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}, \\quad\n",
    "F_2 =\n",
    "\\begin{bmatrix}\n",
    "2 & 0 \\\\\n",
    "1 & 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So $F$ has shape $[C, H, W] = [2, 2, 2]$.\n",
    "\n",
    "---\n",
    "\n",
    "#### **7.1. Global Pooling (squeeze spatial info)**\n",
    "\n",
    "We apply **Average Pooling** and **Max Pooling** over the spatial dimensions $(H, W)$ **independently for each channel**.\n",
    "\n",
    "**Average Pooling**\n",
    "\n",
    "Compute the mean per channel:\n",
    "\n",
    "| Channel | Formula     | Result |\n",
    "| ------- | ----------- | ------ |\n",
    "| 1       | (1+2+3+4)/4 | 2.5    |\n",
    "| 2       | (2+0+1+3)/4 | 1.5    |\n",
    "\n",
    "$$\n",
    "F_{\\text{avg}} =\n",
    "\\begin{bmatrix}\n",
    "2.5 \\\n",
    "1.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Max Pooling**\n",
    "\n",
    "Compute the max per channel:\n",
    "\n",
    "| Channel | Formula      | Result |\n",
    "| ------- | ------------ | ------ |\n",
    "| 1       | max(1,2,3,4) | 4      |\n",
    "| 2       | max(2,0,1,3) | 3      |\n",
    "\n",
    "$$\n",
    "F_{\\text{max}} =\n",
    "\\begin{bmatrix}\n",
    "4 \\\\\n",
    "3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **7.2. Shared MLP (two fully connected layers)**\n",
    "\n",
    "The MLP is shared for both pooled vectors.\n",
    "\n",
    "Let’s assume:\n",
    "\n",
    "* Number of channels $C = 2$\n",
    "* Reduction ratio $r = 1$ (to keep small numbers)\n",
    "* So, weights $W_0, W_1$ are both $2\\times2$ matrices.\n",
    "\n",
    "We’ll choose simple example weights:\n",
    "\n",
    "$$\n",
    "W_0 =\n",
    "\\begin{bmatrix}\n",
    "0.5 & 0.1 \\\\\n",
    "0.3 & 0.7\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "W_1 =\n",
    "\\begin{bmatrix}\n",
    "0.2 & 0.4 \\\\\n",
    "0.6 & 0.8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now process both pooled vectors.\n",
    "\n",
    "---\n",
    "\n",
    "#### **7.3 Average Path**\n",
    "\n",
    "First layer:\n",
    "$$\n",
    "z_1 = \\text{ReLU}(W_0 F_{\\text{avg}})\n",
    "$$\n",
    "\n",
    "Compute:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "W_0 F_{\\text{avg}} &=\n",
    "\\begin{bmatrix}\n",
    "0.5 & 0.1 \\\\\n",
    "0.3 & 0.7\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "2.5 \\\\\n",
    "1.5\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "(0.5 \\times 2.5 + 0.1 \\times 1.5) \\\\\n",
    "(0.3 \\times 2.5 + 0.7 \\times 1.5)\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1.4 \\\\\n",
    "2.2\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "After ReLU: same values (positive).\n",
    "\n",
    "Second layer:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "M_{\\text{avg}} &= W_1 z_1 \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "0.2 & 0.4 \\\\\n",
    "0.6 & 0.8\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1.4 \\\\\n",
    "2.2\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "(0.2 \\times 1.4 + 0.4 \\times 2.2) \\\\\n",
    "(0.6 \\times 1.4 + 0.8 \\times 2.2)\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1.48 \\\\\n",
    "2.92\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **7.4. Max Path**\n",
    "\n",
    "First layer:\n",
    "$$\n",
    "z_2 = \\text{ReLU}(W_0 F_{\\text{max}})\n",
    "$$\n",
    "\n",
    "Compute:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "W_0 F_{\\text{max}} &=\n",
    "\\begin{bmatrix}\n",
    "0.5 & 0.1 \\\\\n",
    "0.3 & 0.7\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "4 \\\\\n",
    "3\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "(0.5 \\times 4 + 0.1 \\times 3) \\\\\n",
    "(0.3 \\times 4 + 0.7 \\times 3)\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "2.3 \\\\\n",
    "3.3\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Second layer:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "M_{\\text{max}} &= W_1 z_2 \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "0.2 & 0.4 \\\\\n",
    "0.6 & 0.8\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "2.3 \\\\\n",
    "3.3\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "(0.2 \\times 2.3 + 0.4 \\times 3.3) \\\\\n",
    "(0.6 \\times 2.3 + 0.8 \\times 3.3)\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1.98 \\\\\n",
    "4.20\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **7.5. Combine and Apply Sigmoid**\n",
    "\n",
    "Add both paths:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "M_{\\text{avg}} + M_{\\text{max}} &=\n",
    "\\begin{bmatrix}\n",
    "1.48 + 1.96 \\\\\n",
    "2.92 + 4.20\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "3.44 \\\\\n",
    "7.12\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Apply sigmoid:\n",
    "\n",
    "| Channel | Input | Sigmoid Output |\n",
    "| ------- | ----- | -------------- |\n",
    "| 1       | 3.44  | 0.969          |\n",
    "| 2       | 7.12  | 0.999          |\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "A_c =\n",
    "\\begin{bmatrix}\n",
    "0.969 \\\\\n",
    "0.999\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **7.6. Apply Channel Attention**\n",
    "\n",
    "Now multiply each channel by its attention weight:\n",
    "\n",
    "$$\n",
    "F'_1 = 0.969 × F_1, \\quad F'_2 = 0.999 × F_2\n",
    "$$\n",
    "\n",
    "Compute:\n",
    "\n",
    "$$\n",
    "F'_1 =\n",
    "\\begin{bmatrix}\n",
    "0.969 & 1.938 \\\\\n",
    "2.907 & 3.876\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "F'_2 =\n",
    "\\begin{bmatrix}\n",
    "1.998 & 0.000 \\\\\n",
    "0.999 & 2.997\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **7.7. Interpretation**\n",
    "\n",
    "* **Channel 1 weight = 0.969**\n",
    "* **Channel 2 weight = 0.999**\n",
    "\n",
    "→ The module slightly prefers **Channel 2** (which may contain more discriminative features in this toy example).\n",
    "Each channel’s spatial structure remains the same, only *scaled*.\n",
    "\n",
    "---\n",
    "\n",
    "#### **7.8. Combined CAM Effect with SAM**\n",
    "\n",
    "If you later pass this through the **Spatial Attention Module (SAM)** (from before), you’ll get:\n",
    "\n",
    "$$\n",
    "F'' = M_s(F') = A_s \\odot F'\n",
    "$$\n",
    "\n",
    "meaning:\n",
    "\n",
    "* **CAM**: emphasizes *which features* to keep\n",
    "* **SAM**: emphasizes *where* to look\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd8ef0-ccd6-4c92-b9ba-f31725a5e400",
   "metadata": {},
   "source": [
    "## **8. Complete CBAM: SAM + CAM Numerical Example**\n",
    "\n",
    "\n",
    "CBAM applies attention **sequentially**:\n",
    "\n",
    "$$\n",
    "F' = M_c(F) \\quad \\text{(Channel Attention)} \n",
    "$$\n",
    "\n",
    "$$\n",
    "F'' = M_s(F') \\quad \\text{(Spatial Attention)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **8.1. Inputs Recap**\n",
    "\n",
    "Initial feature maps:\n",
    "\n",
    "$$\n",
    "F_1 =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}, \\quad\n",
    "F_2 =\n",
    "\\begin{bmatrix}\n",
    "2 & 0 \\\\\n",
    "1 & 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **8.2. Channel Attention Output (from CAM example)**\n",
    "\n",
    "Channel attention weights:\n",
    "\n",
    "$$\n",
    "A_c =\n",
    "\\begin{bmatrix}\n",
    "0.969 \\\\\n",
    "0.999\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Applying them to each channel gives:\n",
    "\n",
    "$$\n",
    "F'_1 =\n",
    "\\begin{bmatrix}\n",
    "0.969 & 1.938 \\\\\n",
    "2.907 & 3.876\n",
    "\\end{bmatrix}, \\quad\n",
    "F'_2 =\n",
    "\\begin{bmatrix}\n",
    "1.998 & 0.000 \\\\\n",
    "0.999 & 2.997\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **8.3. Spatial Attention Map (from SAM example)**\n",
    "\n",
    "We had computed earlier:\n",
    "\n",
    "$$\n",
    "A_s =\n",
    "\\begin{bmatrix}\n",
    "0.85 & 0.82 \\\\\n",
    "0.92 & 0.98\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **8.4. Apply Spatial Attention**\n",
    "\n",
    "Multiply each spatial element by its attention weight (broadcasted over channels):\n",
    "\n",
    "**Channel 1:**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "F''_1 &= F'_1 \\odot A_s \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "0.969 \\times 0.85 & 1.938 \\times 0.82 \\\\\n",
    "2.907 \\times 0.92 & 3.876 \\times 0.98\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "0.824 & 1.589 \\\\\n",
    "2.675 & 3.799\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Channel 2:**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "F''_2 &= F'_2 \\odot A_s \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1.998 \\times 0.85 & 0.000 \\times 0.82 \\\\\n",
    "0.999 \\times 0.92 & 2.997 \\times 0.98\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1.698 & 0.000 \\\\\n",
    "0.919 & 2.937\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **8.5. Final CBAM Output**\n",
    "\n",
    "$$\n",
    "F'' =\n",
    "\\Bigg[\n",
    "\\begin{bmatrix}\n",
    "0.824 & 1.589 \\\\\n",
    "2.675 & 3.799\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "\\begin{bmatrix}\n",
    "1.698 & 0.000 \\\\\n",
    "0.919 & 2.937\n",
    "\\end{bmatrix}\n",
    "\\Bigg]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **8.6. Interpretation**\n",
    "\n",
    "| Step                        | Focus                       | Effect                         |\n",
    "| --------------------------- | --------------------------- | ------------------------------ |\n",
    "| **Channel Attention (CAM)** | *What* features matter      | Slightly boosts channel 2      |\n",
    "| **Spatial Attention (SAM)** | *Where* in each map matters | Emphasizes bottom-right region |\n",
    "\n",
    "Thus, after both attentions:\n",
    "\n",
    "* The **bottom-right** regions (high $A_s$ = 0.98) have the **strongest activations**.\n",
    "* **Channel 2** remains slightly stronger due to higher channel weight (0.999).\n",
    "* **Background regions** (e.g. top-left) are suppressed.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Final Summary**\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "F'' = M_s(M_c(F))\n",
    "}\n",
    "$$\n",
    "\n",
    "with numerically:\n",
    "\n",
    "$$\n",
    "A_c =\n",
    "\\begin{bmatrix}\n",
    "0.969 \\\\ 0.999\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "A_s =\n",
    "\\begin{bmatrix}\n",
    "0.85 & 0.82 \\\\ 0.92 & 0.98\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e42397-f5c8-4fc3-b474-84fac4340e84",
   "metadata": {},
   "source": [
    "## **9. Where and How CBAM Fits Inside a CNN**\n",
    "\n",
    "\n",
    "CBAM is a **plug-and-play attention module** — you insert it **after** a convolutional block to refine the feature maps spatially and across channels.\n",
    "\n",
    "It consists of two sub-modules applied sequentially:\n",
    "\n",
    "$$\n",
    "F' = M_s(M_c(F)) \\quad \\text{(Channel → Spatial)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **9.1. Where It Goes in a CNN**\n",
    "\n",
    "In the original CBAM paper (Sanghyun Woo et al., ECCV 2018), the authors insert CBAM **after each residual block** of a ResNet, just before the residual addition.\n",
    "\n",
    "So, for a residual block with input $x$:\n",
    "\n",
    "$$\n",
    "\\text{out} = \\text{ConvBlock}(x) \\\n",
    "\\text{out} = \\text{CBAM}(\\text{out}) \\\n",
    "\\text{out} = \\text{out} + x\n",
    "$$\n",
    "\n",
    "This means CBAM refines the features **before the skip connection adds them back**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **9.2. Example: Inside a ResNet Block**\n",
    "\n",
    "**Original Residual Block:**\n",
    "\n",
    "```\n",
    "x → Conv → BN → ReLU → Conv → BN → (add skip x)\n",
    "```\n",
    "\n",
    "**With CBAM:**\n",
    "\n",
    "```\n",
    "x → Conv → BN → ReLU → Conv → BN → CBAM → (add skip x)\n",
    "```\n",
    "\n",
    "✅ You can add CBAM to *each block*, or to only *selected stages* (to save computation).\n",
    "\n",
    "---\n",
    "\n",
    "#### **9.3. Inside the CBAM Block**\n",
    "\n",
    "The CBAM block itself is lightweight and small:\n",
    "\n",
    "```python\n",
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(CBAMBlock, self).__init__()\n",
    "        self.channel_att = ChannelAttention(channels)\n",
    "        self.spatial_att = SpatialAttention()\n",
    "    def forward(self, x):\n",
    "        x = self.channel_att(x)\n",
    "        x = self.spatial_att(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **9.4. Example in Architecture (ResNet with CBAM)**\n",
    "\n",
    "If we visualize the flow in a ResNet-50:\n",
    "\n",
    "| Stage   | Typical Layers              | CBAM Added After   |\n",
    "| ------- | --------------------------- | ------------------ |\n",
    "| Conv1   | 7×7 conv, BN, ReLU, MaxPool | Optional           |\n",
    "| Conv2_x | 3 residual blocks           | ✅ after each block |\n",
    "| Conv3_x | 4 residual blocks           | ✅ after each block |\n",
    "| Conv4_x | 6 residual blocks           | ✅ after each block |\n",
    "| Conv5_x | 3 residual blocks           | ✅ after each block |\n",
    "| FC      | AvgPool + Linear            | ✖ Not here         |\n",
    "\n",
    "So yes — we usually **repeat CBAM after every residual block**, but you can selectively apply it if speed matters.\n",
    "\n",
    "---\n",
    "\n",
    "#### **9.5. Other Architectures Where CBAM Is Used**\n",
    "\n",
    "| Model Type                                   | How CBAM Is Used                               | Purpose                                      |\n",
    "| -------------------------------------------- | ---------------------------------------------- | -------------------------------------------- |\n",
    "| **ResNet / ResNeXt / DenseNet**              | Added after each block                         | Improves classification & detection accuracy |\n",
    "| **U-Net / SegNet**                           | Added at encoder or decoder stages             | Improves segmentation precision              |\n",
    "| **YOLO / SSD (Detection)**                   | Added after feature extractors (e.g. backbone) | Helps localize and identify objects          |\n",
    "| **ViT / Swin Hybrid Models**                 | Applied to CNN stem before transformer         | Gives inductive spatial bias                 |\n",
    "| **Lightweight CNNs (MobileNet, ShuffleNet)** | Added only to last few layers                  | Minimal cost, large accuracy gain            |\n",
    "\n",
    "---\n",
    "\n",
    "#### **9.6. Why Not Put It Everywhere?**\n",
    "\n",
    "CBAM is lightweight but still adds small computational overhead:\n",
    "\n",
    "* Channel attention uses MLPs (2 FC layers).\n",
    "* Spatial attention adds one convolution.\n",
    "\n",
    "Hence:\n",
    "\n",
    "* For **small networks (e.g., MobileNet)**, use it **only in deeper layers**.\n",
    "* For **large ResNets**, you can afford to apply CBAM to every block.\n",
    "\n",
    "---\n",
    "\n",
    "#### **9.7. Effect in Practice**\n",
    "\n",
    "CBAM improves:\n",
    "\n",
    "* **Classification accuracy** (ImageNet, CIFAR, etc.)\n",
    "* **Localization and detection** (COCO, Pascal VOC)\n",
    "* **Segmentation boundary precision**\n",
    "\n",
    "Typical improvement:\n",
    "+1 – 3 % Top-1 accuracy with negligible extra FLOPs.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9093f42-d6a2-433d-94ce-eeecda513b61",
   "metadata": {},
   "source": [
    "## **10. CBAM and SENet**\n",
    "CBAM fully includes the functionality of SENet — and then extends it.\n",
    "\n",
    "**CBAM = SENet + spatial refinement**\n",
    "\n",
    "| Type                  | Input            | Output          | Focus        | Common Use            |\n",
    "| --------------------- | ---------------- | --------------- | ------------ | --------------------- |\n",
    "| Channel Attention     | Feature map      | Channel weights | What         | SENet, CBAM           |\n",
    "| **Spatial Attention** | Feature map      | Spatial mask    | **Where**    | CBAM, attention U-Net |\n",
    "| Self-Attention        | Flattened tokens | Weighted tokens | Where + What | Transformers          |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
