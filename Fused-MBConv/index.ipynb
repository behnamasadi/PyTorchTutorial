{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "522099d9-6923-4839-ab45-6aa8fa89c09c",
   "metadata": {},
   "source": [
    "## **Fused Mobile Inverted Bottleneck Convolution**\n",
    "\n",
    "**Fused-MBConv** (short for **Fused Mobile Inverted Bottleneck Convolution**) is a variant of the **MBConv** block used in **EfficientNetV2**, designed to make training faster and inference more efficient on modern accelerators (like GPUs and TPUs).\n",
    "\n",
    "Let’s unpack it step by step.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Background: MBConv (from EfficientNet / MobileNetV2)\n",
    "\n",
    "The original **MBConv** (Mobile Inverted Bottleneck Convolution) block follows this sequence:\n",
    "\n",
    "1. **Expand (1×1 conv)** – increases the number of channels\n",
    "   $$C_{in} \\rightarrow C_{in} \\times t$$\n",
    "   where (t) is the expansion factor.\n",
    "\n",
    "2. **Depthwise convolution (k×k)** – applies one convolution per channel\n",
    "   (preserves the number of channels).\n",
    "\n",
    "3. **Squeeze-and-Excitation (optional)** – channel attention mechanism.\n",
    "\n",
    "4. **Project (1×1 conv)** – reduces channels back to output dimension\n",
    "   $$C_{in} \\times t \\rightarrow C_{out}$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. The Problem\n",
    "\n",
    "While MBConv is *efficient* on mobile CPUs (because depthwise convs are cheap there), it performs *poorly on GPUs* due to **memory access overhead** and **non-fused operations** between the 1×1 and depthwise convs.\n",
    "\n",
    "So, **EfficientNetV2** introduces **Fused-MBConv** to speed up training and make it more GPU-friendly.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Fused-MBConv: The Idea\n",
    "\n",
    "In **Fused-MBConv**, the **expansion 1×1 conv** and the **depthwise k×k conv** are **merged (fused)** into a single **k×k convolution**.\n",
    "\n",
    "This single convolution both **expands** the channels and **extracts spatial features** in one step.\n",
    "\n",
    "### Block structure:\n",
    "\n",
    "| Stage | MBConv                             | Fused-MBConv                           |\n",
    "| ----- | ---------------------------------- | -------------------------------------- |\n",
    "| 1     | 1×1 conv (expand)                  | 3×3 conv (expand + spatial conv fused) |\n",
    "| 2     | Depthwise 3×3 conv                 | — (already fused)                      |\n",
    "| 3     | Squeeze-and-Excitation             | optional                               |\n",
    "| 4     | 1×1 conv (project)                 | 1×1 conv (project)                     |\n",
    "| 5     | Skip connection (if shape matches) | Skip connection (if shape matches)     |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Block Diagram\n",
    "\n",
    "```\n",
    "Input\n",
    " │\n",
    " ├── Conv3x3 + BN + SiLU   ← fused expand + depthwise\n",
    " │\n",
    " ├── (Optional SE)\n",
    " │\n",
    " ├── Conv1x1 + BN\n",
    " │\n",
    " └── Skip connection (if same shape)\n",
    "Output\n",
    "```\n",
    "\n",
    "By comparison, the classic MBConv had *two separate convolutions* before projection.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Mathematical View\n",
    "\n",
    "In MBConv:\n",
    "\n",
    "$$\n",
    "Y = P(\\text{DW}(E(X)))\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* (E) = 1×1 expansion conv\n",
    "* (\\text{DW}) = depthwise conv\n",
    "* (P) = 1×1 projection conv\n",
    "\n",
    "In Fused-MBConv, we replace (E) and (\\text{DW}) with a single fused conv (F):\n",
    "\n",
    "$$\n",
    "Y = P(F(X))\n",
    "$$\n",
    "\n",
    "where (F) is a k×k convolution that expands the channel dimension and captures spatial context.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. When Each Is Used\n",
    "\n",
    "* **Fused-MBConv** is used in **early layers** of EfficientNetV2\n",
    "  → low-resolution, small input → faster and GPU-optimized.\n",
    "\n",
    "* **MBConv** is used in **later layers**\n",
    "  → higher channels, smaller spatial size → depthwise conv becomes efficient again.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Performance Trade-off\n",
    "\n",
    "| Property         | MBConv          | Fused-MBConv                |\n",
    "| ---------------- | --------------- | --------------------------- |\n",
    "| Number of layers | More            | Fewer                       |\n",
    "| GPU speed        | Slower          | Faster                      |\n",
    "| Memory access    | High overhead   | Reduced                     |\n",
    "| FLOPs            | Slightly higher | Slightly higher, but faster |\n",
    "| Accuracy         | Similar         | Similar or slightly better  |\n",
    "\n",
    "---\n",
    "\n",
    "## 8. PyTorch Example\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FusedMBConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, expansion=4, kernel_size=3, stride=1, se_ratio=0.25):\n",
    "        super().__init__()\n",
    "        hidden_dim = in_ch * expansion\n",
    "        self.use_res_connect = (stride == 1 and in_ch == out_ch)\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv2d(in_ch, hidden_dim, kernel_size, stride, padding=kernel_size//2, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.SiLU(inplace=True)\n",
    "        ]\n",
    "\n",
    "        # optional Squeeze-Excitation (not always used)\n",
    "        if se_ratio is not None and se_ratio > 0:\n",
    "            layers += [\n",
    "                nn.AdaptiveAvgPool2d(1),\n",
    "                nn.Conv2d(hidden_dim, int(hidden_dim * se_ratio), 1),\n",
    "                nn.SiLU(inplace=True),\n",
    "                nn.Conv2d(int(hidden_dim * se_ratio), hidden_dim, 1),\n",
    "                nn.Sigmoid()\n",
    "            ]\n",
    "\n",
    "        layers += [\n",
    "            nn.Conv2d(hidden_dim, out_ch, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        ]\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        if self.use_res_connect:\n",
    "            out = out + x\n",
    "        return out\n",
    "\n",
    "x = torch.randn(1, 24, 56, 56)\n",
    "block = FusedMBConv(24, 24, expansion=4)\n",
    "print(block(x).shape)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "torch.Size([1, 24, 56, 56])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Summary\n",
    "\n",
    "| Concept           | Description                                                     |\n",
    "| ----------------- | --------------------------------------------------------------- |\n",
    "| **Origin**        | Introduced in EfficientNetV2                                    |\n",
    "| **Motivation**    | Improve GPU training speed by fusing expansion + depthwise conv |\n",
    "| **Fusion**        | Replace 1×1 + 3×3 with a single 3×3 convolution                 |\n",
    "| **Used in**       | Early stages (large feature maps)                               |\n",
    "| **Advantages**    | Faster, more memory-efficient on modern accelerators            |\n",
    "| **Disadvantages** | Slightly higher FLOPs, less efficient on CPU/mobile             |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to show a **visual comparison diagram** between MBConv and Fused-MBConv with arrows showing feature maps and channel changes?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
