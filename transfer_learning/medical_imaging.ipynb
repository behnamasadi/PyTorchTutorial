{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b424c77-386b-4bb0-8e9b-cc9f41ec7acf",
   "metadata": {},
   "source": [
    "Below is a **clean, complete, and practical** overview of the **most commonly used architectures in medical imaging** (classification, segmentation, detection), including:\n",
    "\n",
    "* typical backbone choices\n",
    "* the **most common head replacements** used in medical DL\n",
    "* recommended **training policies**\n",
    "* domain-shift strategies\n",
    "* grayscale handling\n",
    "* regularization & augmentations\n",
    "\n",
    "This is exactly the knowledge you need when designing medical models with pretrained backbones (ResNet, EfficientNet, ViT, Swin, PVT…).\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Medical Image **Classification**\n",
    "\n",
    "Used for: X-ray classification, CT slice categorization, MRI plane prediction, ultrasound pathology detection, dermatology classification.\n",
    "\n",
    "### **Most common backbones**\n",
    "\n",
    "* EfficientNet-B0/B1/B3\n",
    "* ResNet-50/101\n",
    "* DenseNet-121/169 (very common in hospitals)\n",
    "* ViT-B/16 or DeiT-B\n",
    "* Swin-T, Swin-S\n",
    "* ConvNeXt-T/S\n",
    "\n",
    "### **Most common head replacement**\n",
    "\n",
    "A **2-layer MLP head** with dropout:\n",
    "\n",
    "```\n",
    "Dropout(p=0.3)\n",
    "Linear(backbone_dim → 512)\n",
    "ReLU\n",
    "Dropout(p=0.3)\n",
    "Linear(512 → num_classes)\n",
    "```\n",
    "\n",
    "Example dimensions:\n",
    "\n",
    "* EfficientNet-B0: 1280\n",
    "* ResNet-50: 2048\n",
    "* ViT-B: 768\n",
    "* Swin-T: 768\n",
    "\n",
    "### **Why this head?**\n",
    "\n",
    "* acts as domain adapter\n",
    "* prevents overfitting\n",
    "* small enough to be safe for tiny datasets\n",
    "\n",
    "### **Training policy**\n",
    "\n",
    "The most standard policy in medical imaging:\n",
    "\n",
    "#### **Stage 1 — Freeze backbone**\n",
    "\n",
    "```\n",
    "freeze(backbone)\n",
    "train classifier head only\n",
    "epochs: 3–10\n",
    "lr: 1e-3 or 1e-4\n",
    "```\n",
    "\n",
    "#### **Stage 2 — Unfreeze entire backbone**\n",
    "\n",
    "```\n",
    "unfreeze(backbone)\n",
    "train end-to-end\n",
    "epochs: 10–50\n",
    "lr: 1e-5 or 3e-5\n",
    "schedule: cosine or ReduceLROnPlateau\n",
    "```\n",
    "\n",
    "This is the universal \"medical fine-tuning\" recipe.\n",
    "\n",
    "### **Grayscale handling**\n",
    "\n",
    "Most common approach:\n",
    "\n",
    "```\n",
    "repeat grayscale → 3 channels\n",
    "```\n",
    "\n",
    "Works well with ImageNet pretrained CNNs and ViTs.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Medical **Segmentation**\n",
    "\n",
    "Tasks: tumor segmentation, organ segmentation, vessel extraction, lesion boundary.\n",
    "\n",
    "### **Most common architectures**\n",
    "\n",
    "#### **A. U-Net**\n",
    "\n",
    "The absolute standard.\n",
    "Variants:\n",
    "\n",
    "* U-Net\n",
    "* U-Net++\n",
    "* Attention U-Net\n",
    "* Residual U-Net\n",
    "\n",
    "Heads:\n",
    "\n",
    "```\n",
    "Conv → BN → ReLU → Conv → Sigmoid/Softmax\n",
    "```\n",
    "\n",
    "#### **B. SegFormer (very popular now)**\n",
    "\n",
    "Backbone: MiT-B0/B1/B2\n",
    "\n",
    "Head:\n",
    "\n",
    "```\n",
    "MLP “SegFormer head”:\n",
    "    • project multi-scale features\n",
    "    • concat\n",
    "    • upsample\n",
    "    • linear classifier on fused features\n",
    "```\n",
    "\n",
    "#### **C. Swin-UNet**\n",
    "\n",
    "Encoder: Swin Transformer\n",
    "Decoder: U-Net-style (skip connections, patch merging, patch expanding)\n",
    "\n",
    "Head:\n",
    "\n",
    "```\n",
    "Conv2d(embedding_dim → num_classes, kernel=1)\n",
    "```\n",
    "\n",
    "#### **D. nnU-Net (winner of 95% competitions)**\n",
    "\n",
    "Automatically configures:\n",
    "\n",
    "* UNet depth\n",
    "* patch size\n",
    "* normalization\n",
    "* optimizer\n",
    "* augmentations\n",
    "\n",
    "### **Training policy**\n",
    "\n",
    "* always full fine-tuning (never freeze)\n",
    "* optimizer: AdamW\n",
    "* lr ~ 1e-4\n",
    "* batch size small (1–4)\n",
    "* epochs 300–1000 for 3D, 100–250 for 2D\n",
    "* heavy augmentations (rotation, elastic, gamma, contrast, blur)\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Medical **Detection / Localization**\n",
    "\n",
    "Used for: nodule detection, polyp detection, mass detection in mammography.\n",
    "\n",
    "### **Most common architectures**\n",
    "\n",
    "* Faster R-CNN (backbone: ResNet-50)\n",
    "* RetinaNet\n",
    "* YOLOv5/YOLOv8 (very common now in hospitals)\n",
    "* Vision Transformer detectors (rare but growing: ViTDet, SwinDet)\n",
    "\n",
    "### **Common head replacement**\n",
    "\n",
    "Typical classifiers for 2D detection:\n",
    "\n",
    "```\n",
    "Conv → ReLU → Conv → class_scores\n",
    "Conv → ReLU → Conv → box_regression\n",
    "```\n",
    "\n",
    "YOLO style uses:\n",
    "\n",
    "```\n",
    "Conv → Conv → (class + box)\n",
    "```\n",
    "\n",
    "### **Training policy**\n",
    "\n",
    "* start from COCO-pretrained weights\n",
    "* freeze for ~1 epoch (optional)\n",
    "* then unfreeze all\n",
    "* lr: 1e-4 to 1e-3\n",
    "* augmentation (mosaic, scale, flip)\n",
    "* 100–300 epochs\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Medical **3D classification / 3D segmentation**\n",
    "\n",
    "Used for CT/MRI volumes.\n",
    "\n",
    "### **Most common models**\n",
    "\n",
    "* 3D U-Net\n",
    "* 3D ResNet\n",
    "* MONAI DenseNet-121\n",
    "* nnU-Net 3D full resolution\n",
    "* Swin-UNETR (3D transformer-based)\n",
    "\n",
    "### **Heads**\n",
    "\n",
    "Classification head:\n",
    "\n",
    "```\n",
    "Adaptive global pool 3D\n",
    "Linear(512 → num_classes)\n",
    "```\n",
    "\n",
    "Segmentation head:\n",
    "\n",
    "```\n",
    "Conv3d → BN → ReLU → Conv3d → Softmax\n",
    "```\n",
    "\n",
    "### **Training policy**\n",
    "\n",
    "* no freezing (always end-to-end)\n",
    "* 3D patching (64³, 96³, 128³)\n",
    "* lr: 2e-4\n",
    "* epochs: 500–1500\n",
    "* lots of augmentations\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Medical **Self-Supervised Pretraining** (very common now)\n",
    "\n",
    "### Most common SSL methods in medical imaging:\n",
    "\n",
    "* SimCLR\n",
    "* BYOL\n",
    "* DINO\n",
    "* Masked Autoencoders (MAE)\n",
    "* Model Genesis\n",
    "* Swin MAE (very strong on 3D CT)\n",
    "\n",
    "### Typical head during SSL:\n",
    "\n",
    "Projection head (MLP):\n",
    "\n",
    "```\n",
    "Linear(d → d)\n",
    "ReLU\n",
    "Linear(d → projection_dim)\n",
    "```\n",
    "\n",
    "Head is thrown away after SSL; backbone is fine-tuned for classification/segmentation.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. What heads are used for **ViT / Swin / DeiT** in medical imaging?\n",
    "\n",
    "### Classification:\n",
    "\n",
    "```\n",
    "MLP head:\n",
    "  Linear(dim → 512)\n",
    "  GELU\n",
    "  Dropout\n",
    "  Linear(512 → num_classes)\n",
    "```\n",
    "\n",
    "### Segmentation:\n",
    "\n",
    "Use:\n",
    "\n",
    "* SegFormer head\n",
    "* UNETR head\n",
    "* Swin-UNETR head\n",
    "\n",
    "These fuse multi-scale transformer features.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Common training tricks in medical imaging\n",
    "\n",
    "### **Loss functions**\n",
    "\n",
    "Classification:\n",
    "\n",
    "* BCEWithLogitsLoss\n",
    "* Focal loss\n",
    "* Weighted cross entropy\n",
    "\n",
    "Segmentation:\n",
    "\n",
    "* Dice loss\n",
    "* Cross entropy\n",
    "* Combo: 0.5·Dice + 0.5·CE\n",
    "* Tversky loss (for imbalanced lesions)\n",
    "\n",
    "### **Optimizers**\n",
    "\n",
    "* AdamW (always)\n",
    "* sometimes Adamax for medical datasets\n",
    "* weight decay: 1e-4\n",
    "\n",
    "### **Augmentations**\n",
    "\n",
    "* slight rotation (<15°)\n",
    "* horizontal/vertical flips\n",
    "* CLAHE\n",
    "* Gaussian blur\n",
    "* gamma correction\n",
    "* brightness/contrast adjustments\n",
    "* elastic deformation\n",
    "\n",
    "### **Normalization**\n",
    "\n",
    "* per-image z-score\n",
    "* or per-dataset mean/std\n",
    "\n",
    "### **Training flow**\n",
    "\n",
    "Most common:\n",
    "\n",
    "```\n",
    "1) Start with ImageNet-pretrained CNN/Transformer\n",
    "2) Replace head with small MLP + dropout\n",
    "3) Freeze backbone for warm-up\n",
    "4) Unfreeze everything → train with small LR\n",
    "5) Use class weights or focal loss if imbalance\n",
    "6) Use medical augmentations (contrast, gamma)\n",
    "7) Reduce LR when performance plateaus\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Ready-to-use templates (summary)\n",
    "\n",
    "---\n",
    "\n",
    "## **A. Classification (most common template)**\n",
    "\n",
    "```\n",
    "EfficientNet-B0 backbone\n",
    "    ↓\n",
    "GlobalAvgPool\n",
    "    ↓\n",
    "Dropout(0.3)\n",
    "Linear(1280→512) + ReLU\n",
    "Dropout(0.25)\n",
    "Linear(512→C)\n",
    "```\n",
    "\n",
    "Training:\n",
    "\n",
    "* freeze 5–10 epochs\n",
    "* unfreeze 20–50 epochs\n",
    "* LR: 1e-3 → 1e-5\n",
    "* loss: focal or weighted CE\n",
    "\n",
    "---\n",
    "\n",
    "## **B. Segmentation (most common template)**\n",
    "\n",
    "```\n",
    "SegFormer-B1 backbone (MiT-B1)\n",
    "    ↓\n",
    "SegFormer Head (MLP + upsampling)\n",
    "    ↓\n",
    "Conv2d → Softmax\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```\n",
    "UNet encoder: ResNet-34\n",
    "Decoder: U-Net\n",
    "Head: Conv → Conv → Sigmoid/Softmax\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **C. Detection template (medical YOLO)**\n",
    "\n",
    "```\n",
    "YOLOv8n/s backbone\n",
    "Detect head (Conv → Conv → class+box)\n",
    "```\n",
    "\n",
    "Training:\n",
    "\n",
    "* full fine-tuning\n",
    "* lr: 1e-3\n",
    "* epochs: 200\n",
    "\n",
    "---\n",
    "\n",
    "## **D. 3D segmentation template**\n",
    "\n",
    "```\n",
    "Swin-UNETR\n",
    "ViT encoder (3D patches)\n",
    "3D UNet-style decoder\n",
    "Conv3d → Softmax\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# If you want\n",
    "\n",
    "I can also prepare:\n",
    "\n",
    "* a **full unified table** for classification/segmentation/detection\n",
    "* PyTorch templates for each\n",
    "* or recommendations tailored to your dataset (CT, MRI, X-ray, etc.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
