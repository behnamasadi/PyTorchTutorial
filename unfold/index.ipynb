{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c535a6-38c8-4cd3-a6fe-c3679c80d742",
   "metadata": {},
   "source": [
    "## 1. Motivation\n",
    "\n",
    "In convolutional neural networks (CNNs), each convolution can be thought of as:\n",
    "\n",
    "* Taking **local patches** (receptive fields) from the input,\n",
    "* Flattening them,\n",
    "* Multiplying by the filter weights (matrix multiplication),\n",
    "* Then reshaping the result back to the output feature map.\n",
    "\n",
    "The operations **`torch.nn.Unfold`** and **`torch.nn.Fold`** allow you to explicitly perform those “patch extraction” and “reconstruction” steps.\n",
    "\n",
    "✅ In short:\n",
    "\n",
    "* `unfold` = **extract patches**\n",
    "* `fold` = **reconstruct image from patches**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. `torch.nn.Unfold`\n",
    "\n",
    "### Concept\n",
    "\n",
    "`Unfold` takes a 4D tensor\n",
    "$$x \\in \\mathbb{R}^{(B, C, H, W)}$$\n",
    "and returns a 3D tensor of **flattened sliding local blocks**.\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.arange(1, 17, dtype=torch.float32).view(1, 1, 4, 4)\n",
    "print(x)\n",
    "```\n",
    "\n",
    "```\n",
    "[[[[ 1,  2,  3,  4],\n",
    "   [ 5,  6,  7,  8],\n",
    "   [ 9, 10, 11, 12],\n",
    "   [13, 14, 15, 16]]]]\n",
    "```\n",
    "\n",
    "Let’s extract 2×2 patches with stride 2:\n",
    "\n",
    "```python\n",
    "unfold = nn.Unfold(kernel_size=(2, 2), stride=2)\n",
    "patches = unfold(x)\n",
    "print(patches.shape)\n",
    "print(patches)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "torch.Size([1, 4, 4])\n",
    "tensor([[[ 1.,  3.,  9., 11.],\n",
    "         [ 2.,  4., 10., 12.],\n",
    "         [ 5.,  7., 13., 15.],\n",
    "         [ 6.,  8., 14., 16.]]])\n",
    "```\n",
    "\n",
    "Let’s interpret this:\n",
    "\n",
    "* There are **4 patches** (since 4 windows fit in 4×4 with stride 2).\n",
    "* Each patch has **4 elements** (2×2 = 4).\n",
    "* The shape `[B, C×kernel_height×kernel_width, num_patches]` = `[1, 4, 4]`.\n",
    "\n",
    "If you transpose:\n",
    "\n",
    "```python\n",
    "patches_T = patches.squeeze(0).T\n",
    "print(patches_T)\n",
    "```\n",
    "\n",
    "you’ll see each row = flattened patch:\n",
    "\n",
    "```\n",
    "[[ 1,  2,  5,  6],\n",
    " [ 3,  4,  7,  8],\n",
    " [ 9, 10, 13, 14],\n",
    " [11, 12, 15, 16]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. `torch.nn.Fold`\n",
    "\n",
    "### Concept\n",
    "\n",
    "`Fold` is the *inverse* of `Unfold`:\n",
    "It reconstructs the original image (or feature map) from patches.\n",
    "\n",
    "```python\n",
    "fold = nn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=2)\n",
    "reconstructed = fold(patches)\n",
    "print(reconstructed)\n",
    "```\n",
    "\n",
    "Result:\n",
    "\n",
    "```\n",
    "tensor([[[[ 1.,  2.,  3.,  4.],\n",
    "          [ 5.,  6.,  7.,  8.],\n",
    "          [ 9., 10., 11., 12.],\n",
    "          [13., 14., 15., 16.]]]])\n",
    "```\n",
    "\n",
    "✅ Perfect reconstruction, since the patches don’t overlap.\n",
    "\n",
    "If there **is overlap** (e.g., stride < kernel_size), overlapping pixels will be **summed** during `fold`.\n",
    "\n",
    "To fix that, you can normalize by the overlap count (explained below).\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Handling Overlaps (stride < kernel_size)\n",
    "\n",
    "When patches overlap, `Fold` adds contributions together.\n",
    "You can compute a **normalization mask** like this:\n",
    "\n",
    "```python\n",
    "ones = torch.ones_like(x)\n",
    "patches_ones = unfold(ones)\n",
    "reconstruction_mask = fold(patches_ones)\n",
    "reconstructed /= reconstruction_mask\n",
    "```\n",
    "\n",
    "This ensures that overlapping regions are averaged correctly.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Matrix Multiplication View of Convolution\n",
    "\n",
    "CNN convolution can be written as matrix multiplication:\n",
    "\n",
    "$$\n",
    "Y = W \\times X_{\\text{unfolded}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* ( X_{\\text{unfolded}} ) = patches extracted by `Unfold` → shape `[B, C×k_h×k_w, L]`\n",
    "* ( W ) = filter weights → shape `[out_channels, C×k_h×k_w]`\n",
    "* Result ( Y ) = `[B, out_channels, L]` → reshaped back using `Fold`\n",
    "\n",
    "So, convolution is basically:\n",
    "\n",
    "```python\n",
    "Y = W @ unfold(X)\n",
    "```\n",
    "\n",
    "and then reshape.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Typical Use Cases\n",
    "\n",
    "✅ **ViT or Patch-based Models**\n",
    "`unfold` is used to create patch tokens:\n",
    "\n",
    "```python\n",
    "patches = x.unfold(2, patch_size, patch_size).unfold(3, patch_size, patch_size)\n",
    "patches = patches.contiguous().view(B, C, -1, patch_size*patch_size)\n",
    "```\n",
    "\n",
    "✅ **Image Reconstruction / Super-resolution**\n",
    "`fold` helps reassemble overlapping patches from the processed output.\n",
    "\n",
    "✅ **Implementing Custom Convolutions**\n",
    "You can explicitly compute convolution using `unfold`, matrix multiplication, and `fold`.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Summary Table\n",
    "\n",
    "| Operation   | Purpose                  | Input Shape       | Output Shape      | Example              |\n",
    "| ----------- | ------------------------ | ----------------- | ----------------- | -------------------- |\n",
    "| `nn.Unfold` | Extract local patches    | `[B, C, H, W]`    | `[B, C*kH*kW, L]` | Feature extraction   |\n",
    "| `nn.Fold`   | Reconstruct from patches | `[B, C*kH*kW, L]` | `[B, C, H, W]`    | Image reconstruction |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to show a **numerical example of `unfold` + weight multiplication + `fold` to simulate a 2D convolution manually** (so you see exactly how it matches PyTorch’s `nn.Conv2d`)?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
