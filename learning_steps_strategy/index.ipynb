{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mighty-appliance",
   "metadata": {},
   "source": [
    "# Pre-process Data\n",
    "\n",
    "Normalize the data (Z-Score Normalization)\n",
    "Turn the data into zero mean, and std=1\n",
    "you should know mean and std of every channel in advance, this could be done only if you iterate over all images\n",
    "i.e. CIFAR10\n",
    "r_mean, g_mean, b_mean, r_std, b_std, g_std=0.49139968, 0.48215841, 0.44653091, 0.24703223, 0.24348513, 0.26158784\n",
    "\n",
    "transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                torchvision.transforms.Normalize(\n",
    "                                                    (r_mean, g_mean, b_mean),\n",
    "                                                    (r_std, b_std, g_std)  ) ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-chase",
   "metadata": {},
   "source": [
    "# Choose Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-peeing",
   "metadata": {},
   "source": [
    "# Weight initialization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-divide",
   "metadata": {},
   "source": [
    "## xavier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-police",
   "metadata": {},
   "source": [
    "## kaiming-he"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-seating",
   "metadata": {},
   "source": [
    "# Batch Normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-keeping",
   "metadata": {},
   "source": [
    "# Drop out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-creation",
   "metadata": {},
   "source": [
    "# Eval\n",
    "`model.eval()` is a kind of switch for some specific layers/parts of the model (i.e. Dropouts Layers, BatchNorm Layers etc) that behave  differently during training and inference (evaluating) time.\n",
    "\n",
    "You need to turn off them during model evaluation, and .eval() will do it for you.\n",
    "In addition, the common practice for evaluating/validation is using torch.no_grad() in pair with model.eval() to turn off gradients computation:\n",
    "\n",
    "Evaluate model:\n",
    "model.eval()\n",
    "```\n",
    "with torch.no_grad():\n",
    "    ...\n",
    "    out_data = model(data)\n",
    "````\n",
    "Training step:\n",
    "`\n",
    "model.train()\n",
    "`\n",
    "Refs: [1](https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-communications",
   "metadata": {},
   "source": [
    "# Training Steps\n",
    "1. Check if the loss is reasonable\n",
    "2. Disable regularization, do a forward and check the loss\n",
    "3. Crank up the regularization and the loss should goes up,\n",
    "4. Feed a small portion of data, turn off regularization, it should easily overfit  and loss goes to zero, train accuracy =1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-selection",
   "metadata": {},
   "source": [
    "# General Tips\n",
    "1. donâ€™t use autograd of not necessary (use with torch.no_grad() if possible)\n",
    "2. only push tensors to GPU, if they are actually needed\n",
    "3. try to avoid loops over tensor dimensions (slows things down)\n",
    "4. try to free graphs as soon as possible (use detach or item whenever you can) to avoid memory leaks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
