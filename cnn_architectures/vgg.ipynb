{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b3cc21-c0fb-4f49-93fb-adcf00a9d245",
   "metadata": {},
   "source": [
    "# VGG Networks\n",
    "\n",
    "(VGG-11/13/16/19), Simonyan & Zisserman (2014)\n",
    "\n",
    "## 1. Motivation\n",
    "\n",
    "Before VGG, many CNNs (e.g., AlexNet) used **large convolution kernels** such as\n",
    "$$11 \\times 11, \\quad 7 \\times 7, \\quad 5 \\times 5.$$\n",
    "\n",
    "The authors asked a simple question:\n",
    "\n",
    "**Can we replace large kernels with several small kernels and still capture the same receptive field, but with fewer parameters and more non-linearities?**\n",
    "\n",
    "For example:\n",
    "\n",
    "* One $5\\times 5$ convolution has receptive field $5\\times 5$.\n",
    "* Two consecutive $3\\times 3$ convolutions also give overall receptive field $5\\times 5$, because:\n",
    "  $$\n",
    "  3 + (3 - 1) = 5.\n",
    "  $$\n",
    "* But two $3\\times 3$ layers have **two nonlinearities (ReLU)** instead of one, and require **fewer parameters**.\n",
    "\n",
    "Therefore the core idea:\n",
    "\n",
    "**Stack many small $3\\times 3$ convolutions instead of using large kernels.\n",
    "This yields deeper networks, better feature extraction, and lower parameter cost per receptive field size.**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Architectural Principles\n",
    "\n",
    "VGG follows four simple rules:\n",
    "\n",
    "1. **Use only $3\\times 3$ convolutions**, stride (1), padding (1).\n",
    "2. **Double the number of channels** after each spatial downsampling.\n",
    "3. **Downsample only by max-pooling**, using $2\\times 2$, stride (2).\n",
    "4. At the end, use **3 fully-connected layers**.\n",
    "\n",
    "The architecture becomes extremely **uniform and clean**, which was one of the reasons VGG was so influential.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Architecture Overview\n",
    "\n",
    "The canonical **VGG-16** consists of 16 trainable layers (13 conv + 3 FC).\n",
    "\n",
    "### Stage 1\n",
    "\n",
    "Input: $224 \\times 224$\n",
    "\n",
    "1. Conv $3\\times 3$, 64\n",
    "2. Conv $3\\times 3$, 64\n",
    "3. MaxPool $2\\times 2$\n",
    "\n",
    "### Stage 2\n",
    "\n",
    "1. Conv $3\\times 3$, 128\n",
    "2. Conv $3\\times 3$, 128\n",
    "3. MaxPool $2\\times 2$\n",
    "\n",
    "### Stage 3\n",
    "\n",
    "1. Conv $3\\times 3$, 256\n",
    "2. Conv $3\\times 3$, 256\n",
    "3. Conv $3\\times 3$, 256\n",
    "4. MaxPool $2\\times 2$\n",
    "\n",
    "### Stage 4\n",
    "\n",
    "1. Conv $3\\times 3$, 512\n",
    "2. Conv $3\\times 3$, 512\n",
    "3. Conv $3\\times 3$, 512\n",
    "4. MaxPool $2\\times 2$\n",
    "\n",
    "### Stage 5\n",
    "\n",
    "1. Conv $3\\times 3$, 512\n",
    "2. Conv $3\\times 3$, 512\n",
    "3. Conv $3\\times 3$, 512\n",
    "4. MaxPool $2\\times 2$\n",
    "\n",
    "### Final Classifier\n",
    "\n",
    "Flatten →\n",
    "FC 4096 → ReLU\n",
    "FC 4096 → ReLU\n",
    "FC 1000 → softmax\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Why Multiple $3\\times 3$ Layers Help\n",
    "\n",
    "### 4.1 Receptive Field Growth\n",
    "\n",
    "Two stacked $3\\times 3$ convs produce an effective $5\\times 5$ receptive field:\n",
    "\n",
    "$$\n",
    "R = 3 + (3-1) = 5.\n",
    "$$\n",
    "\n",
    "Three stacked $3\\times 3$ convs → effective $7\\times 7$.\n",
    "\n",
    "### 4.2 Parameter Reduction\n",
    "\n",
    "Compare parameter counts:\n",
    "\n",
    "* One $5\\times 5$ conv:\n",
    "  $$\n",
    "  5 \\times 5 \\times C^2 = 25C^2.\n",
    "  $$\n",
    "\n",
    "* Two $3\\times 3$ convs:\n",
    "  $$\n",
    "  2 \\times (3 \\times 3 \\times C^2) = 18C^2.\n",
    "  $$\n",
    "\n",
    "This saves parameters while increasing depth.\n",
    "\n",
    "### 4.3 More Non-Linearity\n",
    "\n",
    "Each $3\\times 3$ comes with ReLU:\n",
    "\n",
    "$$\n",
    "x_{l+1} = \\text{ReLU}(W_l * x_l).\n",
    "$$\n",
    "\n",
    "Stacking many increases expressiveness.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Advantages of VGG\n",
    "\n",
    "* Very **simple and clean architecture**.\n",
    "* Demonstrated that **depth matters** for representation power.\n",
    "* Became a **feature extractor standard** for years.\n",
    "* Outputs at different layers are great for **style transfer, perceptual loss, feature pyramids**, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Weaknesses\n",
    "\n",
    "* **Huge number of parameters** (≈ 138M for VGG-16).\n",
    "* **Slow** and **memory-heavy** compared to modern CNNs.\n",
    "* No skip connections (unlike ResNet).\n",
    "* Poor for very deep scaling.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6105e0f5-88b6-4275-8e02-ecfee03fbd0d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "VGG-19 has the following pattern in the first block:\n",
    "\n",
    "**Input (RGB image)** → Conv(3 → 64) → Conv(64 → 64) → MaxPool\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Why do we have **two times 64 feature maps**?\n",
    "\n",
    "* The **first conv layer** takes the raw RGB channels (3) and learns 64 different filters, so the output has **64 feature maps**.\n",
    "* The **second conv layer** then applies 64 new filters, each seeing *all 64 previous feature maps* as input. This lets the network build richer, more abstract features without yet reducing spatial resolution.\n",
    "* So it’s not “repeating the same 64 maps,” it’s:\n",
    "\n",
    "  * First layer: detect low-level patterns (edges, colors, textures).\n",
    "  * Second layer: combine them into more complex local structures, still keeping 64 channels so the representational power is larger before downsampling.\n",
    "\n",
    "In other words, **keeping the same number of channels but stacking multiple convs increases depth of processing at the same spatial scale**. This improves expressive power.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. What happens to **H and W**?\n",
    "\n",
    "* Both conv layers in VGG use **3×3 kernels, stride = 1, padding = 1**.\n",
    "* Formula for conv output size:\n",
    "\n",
    "$$\n",
    "H_{out} = \\frac{H_{in} + 2p - k}{s} + 1\n",
    "$$\n",
    "\n",
    "With $k=3, s=1, p=1$, we get:\n",
    "\n",
    "$$\n",
    "H_{out} = \\frac{H_{in} + 2 - 3}{1} + 1 = H_{in}\n",
    "$$\n",
    "\n",
    "Same for $W$.\n",
    " So after each 3×3 conv, the spatial size **stays the same**. Only the **channel depth changes** (3 → 64 → 64).\n",
    "\n",
    "* After the two convs, a **max-pool (2×2, stride=2)** halves the H and W.\n",
    "\n",
    "  * Example: $224×224×3$ input →\n",
    "    Conv → $224×224×64$ →\n",
    "    Conv → $224×224×64$ →\n",
    "    MaxPool → $112×112×64$.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e661df-521b-4791-bb5e-673adcb2a11b",
   "metadata": {},
   "source": [
    "## 1. What does **kernel size** mean?\n",
    "\n",
    "* A **kernel (filter)** is the small sliding window used in a convolution.\n",
    "* Its size is written as $k \\times k$. Examples:\n",
    "\n",
    "  * **3×3 kernel** → looks at a 3×3 patch of the image (or feature map).\n",
    "  * **5×5 kernel** → looks at a 5×5 patch.\n",
    "  * **7×7 kernel** → looks at a 7×7 patch.\n",
    "\n",
    "The choice of kernel size affects the **receptive field**:\n",
    "\n",
    "* 3×3 sees very local details (edges, textures).\n",
    "* 5×5 sees slightly larger structures.\n",
    "* 7×7 sees broader patterns (but costs more parameters).\n",
    "\n",
    " VGG chose **3×3 kernels stacked multiple times** instead of using 5×5 or 7×7, because:\n",
    "\n",
    "* Two 3×3 layers = receptive field of 5×5, but with fewer parameters and more non-linearities (ReLU in between).\n",
    "* Three 3×3 layers = receptive field of 7×7, with even deeper representations.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. How many kernels do we need in the first conv layer of VGG?\n",
    "\n",
    "Input: **RGB image** → $H \\times W \\times 3$.\n",
    "First conv layer: 64 output channels.\n",
    "\n",
    "* Each output channel is produced by **one kernel**.\n",
    "* Since the input has 3 channels, each kernel must also have **3 channels**.\n",
    "* So the shape of one kernel is:\n",
    "\n",
    "  $$\n",
    "  3 \\times 3 \\times 3\n",
    "  $$\n",
    "* To get 64 output channels, we need **64 different kernels** of shape $3 \\times 3 \\times 3$.\n",
    "\n",
    "So total parameters in the first conv =\n",
    "\n",
    "$$\n",
    "(3 \\times 3 \\times 3) \\times 64 + 64 \\quad \\text{(bias terms)}\n",
    "$$\n",
    "\n",
    "\\= 1,792 parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. What about the **second conv layer (64→64)?**\n",
    "\n",
    "Now the input has 64 channels.\n",
    "We want 64 outputs again.\n",
    "\n",
    "* Each kernel is now: $3 \\times 3 \\times 64$.\n",
    "* Each output channel has one such kernel.\n",
    "* We need 64 kernels.\n",
    "\n",
    "So parameters =\n",
    "\n",
    "$$\n",
    "(3 \\times 3 \\times 64) \\times 64 + 64 = 36,928\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    " **Summary**:\n",
    "\n",
    "* Kernel size = spatial window (3×3, 5×5, 7×7).\n",
    "* In conv layers:\n",
    "\n",
    "  * 3 input channels → each kernel has 3 channels.\n",
    "  * 64 output channels → we need 64 kernels.\n",
    "* First VGG conv: 64 kernels of shape $3 \\times 3 \\times 3$.\n",
    "* Second VGG conv: 64 kernels of shape $3 \\times 3 \\times 64$.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe7cf2-a993-4e48-8f1d-66b28a16ff77",
   "metadata": {},
   "source": [
    "<img src='images/06_03.png'/>\n",
    "<img src='images/06_09.png'>\n",
    "<img src='images/3_channel_conv.gif'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
