{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c921d44-5a3d-4f39-b88e-df7ba9fe1b91",
   "metadata": {},
   "source": [
    "# 1. What problem Inception was solving\n",
    "\n",
    "Before Inception (2014), CNNs faced two major issues:\n",
    "\n",
    "1. **Large kernels (e.g., 5×5, 7×7) were expensive.**\n",
    "   The cost of a convolution is\n",
    "   $$\\text{FLOPs} \\propto k^2 \\cdot C_{\\text{in}} \\cdot C_{\\text{out}}$$\n",
    "   so larger kernels explode computation.\n",
    "\n",
    "2. **Choosing the right kernel size was hard.**\n",
    "   Should the network use 1×1, 3×3, 5×5? Each captures different receptive fields.\n",
    "\n",
    "3. **Simply stacking deeper layers caused overfitting** (too many parameters) and inefficiency.\n",
    "\n",
    "**Inception introduced a way to make the model simultaneously wide and deep, without exploding computation.**\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Core idea: multi-scale feature extraction **in parallel**\n",
    "\n",
    "Instead of choosing one kernel size, the **Inception module** runs several convolutions in parallel:\n",
    "\n",
    "* 1×1 conv\n",
    "* 3×3 conv\n",
    "* 5×5 conv\n",
    "* 3×3 max-pooling (with optional projection)\n",
    "\n",
    "and then concatenates all outputs along the channel dimension:\n",
    "\n",
    "$$\n",
    "\\text{Output} = \\text{Concat}\\left[\n",
    "\\text{Conv}_{1\\times1},;\n",
    "\\text{Conv}_{3\\times3},;\n",
    "\\text{Conv}_{5\\times5},;\n",
    "\\text{Pool}\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "This gives the network multiple receptive fields at the same layer, so it can detect:\n",
    "\n",
    "* fine details (1×1, 3×3)\n",
    "* larger patterns (5×5)\n",
    "* translation-robust features (pooling)\n",
    "\n",
    "All in one block.\n",
    "\n",
    "\n",
    "<img src=\"images/inception-with-reduction.png\" height=\"20%\"  weight=\"20%\" />\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# 3. The key innovation: **1×1 convolutions as bottlenecks**\n",
    "\n",
    "Direct 3×3 and 5×5 ops are expensive.\n",
    "Inception reduces their input channels using 1×1 convolutions:\n",
    "\n",
    "Example:\n",
    "\n",
    "* Instead of doing 5×5 on 256 channels → expensive\n",
    "* First reduce to, say, 32 channels with 1×1 → cheap\n",
    "* Then apply 5×5.\n",
    "\n",
    "This makes the module efficient.\n",
    "\n",
    "### Why 1×1 convolutions help:\n",
    "\n",
    "1. **Dimensionality reduction**\n",
    "   $$1\\times1: \\quad C_{\\text{in}} \\to C_{\\text{reduced}}$$\n",
    "\n",
    "2. **Nonlinearity injection**\n",
    "   Because each 1×1 conv is followed by ReLU.\n",
    "\n",
    "3. **Feature mixing across channels**\n",
    "   They are like per-pixel fully-connected layers.\n",
    "\n",
    "This was revolutionary at the time.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. High-level formula for an Inception block\n",
    "\n",
    "An Inception block output is:\n",
    "\n",
    "$$\n",
    "F(x)= \\left[\n",
    "f_{1\\times1}(x); |; f_{3\\times3}(g_{1\\times1}(x)); |;\n",
    "f_{5\\times5}(h_{1\\times1}(x)); |;\n",
    "p_{3\\times3}(x)\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Where\n",
    "\n",
    "* $g_{1\\times1}, h_{1\\times1}$ are bottlenecks\n",
    "* $f_{k\\times k}$ are convolution branches\n",
    "* $p_{3\\times3}$ is pooling\n",
    "* $|$ is channel concatenation.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Full GoogLeNet (Inception v1)\n",
    "\n",
    "* 22 layers deep\n",
    "* Only 5M parameters (very small compared to VGG’s 138M)\n",
    "* Won **ILSVRC 2014** classification challenge\n",
    "\n",
    "Key ideas:\n",
    "\n",
    "* Inception modules stacked repeatedly\n",
    "* Auxiliary classifiers (extra softmax heads at intermediate layers for gradient flow)\n",
    "* Use of global average pooling instead of huge FC layers\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Improvements: Inception v2, v3, v4\n",
    "\n",
    "### Inception v2 / v3\n",
    "\n",
    "* Replace 5×5 with two 3×3 → reduces cost\n",
    "  $$5\\times5 \\approx 3\\times3 + 3\\times3$$\n",
    "* Factorizing convolutions\n",
    "  Example:\n",
    "  $$3\\times3 \\to 1\\times3 \\text{ then } 3\\times1$$\n",
    "* Better regularization (label smoothing)\n",
    "* RMSProp optimizer\n",
    "* BatchNorm inside Inception modules\n",
    "\n",
    "### Inception v4 / Inception-ResNet\n",
    "\n",
    "* Combine Inception modules with residual connections\n",
    "* Deeper, faster convergence\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Why Inception is important\n",
    "\n",
    "1. Introduced the idea of **multi-scale parallel feature extraction**\n",
    "2. Demonstrated powerful **computational efficiency**\n",
    "3. Pioneered **1×1 convolution bottlenecks** (later used in ResNet, MobileNet, etc.)\n",
    "4. Influenced many architectures — including depthwise separable convolutions (Xception) and ResNeXt.\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Intuition summary\n",
    "\n",
    "Think of an Inception module like a camera lens system:\n",
    "\n",
    "* One lens sees tiny details (1×1)\n",
    "* One sees mid-scale (3×3)\n",
    "* One sees large structures (5×5)\n",
    "* One performs smoothing / pooling\n",
    "\n",
    "The model **does not choose a single resolution** — it learns all of them in parallel, at each stage.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b79df-ed96-419b-a195-e93c81f34125",
   "metadata": {},
   "source": [
    "## **Numerical Exmple**\n",
    "Below is a **clean, fully-numeric, channel/size-only example** of how **Inception-ResNet-A** (from Inception-ResNet-v2 or Inception-v4 family) transforms tensor shapes.\n",
    "\n",
    "You want:\n",
    "\n",
    "* Input: $ B, C, H, W $\n",
    "* Each branch: exact shapes after each convolution\n",
    "* Final concatenation shape\n",
    "* Residual projection shape\n",
    "* Final output shape\n",
    "\n",
    "Below is a **realistic** configuration for **Inception-ResNet-A** from the official paper.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. **Input**\n",
    "\n",
    "We define the input tensor:\n",
    "\n",
    "$$\n",
    "x \\in \\mathbb{R}^{B \\times 384 \\times 35 \\times 35}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "* Batch = $B$\n",
    "* Channels = 384\n",
    "* Height = 35\n",
    "* Width = 35\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Branch-by-branch numeric channel expansion**\n",
    "\n",
    "#### **Branch 1**\n",
    "\n",
    "1×1 convolution → 32 channels\n",
    "\n",
    "**Input:** $ B \\times 384 \\times 35 \\times 35 $\n",
    "**Output:** $ B \\times 32 \\times 35 \\times 35 $\n",
    "\n",
    "---\n",
    "\n",
    "#### **Branch 2**\n",
    "\n",
    "1×1 → 32, then 3×3 → 32\n",
    "\n",
    "* 1×1 conv:\n",
    "  $384 \\to 32$ channels\n",
    "* 3×3 conv:\n",
    "  $32 \\to 32$ channels (padding keeps spatial size)\n",
    "\n",
    "So:\n",
    "\n",
    "**After 1×1:**\n",
    "$ B \\times 32 \\times 35 \\times 35 $\n",
    "\n",
    "**After 3×3:**\n",
    "$ B \\times 32 \\times 35 \\times 35 $\n",
    "\n",
    "Final branch 2 output:\n",
    "\n",
    "$$\n",
    "B \\times 32 \\times 35 \\times 35\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Branch 3**\n",
    "\n",
    "1×1 → 32 → 3×3 → 48 → 3×3 → 64\n",
    "\n",
    "This is the “long” branch.\n",
    "\n",
    "1. 1×1 conv:\n",
    "   $384 \\to 32$\n",
    "\n",
    "2. 3×3 conv:\n",
    "   $32 \\to 48$\n",
    "\n",
    "3. 3×3 conv:\n",
    "   $48 \\to 64$\n",
    "\n",
    "All with padding = 1, so spatial dims unchanged.\n",
    "\n",
    "Output:\n",
    "\n",
    "$$\n",
    "B \\times 64 \\times 35 \\times 35\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Concatenate the 3 branches\n",
    "\n",
    "Branch outputs:\n",
    "\n",
    "* Branch 1: 32 channels\n",
    "* Branch 2: 32 channels\n",
    "* Branch 3: 64 channels\n",
    "\n",
    "Total after concatenation:\n",
    "\n",
    "$$\n",
    "32 + 32 + 64 = 128 \\text{ channels}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "**Concatenated tensor shape:**\n",
    "\n",
    "$$\n",
    "c = \\mathbb{R}^{B \\times 128 \\times 35 \\times 35}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Residual 1×1 projection**\n",
    "\n",
    "After concatenation, Inception-ResNet applies a 1×1 convolution that maps:\n",
    "\n",
    "$$\n",
    "128 \\to 384\n",
    "$$\n",
    "\n",
    "Why?\n",
    "Because the residual connection expects the output to match the input channel count (384).\n",
    "\n",
    "So:\n",
    "\n",
    "**Projection output:**\n",
    "\n",
    "$$\n",
    "m = \\mathbb{R}^{B \\times 384 \\times 35 \\times 35}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Residual scaling**\n",
    "\n",
    "In the real model, they scale the residual by a small factor, typically:\n",
    "\n",
    "$$\n",
    "s = \\alpha m, \\quad \\alpha = 0.1\n",
    "$$\n",
    "\n",
    "The shape is unchanged:\n",
    "\n",
    "$$\n",
    "s \\in \\mathbb{R}^{B \\times 384 \\times 35 \\times 35}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. **Final output**\n",
    "\n",
    "Residual addition:\n",
    "\n",
    "$$\n",
    "y = x + s\n",
    "$$\n",
    "\n",
    "Since:\n",
    "\n",
    "* $ x $ is $ B \\times 384 \\times 35 \\times 35 $\n",
    "* $ s $ is $ B \\times 384 \\times 35 \\times 35 $\n",
    "\n",
    "The output is:\n",
    "\n",
    "$$\n",
    "y \\in \\mathbb{R}^{B \\times 384 \\times 35 \\times 35}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# Final Summary Table (compact)\n",
    "\n",
    "| Step       | Operation       | Output Shape                         |\n",
    "| ---------- | --------------- | ------------------------------------ |\n",
    "| Input      | —               | $ B \\times 384 \\times 35 \\times 35 $ |\n",
    "| Branch 1   | 1×1 $384→32$    | $ B \\times 32 \\times 35 \\times 35 $  |\n",
    "| Branch 2a  | 1×1 $384→32$    | $ B \\times 32 \\times 35 \\times 35 $  |\n",
    "| Branch 2b  | 3×3 $32→32$     | $ B \\times 32 \\times 35 \\times 35 $  |\n",
    "| Branch 3a  | 1×1 $384→32$    | $ B \\times 32 \\times 35 \\times 35 $  |\n",
    "| Branch 3b  | 3×3 $32→48$     | $ B \\times 48 \\times 35 \\times 35 $  |\n",
    "| Branch 3c  | 3×3 $48→64$     | $ B \\times 64 \\times 35 \\times 35 $  |\n",
    "| Concat     | concat channels | $ B \\times 128 \\times 35 \\times 35 $ |\n",
    "| Projection | 1×1 $128→384$   | $ B \\times 384 \\times 35 \\times 35 $ |\n",
    "| Scale      | multiply by α   | $ B \\times 384 \\times 35 \\times 35 $ |\n",
    "| Add        | + residual      | $ B \\times 384 \\times 35 \\times 35 $ |\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
