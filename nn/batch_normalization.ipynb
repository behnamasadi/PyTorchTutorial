{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "We want to keep the output of activation function unit gaussian, so we make them gaussian. In the process we are not normalizing weight but the output of activations.\n",
    "\n",
    "\n",
    "Usually inserted after Fully Connected or Convolutional layers, and before nonlinearity.\n",
    "\n",
    "You want to be able how much saturation you have:\n",
    "bth of them are learnable \n",
    "$\\gamma$ and $\\beta$\n",
    "\n",
    "[1](https://youtu.be/wEoyxE0GP2M?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&t=2933),\n",
    "[2](https://arxiv.org/abs/1502.03167),\n",
    "[3](https://www.youtube.com/watch?v=DtEq44FTPM4), [4](https://www.youtube.com/watch?v=dXB-KQYkzNU), [5](https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm with PyTorch\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
