{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e777af5-f877-4970-bf76-f5fa63667437",
   "metadata": {},
   "source": [
    "## Structural Similarity Index Measure (SSIM)\n",
    "\n",
    "\n",
    "The **Structural Similarity Index Measure (SSIM)** is a widely used metric for measuring the similarity between two images. Unlike simple metrics such as Mean Squared Error (MSE) or Peak Signal-to-Noise Ratio (PSNR), SSIM is designed to model the way humans perceive image quality — focusing on structural information, contrast, and luminance rather than raw pixel differences.\n",
    "\n",
    "---\n",
    "\n",
    "### The Idea Behind SSIM\n",
    "\n",
    "SSIM tries to answer: *“How similar are two images in terms of structure, contrast, and brightness?”*\n",
    "\n",
    "It decomposes similarity into **three components**:\n",
    "\n",
    "1. **Luminance similarity** $l(x, y)$:\n",
    "\n",
    "   Are the two images equally bright on average?\n",
    "\n",
    "   $$\n",
    "   l(x,y) = \\frac{2 \\mu_x \\mu_y + C_1}{\\mu_x^2 + \\mu_y^2 + C_1}\n",
    "   $$\n",
    "\n",
    "- If both images have similar brightness, this term is near 1.\n",
    "- If one image is much darker, it will drop below 1.   \n",
    "\n",
    "2. **Contrast similarity** $c(x, y)$:\n",
    "\n",
    "   Do the two images have the same amount of contrast?\n",
    "\n",
    "   $$\n",
    "   c(x,y) = \\frac{2 \\sigma_x \\sigma_y + C_2}{\\sigma_x^2 + \\sigma_y^2 + C_2}\n",
    "   $$\n",
    "\n",
    "- If both images have similar contrast (variability), this is near 1.\n",
    "- If one is flat (low contrast) and the other is textured (high contrast), the similarity decreases.\n",
    "\n",
    "3. **Structural similarity** $s(x, y)$:\n",
    "\n",
    "   Do the two images have the same patterns and textures?\n",
    "\n",
    "   $$\n",
    "   s(x,y) = \\frac{\\sigma_{xy} + C_3}{\\sigma_x \\sigma_y + C_3}\n",
    "   $$\n",
    "- If $x$ and $y$ rise and fall together (high correlation), this is near $1$.\n",
    "- If they are uncorrelated or inverted (noise, wrong edges), this value becomes smaller or even negative.   \n",
    "\n",
    "Here:\n",
    "\n",
    "* $\\mu_x, \\mu_y$ are the mean intensities,\n",
    "* $\\sigma_x, \\sigma_y$ are standard deviations,\n",
    "* $\\sigma_{xy}$ is covariance between $x$ and $y$,\n",
    "* $C_1, C_2, C_3$ are small constants to stabilize division.\n",
    "\n",
    "The final SSIM is:\n",
    "\n",
    "$$\n",
    "SSIM(x, y) = [l(x, y)]^\\alpha \\cdot [c(x, y)]^\\beta \\cdot [s(x, y)]^\\gamma\n",
    "$$\n",
    "\n",
    "Usually $\\alpha = \\beta = \\gamma = 1$.\n",
    "\n",
    "\n",
    "SSIM is bounded between **–1 and 1**, where **1 means perfect similarity**.\n",
    "\n",
    "In loss form we usually use:\n",
    "\n",
    "$$\n",
    "\\text{SSIMLoss} = 1 - \\text{SSIM}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "This single equation combines three components:\n",
    "Often $ C_3 = C_2 / 2 $, and the product of these three terms is simplified into the combined form used above.\n",
    "\n",
    "\n",
    "$$\n",
    "SSIM(x,y) = \\frac{(2\\mu_x\\mu_y + C_1)(2\\sigma_{xy} + C_2)}\n",
    "{(\\mu_x^2 + \\mu_y^2 + C_1)(\\sigma_x^2 + \\sigma_y^2 + C_2)}\n",
    "$$\n",
    "\n",
    "Constants $ C_1 $ and $ C_2 $ are small stabilizers:\n",
    "$$\n",
    "C_1 = (0.01)^2, \\quad C_2 = (0.03)^2\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789f00f9-8ce1-4c77-ac8d-b3e08b4ccb1f",
   "metadata": {},
   "source": [
    "### **Interpreting the number**\n",
    "\n",
    "| SSIM Index (≈ 1 – loss) | Meaning                                           |\n",
    "| ----------------------- | ------------------------------------------------- |\n",
    "| 0.95 – 1.00             | Almost identical                                  |\n",
    "| 0.70 – 0.95             | Similar (small structural differences)            |\n",
    "| 0.40 – 0.70             | Moderately different (like adjacent KITTI frames) |\n",
    "| 0.10 – 0.40             | Visibly different                                 |\n",
    "| < 0.10                  | Almost unrelated                                  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e714f9-5318-49e9-940c-92abffa639f8",
   "metadata": {},
   "source": [
    "### Numerical SSIM Example\n",
    "Awesome—let’s do a fully worked **numerical SSIM example** with two $3\\times3$ grayscale image patches and compute every piece: mean, std, covariance, normalized correlation, the three SSIM terms (luminance/contrast/structure), and the final SSIM.\n",
    "\n",
    "**Images (grayscale, 8-bit scale assumed)**\n",
    "\n",
    "$$\n",
    "x=\\begin{bmatrix}\n",
    "10&20&30\\\\\n",
    "20&30&40\\\\\n",
    "30&40&50\n",
    "\\end{bmatrix},\\quad\n",
    "y=\\begin{bmatrix}\n",
    "12&22&32\\\\\n",
    "21&31&41\\\\\n",
    "29&39&49\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We’ll treat the whole $3\\times3$ window as one patch (i.e., a single SSIM window).\n",
    "\n",
    "---\n",
    "\n",
    "#### 1) Basic statistics\n",
    "\n",
    "Let $N=9$.\n",
    "\n",
    "**Means**\n",
    "\n",
    "$$\n",
    "\\mu_x=30.0000,\\qquad \\mu_y=30.6667\n",
    "$$\n",
    "\n",
    "**Sample standard deviations** (ddof=1)\n",
    "\n",
    "$$\n",
    "\\sigma_x=\\sqrt{150}=12.2474,\\qquad \\sigma_y=\\sqrt{129.25}=11.3688\n",
    "$$\n",
    "\n",
    "**Sample covariance**\n",
    "\n",
    "$$\n",
    "\\sigma_{xy}=\\frac{1}{N-1}\\sum (x_i-\\mu_x)(y_i-\\mu_y)=138.75\n",
    "$$\n",
    "\n",
    "**Normalized correlation (Pearson $\\rho$)**\n",
    "\n",
    "$$\n",
    "\\rho=\\frac{\\sigma_{xy}}{\\sigma_x\\sigma_y}=\\frac{138.75}{12.2474\\cdot 11.3688}\\approx 0.9965\n",
    "$$\n",
    "\n",
    "> Intuition: the patches vary together almost perfectly (very strong structural agreement).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2) SSIM components\n",
    "\n",
    "Use the standard SSIM constants for 8-bit images:\n",
    "\n",
    "$$\n",
    "L=255,\\quad C_1=(0.01L)^2=6.5025,\\quad C_2=(0.03L)^2=58.5225,\\quad C_3=\\frac{C_2}{2}=29.26125\n",
    "$$\n",
    "\n",
    "#### (a) Luminance term $l(x,y)$\n",
    "\n",
    "$$\n",
    "l=\\frac{2\\mu_x\\mu_y+C_1}{\\mu_x^2+\\mu_y^2+C_1}\n",
    "=\\frac{2\\cdot 30\\cdot 30.6667+6.5025}{30^2+30.6667^2+6.5025}\n",
    "\\approx 0.99976\n",
    "$$\n",
    "\n",
    "#### (b) Contrast term $c(x,y)$\n",
    "\n",
    "$$\n",
    "c=\\frac{2\\sigma_x\\sigma_y+C_2}{\\sigma_x^2+\\sigma_y^2+C_2}\n",
    "=\\frac{2\\cdot 12.2474\\cdot 11.3688+58.5225}{12.2474^2+11.3688^2+58.5225}\n",
    "\\approx 0.99771\n",
    "$$\n",
    "\n",
    "#### (c) Structure term $s(x,y)$\n",
    "\n",
    "$$\n",
    "s=\\frac{\\sigma_{xy}+C_3}{\\sigma_x\\sigma_y+C_3}\n",
    "=\\frac{138.75+29.26125}{12.2474\\cdot 11.3688+29.26125}\n",
    "\\approx 0.99710\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 3) Final SSIM\n",
    "\n",
    "$$\n",
    "SSIM=l\\cdot c\\cdot s\\approx 0.99976\\cdot 0.99771\\cdot 0.99710\\approx \\mathbf{0.99458}\n",
    "$$\n",
    "\n",
    "**Takeaway:** Despite small brightness/contrast differences, the structures match extremely well (high $\\rho$ and high SSIM ≈ **0.995**). This is exactly the kind of case where SSIM (and the structure term) shines compared to plain MSE/PSNR.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4fb7fa-7c6f-4770-81e1-faae4b14c9a4",
   "metadata": {},
   "source": [
    "### **PyTorch Implementation of SSIM**\n",
    "\n",
    "\n",
    "#### **Local Computation and the Role of the Gaussian Window**\n",
    "\n",
    "Unlike pixel-wise losses, SSIM operates on **local patches** — e.g. $ 11 \\times 11 $ regions — because the human eye perceives structure **locally**, not globally.\n",
    "\n",
    "For each pixel location $(i,j)$, a local window $ \\mathcal{W}(i,j) $ is centered on that pixel.\n",
    "Within this window, SSIM computes the following:\n",
    "\n",
    "* Local means $ \\mu_x, \\mu_y $\n",
    "* Local variances $ \\sigma_x^2, \\sigma_y^2 $\n",
    "* Local covariance $ \\sigma_{xy} $\n",
    "\n",
    "#### **Why Gaussian?**\n",
    "\n",
    "Not all pixels in a local window should contribute equally — center pixels are perceptually more relevant than distant ones.\n",
    "Therefore, SSIM uses a **Gaussian weighting function** to emphasize the center:\n",
    "\n",
    "$$\n",
    "G(x, y) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "This Gaussian acts as a **smooth, normalized weighting kernel** over the window.\n",
    "It ensures:\n",
    "\n",
    "* Higher weight near the window center\n",
    "* Gradual falloff toward the edges\n",
    "* Smooth transitions between neighboring windows\n",
    "\n",
    "The local mean (brightness) is then computed as a **weighted average**:\n",
    "$$\n",
    "\\mu_x(i,j) = (G * x)(i,j)\n",
    "$$\n",
    "and similarly for $ \\mu_y(i,j) $.\n",
    "\n",
    "The variance and covariance use the same Gaussian weights:\n",
    "$$\n",
    "\\sigma_x^2 = (G * x^2) - \\mu_x^2, \\quad\n",
    "\\sigma_y^2 = (G * y^2) - \\mu_y^2, \\quad\n",
    "\\sigma_{xy} = (G * xy) - \\mu_x\\mu_y\n",
    "$$\n",
    "\n",
    "So, the Gaussian window defines how **local** and how **smooth** these statistics are.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "#### **Implementation Breakdown**\n",
    "\n",
    "Here is how the PyTorch implementation encodes the above:\n",
    "\n",
    "```python\n",
    "class SSIMLoss(nn.Module):\n",
    "    def __init__(self, window_size=11, size_average=True):\n",
    "        super().__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "```\n",
    "\n",
    "#### **(a) Building the Gaussian Window**\n",
    "\n",
    "```python\n",
    "def gaussian_window(self, window_size, sigma):\n",
    "    gauss = torch.Tensor([\n",
    "        torch.exp(-(x - window_size//2)**2 / float(2*sigma**2))\n",
    "        for x in range(window_size)\n",
    "    ])\n",
    "    return gauss / gauss.sum()\n",
    "```\n",
    "\n",
    "Creates a **1D Gaussian vector** centered at `window_size // 2`.\n",
    "\n",
    "Then extended to **2D** via outer product:\n",
    "\n",
    "```python\n",
    "_2D_window = _1D_window.mm(_1D_window.t())\n",
    "```\n",
    "\n",
    "and broadcast to all channels:\n",
    "\n",
    "```python\n",
    "window = _2D_window.expand(channel, 1, window_size, window_size)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **(b) Computing Local Statistics**\n",
    "\n",
    "Using grouped 2D convolution, each channel is processed independently:\n",
    "\n",
    "```python\n",
    "mu1 = F.conv2d(img1, window, padding=self.window_size//2, groups=channel)\n",
    "mu2 = F.conv2d(img2, window, padding=self.window_size//2, groups=channel)\n",
    "```\n",
    "\n",
    "This computes local **weighted means** using the Gaussian kernel.\n",
    "\n",
    "Then:\n",
    "\n",
    "```python\n",
    "sigma1_sq = F.conv2d(img1 * img1, window, ...) - mu1**2\n",
    "sigma2_sq = F.conv2d(img2 * img2, window, ...) - mu2**2\n",
    "sigma12   = F.conv2d(img1 * img2, window, ...) - mu1 * mu2\n",
    "```\n",
    "\n",
    "These correspond to **local variances and covariance**, weighted by the same Gaussian.\n",
    "\n",
    "---\n",
    "\n",
    "#### **(c) Computing the SSIM Map**\n",
    "\n",
    "```python\n",
    "C1, C2 = 0.01**2, 0.03**2\n",
    "ssim_map = ((2*mu1*mu2 + C1) * (2*sigma12 + C2)) / \\\n",
    "           ((mu1**2 + mu2**2 + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "```\n",
    "\n",
    "This yields a pixel-wise SSIM map (one value per local patch).\n",
    "\n",
    "---\n",
    "\n",
    "#### **(d) Turning into a Loss**\n",
    "\n",
    "The final output is:\n",
    "\n",
    "```python\n",
    "return 1 - ssim_map.mean()\n",
    "```\n",
    "\n",
    "So the model minimizes dissimilarity (i.e., maximizes SSIM).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Interpretation**\n",
    "\n",
    "| Aspect                   | Meaning                                     | Implementation                |\n",
    "| ------------------------ | ------------------------------------------- | ----------------------------- |\n",
    "| **Window**               | Defines local region around each pixel      | Gaussian kernel (e.g., 11×11) |\n",
    "| **Gaussian weighting**   | Emphasizes center pixels, smooth transition | `gaussian_window()`           |\n",
    "| **Luminance similarity** | Compares brightness                         | `mu1`, `mu2`                  |\n",
    "| **Contrast similarity**  | Compares variance                           | `sigma1_sq`, `sigma2_sq`      |\n",
    "| **Structure similarity** | Compares pattern correlation                | `sigma12`                     |\n",
    "| **Final SSIM**           | Combined measure                            | `ssim_map = ...`              |\n",
    "| **Loss**                 | ( 1 - \\text{mean(SSIM)} )                   | Returned as `SSIMLoss`        |\n",
    "\n",
    "---\n",
    "\n",
    "#### **Typical Use in Deep Learning**\n",
    "\n",
    "In tasks like **Monodepth2** (self-supervised depth estimation), the photometric loss combines SSIM and L1:\n",
    "\n",
    "$$\n",
    "L_{photo} = \\alpha \\cdot L_{SSIM} + (1 - \\alpha) \\cdot L_{L1}\n",
    "$$\n",
    "\n",
    "with $ \\alpha = 0.85 $.\n",
    "This way, the loss captures both perceptual similarity and pixel accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Behavior**\n",
    "\n",
    "* If two images are identical:\n",
    "  $ SSIM = 1 \\Rightarrow L_{SSIM} = 0 $\n",
    "* If completely different:\n",
    "  $ SSIM \\approx 0 \\Rightarrow L_{SSIM} \\approx 1 $\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "* The **Gaussian window** defines the **local region** and gives **weighted emphasis** toward the center.\n",
    "* SSIM computes **luminance**, **contrast**, and **structure** similarity **within** that window.\n",
    "* Using **convolution with a Gaussian kernel** efficiently computes local statistics for every pixel.\n",
    "* The final loss, ( 1 - \\text{SSIM} ), encourages the model to produce images that are perceptually and structurally similar to the target.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to follow up with a **numerical or visual example** showing how Gaussian weighting affects the local mean and SSIM calculation across an image patch?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a979f2-92f1-4346-99db-b2b54d03c18c",
   "metadata": {},
   "source": [
    "###  Normalized Correlation\n",
    "The **normalized correlation** part of SSIM is the most “structural” component, so it’s worth understanding carefully.\n",
    "\n",
    "**Step 1: Represent the Images**\n",
    "\n",
    "Suppose you have two image patches $x$ and $y$ of size $N$ pixels (can be grayscale or single channel).\n",
    "\n",
    "$$\n",
    "x = [x_1, x_2, \\dots, x_N], \\quad y = [y_1, y_2, \\dots, y_N]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Compute the Mean**\n",
    "\n",
    "Compute the mean intensity (average brightness) of each patch:\n",
    "\n",
    "$$\n",
    "\\mu_x = \\frac{1}{N} \\sum_{i=1}^{N} x_i, \\qquad\n",
    "\\mu_y = \\frac{1}{N} \\sum_{i=1}^{N} y_i\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Compute the Standard Deviations**\n",
    "\n",
    "Compute how much pixel values vary around the mean:\n",
    "\n",
    "$$\n",
    "\\sigma_x = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^{N} (x_i - \\mu_x)^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_y = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^{N} (y_i - \\mu_y)^2}\n",
    "$$\n",
    "\n",
    "These represent the **contrast** of each image.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Compute the Covariance**\n",
    "\n",
    "Covariance measures how much the two patches vary *together*:\n",
    "\n",
    "$$\n",
    "\\sigma_{xy} = \\frac{1}{N-1} \\sum_{i=1}^{N} (x_i - \\mu_x)(y_i - \\mu_y)\n",
    "$$\n",
    "\n",
    "* If $x$ and $y$ increase/decrease together → covariance is **positive**.\n",
    "* If one increases when the other decreases → covariance is **negative**.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 5: Normalize → Get the Correlation**\n",
    "\n",
    "The **Pearson correlation coefficient** is just the covariance normalized by the product of standard deviations:\n",
    "\n",
    "$$\n",
    "\\rho_{xy} = \\frac{\\sigma_{xy}}{\\sigma_x \\sigma_y}\n",
    "$$\n",
    "\n",
    "* This value ranges between **-1 and 1**.\n",
    "\n",
    "  * $1.0 \\Rightarrow$ perfect positive linear correlation (structures align perfectly).\n",
    "  * $0 \\Rightarrow$ no linear correlation (structures unrelated).\n",
    "  * $-1.0 \\Rightarrow$ perfect negative correlation (inverted contrast).\n",
    "\n",
    "---\n",
    "\n",
    "**Step 6: Add Stabilization for SSIM**\n",
    "\n",
    "In SSIM, to avoid division by zero when contrast is very low, we use a small constant $C_3$:\n",
    "\n",
    "$$\n",
    "s(x, y) = \\frac{\\sigma_{xy} + C_3}{\\sigma_x \\sigma_y + C_3}\n",
    "$$\n",
    "\n",
    "This keeps the measure well-defined even for very flat patches (e.g., almost uniform gray).\n",
    "\n",
    "---\n",
    "\n",
    "**Intuition**\n",
    "\n",
    "* **Covariance** tells you whether pixel intensities move together.\n",
    "* **Normalization** by $\\sigma_x \\sigma_y$ removes the effect of scale/contrast so you focus purely on **structure** (edges, textures, gradients).\n",
    "\n",
    "This is why SSIM can still give a high similarity score if one image is slightly brighter/darker — because the **pattern** of variations is the same.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71665822-6aad-41fc-8c27-52fb57a8f6b1",
   "metadata": {},
   "source": [
    "SSIM tries to mimic the **human visual system** by:\n",
    "\n",
    "* **Normalizing for lighting** (so small brightness changes are ignored).\n",
    "* **Normalizing for contrast** (so small contrast changes are less penalized).\n",
    "* **Measuring structure** (so it cares about edges, patterns, textures).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14310ab-96f4-4f5c-abd7-2081315611f6",
   "metadata": {},
   "source": [
    "\n",
    "## LPIPS\n",
    "\n",
    "So far, we talked about **SSIM** (hand-crafted metric). Now, **LPIPS (Learned Perceptual Image Patch Similarity)** goes a step further: instead of manually designing similarity measures, it uses **deep features** from pretrained networks (e.g., AlexNet, VGG, SqueezeNet) to capture perceptual similarity.\n",
    "\n",
    "\n",
    "* Proposed in **\"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric\"** (Zhang et al., 2018).\n",
    "* Idea: Humans judge images by *perceptual similarity*, not pixel-wise equality.\n",
    "* LPIPS measures distance in the **feature space** of a pretrained CNN rather than raw pixels.\n",
    "\n",
    "---\n",
    "\n",
    "####  How It Works\n",
    "\n",
    "1. Take two images $x$ and $y$.\n",
    "2. Pass both through a **pretrained network** (e.g., VGG).\n",
    "3. Extract activations from multiple layers (feature maps).\n",
    "4. Normalize features and compute **L2 distance** per spatial location.\n",
    "5. Average distances across spatial positions and layers.\n",
    "6. Optionally, train small linear weights to better align with human judgments.\n",
    "\n",
    "$$\n",
    "LPIPS(x,y) = \\sum_l \\frac{1}{H_l W_l} \\sum_{h,w} w_l \\; \\| \\hat{f}_l(x)_{h,w} - \\hat{f}_l(y)_{h,w} \\|_2^2\n",
    "$$\n",
    "\n",
    "* $f_l$: feature map from layer $l$.\n",
    "* $\\hat{f}_l$: channel-wise normalized.\n",
    "* $w_l$: learned weights.\n",
    "\n",
    "---\n",
    "\n",
    "####  Why LPIPS is Important\n",
    "\n",
    "* **MSE/PSNR**: pixel-wise, not perceptual.\n",
    "* **SSIM**: structural but still hand-crafted.\n",
    "* **LPIPS**: learned perceptual similarity, matches human perception much better.\n",
    "\n",
    "In practice, LPIPS is considered **state-of-the-art** for evaluating perceptual image quality (GANs, super-resolution, style transfer, inpainting).\n",
    "\n",
    "---\n",
    "\n",
    "**LPIPS in Deep Learning Workflows**\n",
    "\n",
    "* Used as an **evaluation metric** for generative models (GANs, diffusion, etc.).\n",
    "* Sometimes used as a **loss function** (LPIPS loss) for training perceptual similarity.\n",
    "* Often combined with pixel losses (L1/L2) or SSIM.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "####  Comparison: SSIM vs LPIPS\n",
    "\n",
    "| Metric       | Based on                           | Pros                                                         | Cons                                             |\n",
    "| ------------ | ---------------------------------- | ------------------------------------------------------------ | ------------------------------------------------ |\n",
    "| **MSE/PSNR** | Pixel differences                  | Simple, fast                                                 | Not perceptual, sensitive to shifts              |\n",
    "| **SSIM**     | Luminance, contrast, structure     | Better perceptual alignment                                  | Hand-crafted, less robust to complex distortions |\n",
    "| **LPIPS**    | Deep features (VGG, AlexNet, etc.) | Best matches human perception, widely used in GAN evaluation | Heavier, requires pretrained nets                |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
