{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13843bf-c0cf-40ea-ae97-b8a441c1c927",
   "metadata": {},
   "source": [
    "##  1. Overview: Loss taxonomy for Depth + Pose self-supervised VO\n",
    "\n",
    "| Category                              | Loss name                                                              | Purpose                                |\n",
    "| ------------------------------------- | ---------------------------------------------------------------------- | -------------------------------------- |\n",
    "| **Photometric consistency**           | ðŸ”¸ *Photometric loss* (SSIM + L1)                                      | Reprojection-based self-supervision    |\n",
    "| **Geometry regularization**           | ðŸ”¸ *Edge-aware depth smoothness*                                       | Enforces spatial coherence on depth    |\n",
    "| **Pose supervision / regularization** | ðŸ”¸ *Geodesic loss*, *Quaternion loss*, *SE(3) transform loss*          | If GT or pseudo-GT poses are available |\n",
    "| **Motion priors / dynamics**          | ðŸ”¸ *Rotation magnitude loss*, *velocity smoothness*                    | Regularize PoseNet outputs             |\n",
    "| **Additional (optional)**             | ðŸ”¸ *Depth consistency*, *multi-scale weighting*, *explainability mask* | More advanced refinements              |\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##  2. Core self-supervised losses (always used)\n",
    "\n",
    "These two are your **bread and butter**.\n",
    "They drive both DepthNet and PoseNet when you train from monocular videos **without ground truth**.\n",
    "\n",
    "---\n",
    "\n",
    "### (a) **Photometric Reprojection Loss** (a.k.a. View Synthesis Loss)\n",
    "\n",
    "**Definition:**\n",
    "$\n",
    "L_\\text{photo} = \\min_s \\Big( \\alpha \\frac{1 - \\text{SSIM}(I_t, I_s')}{2} + (1 - \\alpha) | I_t - I_s' |_1 \\Big)\n",
    "$\n",
    "\n",
    "* (I_s'): Source image warped into target frame using predicted depth + pose.\n",
    "* Î± = 0.85 works best (from Monodepth2).\n",
    "* Take **minimum reprojection** across multiple source frames (to ignore occlusions).\n",
    "\n",
    " **You already implemented this**. Itâ€™s the most critical part.\n",
    "\n",
    "---\n",
    "\n",
    "### (b) **Edge-Aware Depth Smoothness Loss**\n",
    "\n",
    "Encourages locally smooth depth while preserving depth discontinuities along image edges.\n",
    "\n",
    "**Equation:**\n",
    "$\n",
    "L_\\text{smooth} = |\\partial_x d_t^*| e^{-|\\partial_x I_t|} + |\\partial_y d_t^*| e^{-|\\partial_y I_t|}\n",
    "$\n",
    "\n",
    "where $d_t^* = d_t / \\bar{d_t}$ (normalized disparity).\n",
    "\n",
    " This loss prevents noisy disparity, and the edge weighting keeps depth edges aligned with color edges.\n",
    "\n",
    "---\n",
    "\n",
    "**Combined core loss:**\n",
    "$\n",
    "L_\\text{unsup} = L_\\text{photo} + \\lambda_\\text{smooth} L_\\text{smooth}\n",
    "$\n",
    "Typical Î»â‚›â‚˜â‚’â‚’â‚œâ‚• â‰ˆ 0.001 â€“ 0.01.\n",
    "\n",
    "---\n",
    "\n",
    "##  3. Optional pose-related losses (for better motion consistency)\n",
    "\n",
    "These are **not mandatory** for self-supervised training,\n",
    "but useful if you have **pseudo ground truth poses** (e.g., from KITTI odometry or IMU).\n",
    "\n",
    "---\n",
    "\n",
    "### (a) **Geodesic Rotation Loss**\n",
    "\n",
    "Encourages PoseNetâ€™s predicted rotation (R_\\text{pred}) to be close to ground truth (R_\\text{gt}) on SO(3):\n",
    "\n",
    "$\n",
    "L_R = | \\log(R_\\text{gt}^T R_\\text{pred}) |_2\n",
    "$\n",
    "\n",
    "Where `log()` is the matrix logarithm mapping to so(3).\n",
    "This gives a **rotation angle error** in radians.\n",
    "\n",
    "```python\n",
    "def geodesic_loss(R_pred, R_gt):\n",
    "    R_rel = R_pred.transpose(-1, -2) @ R_gt\n",
    "    log_R = torch.linalg.logm(R_rel)\n",
    "    return torch.norm(log_R, dim=(1,2)).mean()\n",
    "```\n",
    "\n",
    "Use if you have ground-truth rotations from KITTI or IMU fusion.\n",
    "\n",
    "---\n",
    "\n",
    "### (b) **Quaternion Loss**\n",
    "\n",
    "If you represent rotations as quaternions (q):\n",
    "\n",
    "$\n",
    "L_q = 1 - \\langle q_\\text{pred}, q_\\text{gt} \\rangle^2\n",
    "$\n",
    "\n",
    "It penalizes quaternion misalignment.\n",
    "\n",
    "```python\n",
    "def quaternion_loss(q_pred, q_gt):\n",
    "    return 1 - torch.sum(q_pred * q_gt, dim=-1).pow(2).mean()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### (c) **Full SE(3) Transformation Loss**\n",
    "\n",
    "Combines rotation and translation errors in one expression:\n",
    "\n",
    "$\n",
    "L_{SE3} = | \\log(T_\\text{gt}^{-1} T_\\text{pred}) |_2\n",
    "$\n",
    "This measures the 6D twist vector (Î¾) difference between two SE(3) transforms.\n",
    "\n",
    " Great for fine-tuning PoseNet if you have ground-truth or pseudo ground-truth trajectories.\n",
    "\n",
    "---\n",
    "\n",
    "### (d) **Rotation Magnitude / Motion Prior Loss**\n",
    "\n",
    "Encourages PoseNet outputs to have small, realistic motion per frame:\n",
    "\n",
    "$\n",
    "L_\\text{motion} = |r_\\text{pred}|*2 + |t*\\text{pred}|_2\n",
    "$\n",
    "\n",
    "This acts like a regularizer and avoids large jumps in estimated pose.\n",
    "\n",
    "---\n",
    "\n",
    "##  4. Optional advanced terms (for refinement or stability)\n",
    "\n",
    "| Loss                           | Purpose                                                          |\n",
    "| ------------------------------ | ---------------------------------------------------------------- |\n",
    "| **Explainability mask loss**   | Downweights moving objects and occlusions.                       |\n",
    "| **Depth consistency loss**     | Enforces consistency between multi-scale depth predictions.      |\n",
    "| **Temporal smoothness loss**   | Penalizes acceleration/jerk between consecutive predicted poses. |\n",
    "| **Scale-invariant depth loss** | Used when GT depths are available but relative scale is unknown. |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Recommended combination for your project\n",
    "\n",
    "Since youâ€™re currently using **KITTI** and your setup is **self-supervised** (DepthNet + PoseNet trained together):\n",
    "\n",
    "###  **Use these always**\n",
    "\n",
    "| Loss                                      | Weight | Purpose              |\n",
    "| ----------------------------------------- | ------ | -------------------- |\n",
    "| Photometric (SSIM + L1, min reprojection) | 1.0    | Core supervision     |\n",
    "| Edge-aware depth smoothness               | 0.001  | Depth regularization |\n",
    "\n",
    "###  **Add these if GT poses available (optional fine-tuning)**\n",
    "\n",
    "| Loss                   | Weight | Purpose               |\n",
    "| ---------------------- | ------ | --------------------- |\n",
    "| Geodesic rotation loss | 1.0    | Rotation accuracy     |\n",
    "| Translation (L1) loss  | 0.1    | Motion scale accuracy |\n",
    "| SE(3) transform loss   | 0.5    | Joint refinement      |\n",
    "\n",
    "---\n",
    "\n",
    "##  6. Example final total loss\n",
    "\n",
    "```python\n",
    "Î»_smooth = 0.001\n",
    "Î»_se3 = 0.5\n",
    "Î»_geo = 1.0\n",
    "\n",
    "total_loss = photo_loss + Î»_smooth * smooth_loss\n",
    "\n",
    "if use_pose_supervision:\n",
    "    total_loss += Î»_geo * geo_loss + Î»_se3 * se3_loss\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  TL;DR Summary\n",
    "\n",
    "| Loss                      | Type             | Mandatory? | Description                     |\n",
    "| ------------------------- | ---------------- | ---------- | ------------------------------- |\n",
    "| **Photometric (SSIM+L1)** | Self-supervised  | âœ…          | Image reconstruction            |\n",
    "| **Edge-aware smoothness** | Regularization   | âœ…          | Sharp, stable depth             |\n",
    "| **Geodesic rotation**     | Pose supervision | optional   | SO(3) rotation distance         |\n",
    "| **Quaternion**            | Pose supervision | optional   | Quaternion consistency          |\n",
    "| **SE(3) full transform**  | Pose supervision | optional   | Combined rotation + translation |\n",
    "| **Motion prior (L2)**     | Regularization   | optional   | Prevent large PoseNet jumps     |\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
