{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "511abc29-ad3f-4302-bc5e-5cb9d03db5e7",
   "metadata": {},
   "source": [
    "##  Two ways to save models in PyTorch\n",
    "\n",
    "### 1. `torch.save(model.state_dict(), PATH)`\n",
    "\n",
    "This saves **only the parameters** (weights & biases) of the model.\n",
    "\n",
    "```python\n",
    "# Save\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")\n",
    "\n",
    "# Load\n",
    "model = TheModelClass(*args, **kwargs)  # must recreate same architecture\n",
    "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "* **Pros:**\n",
    "\n",
    "  * Recommended / common way.\n",
    "  * File is lighter (only contains tensors).\n",
    "  * Flexible: you can change some parts of the model code and still load weights.\n",
    "  * More portable (different machines, PyTorch versions).\n",
    "*  **Cons:**\n",
    "\n",
    "  * You must have the model class definition available when loading.\n",
    "  * Requires you to manually re-create the model object before loading weights.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. `torch.save(model, PATH)`\n",
    "\n",
    "This saves the **entire model object**, including:\n",
    "\n",
    "* Architecture definition\n",
    "* Parameters\n",
    "\n",
    "```python\n",
    "# Save\n",
    "torch.save(model, \"entire_model.pth\")\n",
    "\n",
    "# Load\n",
    "model = torch.load(\"entire_model.pth\")\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "*  **Pros:**\n",
    "\n",
    "  * Super easy to load — you don’t need to redefine the model class.\n",
    "  * Useful for quick experiments or when sharing with colleagues who won’t re-create the model code.\n",
    "*  **Cons:**\n",
    "\n",
    "  * Not portable: tightly coupled to the code (class name, location in module, etc.).\n",
    "  * May break if:\n",
    "\n",
    "    * Code changes (e.g., you rename a class or move files).\n",
    "    * Different PyTorch versions are used.\n",
    "  * Larger file size.\n",
    "\n",
    "---\n",
    "\n",
    "##  Which one is more common?\n",
    "\n",
    " **Best practice (most common in research & production):**\n",
    "\n",
    "```python\n",
    "torch.save(model.state_dict(), PATH)\n",
    "```\n",
    "\n",
    "because it’s more **robust, portable, and reproducible**.\n",
    "\n",
    "**When to use `torch.save(model, PATH)`:**\n",
    "\n",
    "* Quick experiments, debugging, or toy projects.\n",
    "* When you’re not planning to refactor the code and just want to “freeze” everything.\n",
    "\n",
    "---\n",
    "\n",
    " **Summary:**\n",
    "\n",
    "* Use `state_dict()` in 99% of cases (production, research, sharing).\n",
    "* Use `torch.save(model)` only if you want the *entire object snapshot* and you control the environment.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
