{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fee63a2-79ab-4551-b669-dc75df45ca4c",
   "metadata": {},
   "source": [
    "# 1. Saving Weights\n",
    "If you're also using CUDA (GPU tensors), and you want deterministic behavior there too, you should also call:\n",
    "\n",
    "\n",
    "```python\n",
    "torch.cuda.manual_seed(42)\n",
    "```\n",
    "\n",
    "but for CPU, \n",
    "```python\n",
    "torch.manual_seed(42)\n",
    "```\n",
    "is enough.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "placed-colony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from model.pth\n",
      "tensor([[ 0.5498],\n",
      "        [ 0.2914],\n",
      "        [-0.0424],\n",
      "        [-0.1927],\n",
      "        [-0.2770]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "model = nn.Sequential(nn.Flatten(), nn.Linear(2, 10),\n",
    "                      nn.ReLU(),    nn.Linear(10, 1))\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed(42)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "if os.path.isfile(\"model.pth\"):\n",
    "    print(\"Loading model from model.pth\")\n",
    "    model.load_state_dict(torch.load(\"model.pth\", weights_only=True))\n",
    "else:\n",
    "    print(\"Creating new model\")\n",
    "\n",
    "\n",
    "N, C, H, W = 5, 1, 2, 1\n",
    "input = torch.randn(N, C, H, W, device=device)\n",
    "\n",
    "\n",
    "input = input.view(N, -1)\n",
    "print(model(input))\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35162fcd-6605-402e-acae-f5a31816188c",
   "metadata": {},
   "source": [
    "# 2. Saving Model Architecture + Weights\n",
    "\n",
    "There are **two main ways** to save both **model architecture + weights** together in PyTorch:\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1. Save the **whole model** (architecture + weights)\n",
    "\n",
    "You can simply do:\n",
    "\n",
    "```python\n",
    "torch.save(model, \"model_full.pth\")\n",
    "```\n",
    "\n",
    "And then **load** it like this:\n",
    "\n",
    "```python\n",
    "model = torch.load(\"model_full.pth\")\n",
    "```\n",
    "\n",
    "This way, you **don't need to manually recreate the model** — it knows its own architecture.\n",
    "\n",
    "**BUT**, it's a bit less flexible, because it's tied to the exact Python code and environment where you saved it (especially class definitions). It's not very portable across different codebases.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2. Save **architecture and weights separately** (better practice)\n",
    "\n",
    "A **cleaner, safer** way (especially for serious projects) is:\n",
    "\n",
    "**When saving:**\n",
    "\n",
    "```python\n",
    "# Save model parameters (e.g., for example input size, number of classes, etc.)\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'input_size': 784,\n",
    "    'hidden_size': 500,\n",
    "    'output_size': 10\n",
    "}, 'model_checkpoint.pth')\n",
    "```\n",
    "\n",
    "**When loading:**\n",
    "\n",
    "```python\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "\n",
    "# Recreate the model using saved parameters\n",
    "model = MyModel(checkpoint['input_size'], checkpoint['hidden_size'], checkpoint['output_size'])\n",
    "\n",
    "# Load the weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "```\n",
    "\n",
    "This is much more flexible: you can update the model code later if needed, and still restore the trained model correctly.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cdeb09-36b3-451f-a712-0bab5c6ec491",
   "metadata": {},
   "source": [
    "**if your model is big and complex** (many convolution layers, BatchNorms, Dropouts, special blocks like ResNet, etc.):  It's **better to separate model architecture info into a separate config file** (like **YAML** or **JSON**).\n",
    "\n",
    "---\n",
    "\n",
    "### Typical structure for big models:\n",
    "\n",
    "- `model_weights.pth`: → only stores the **state_dict** (weights and batchnorm stats).\n",
    "- `model_config.yaml` or `model_config.json`: → describes the **model architecture** (layer sizes, number of blocks, activation types, etc.).\n",
    "\n",
    "\n",
    "For example, the YAML file might look like:\n",
    "\n",
    "```yaml\n",
    "model_type: \"resnet\"\n",
    "num_layers: 50\n",
    "input_channels: 3\n",
    "num_classes: 1000\n",
    "block_type: \"bottleneck\"\n",
    "```\n",
    "\n",
    "Then you **reconstruct the model from the YAML/JSON** + **load weights from .pth**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a6b541-b2de-4292-a122-db15ccfc06b4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`model_config.yaml`:\n",
    "\n",
    "```yaml\n",
    "model_type: simple_cnn\n",
    "input_channels: 3\n",
    "num_classes: 10\n",
    "conv_layers: \n",
    "  - out_channels: 32\n",
    "    kernel_size: 3\n",
    "    stride: 1\n",
    "  - out_channels: 64\n",
    "    kernel_size: 3\n",
    "    stride: 1\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6180aec6-06e0-4ee6-8efd-1ad6d9a29527",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "\n",
    "# 1. Define a model class that can build dynamically based on config\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes, conv_layers):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = input_channels\n",
    "        for layer_cfg in conv_layers:\n",
    "            layers.append(nn.Conv2d(in_channels, layer_cfg['out_channels'], kernel_size=layer_cfg['kernel_size'], stride=layer_cfg['stride']))\n",
    "            layers.append(nn.BatchNorm2d(layer_cfg['out_channels']))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            in_channels = layer_cfg['out_channels']\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 2. Load config\n",
    "with open(\"model_config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# 3. Create the model\n",
    "model = SimpleCNN(\n",
    "    input_channels=config['input_channels'],\n",
    "    num_classes=config['num_classes'],\n",
    "    conv_layers=config['conv_layers']\n",
    ")\n",
    "\n",
    "# 4. Load weights\n",
    "\n",
    "\n",
    "if os.path.isfile(\"model_weights.pth\"):\n",
    "    print(\"Loading model from model_weights.pth\")\n",
    "    model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "    model.eval()\n",
    "    print(\"Model is ready\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
