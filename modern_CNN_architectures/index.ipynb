{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce3eb8f3-dce6-4537-85c9-a1f4cbc5d2a0",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)\n",
    "A Convolutional Neural Network (CNN) processes an input image through several **convolutional layers**, each applying multiple learnable filters (kernels). For example, the first convolution layer might use 10 filters of size $6 \\times 6 \\times 3$ (height × width × depth), producing **10 feature maps** that capture different local patterns such as edges or textures.\n",
    "\n",
    "These feature maps then undergo **subsampling** (often via max pooling) to reduce spatial dimensions while keeping the most prominent features, improving translation invariance and reducing computation.\n",
    "\n",
    "The process of **convolution → subsampling** repeats multiple times, with feature maps getting deeper (more channels) but spatially smaller as we move through the network.\n",
    "\n",
    "Eventually, the resulting high-level feature maps are **flattened** into a vector and passed to one or more **fully connected layers**, which perform the final classification or regression task.\n",
    "\n",
    "In short:\n",
    "\n",
    "* **Width & height** of feature maps → decrease as we go deeper.\n",
    "* **Depth (number of channels)** → increases as we go deeper.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b1e48-884d-4f98-9dee-396fcfe6cc43",
   "metadata": {},
   "source": [
    "![](images/Typical_cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ac4bf-ff22-4b6a-ab6e-e96576f2b41c",
   "metadata": {},
   "source": [
    "![](images/vgg-16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e8c5b1-f60c-4f2d-a2b5-542ddc3fb293",
   "metadata": {},
   "source": [
    "![](images/VGG-16-architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff65774-96c0-4200-bba9-04969fc6e23e",
   "metadata": {},
   "source": [
    "## How to read and interpret network architecture\n",
    "\n",
    "\n",
    "When you see a diagram of a network architecture like **U-Net** or **ResNet**, the goal is to translate that picture (or description) into:\n",
    "\n",
    "1. **What’s happening to the data at each stage** (shape, type, and meaning).\n",
    "2. **Why those stages are there** (function and design reasoning).\n",
    "3. **How the whole thing solves the intended problem** (semantic flow).\n",
    "\n",
    "Here’s a structured way to read and interpret them:\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Identify the big picture**\n",
    "\n",
    "Before diving into layers:\n",
    "\n",
    "* **Task type** – Is this classification, segmentation, detection, reconstruction, etc.?\n",
    "\n",
    "  * U-Net → segmentation.\n",
    "  * ResNet → classification (originally), but adaptable.\n",
    "* **Data type** – Images, video, 3D volumes, etc.? This determines convolution types, input shapes, etc.\n",
    "* **Input & output shapes** – e.g. U-Net may take a `256×256×3` image and output `256×256×C` where `C` = number of segmentation classes.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Break the architecture into high-level blocks**\n",
    "\n",
    "Architectures are rarely “just a list of layers.” They usually have **modules**:\n",
    "\n",
    "* **Encoder / backbone** – progressively reduces spatial size, increases channels (feature depth).\n",
    "* **Bottleneck** – most compressed representation.\n",
    "* **Decoder / head** – progressively upsamples, merges, and produces output.\n",
    "\n",
    "For example:\n",
    "\n",
    "* **U-Net** – Encoder → Bottleneck → Decoder with skip connections between matching resolutions.\n",
    "* **ResNet** – Stack of “Residual Blocks” arranged in stages, gradually shrinking resolution but increasing channels.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Understand the transformations per block**\n",
    "\n",
    "For each module:\n",
    "\n",
    "* **What’s the input shape?**\n",
    "* **What layers are applied?** (Conv, BatchNorm, Activation, Pooling, etc.)\n",
    "* **How does shape change?**\n",
    "\n",
    "  * Convolution with stride > 1 → downsampling.\n",
    "  * Pooling → downsampling.\n",
    "  * Transposed convolution / upsampling → upsampling.\n",
    "* **What is the role?**\n",
    "\n",
    "  * Convs → extract local patterns.\n",
    "  * Pooling / stride → abstract and compress information.\n",
    "  * Skip connections → preserve details, help gradient flow.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Watch the “information highway”**\n",
    "\n",
    "Some architectures have *special wiring*:\n",
    "\n",
    "* **Skip connections (ResNet)** → Shortcuts that add input to output of a block (helps train deep nets).\n",
    "* **Concatenation skips (U-Net)** → Copy encoder features to decoder to restore detail.\n",
    "* **Multi-scale paths (FPN, U-Net++)** → Combine features from different scales.\n",
    "\n",
    "Interpretation tip:\n",
    "\n",
    "* Ask: *“Where does the data flow in parallel?”*\n",
    "* Ask: *“What is merged and how (addition, concatenation)?”*\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Pay attention to design patterns**\n",
    "\n",
    "Many architectures reuse “building blocks”:\n",
    "\n",
    "* **Residual Block** – Conv → BN → ReLU → Conv → BN → Add input → ReLU.\n",
    "* **Inverted Residual (MobileNetV2)** – Expand → Depthwise Conv → Project.\n",
    "* **Double Convolution (U-Net)** – Two `3×3` convs with BN/ReLU.\n",
    "\n",
    "Once you recognize a block, you can “mentally compress” the diagram.\n",
    "Example: A ResNet-50 has 4 main stages with specific block counts, not just “50 layers.”\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Use the “shape trace” method**\n",
    "\n",
    "This is my go-to trick for making sense of *any* architecture:\n",
    "\n",
    "| Step | Layer/Block       | Input Shape | Operation | Output Shape | Notes                 |\n",
    "| ---- | ----------------- | ----------- | --------- | ------------ | --------------------- |\n",
    "| 1    | Conv 7×7 s=2      | 224×224×3   | ↓ spatial | 112×112×64   | Early feature extract |\n",
    "| 2    | MaxPool 3×3 s=2   | 112×112×64  | ↓ spatial | 56×56×64     | ...                   |\n",
    "| 3    | Residual Block ×3 | 56×56×64    | same res  | 56×56×256    | ...                   |\n",
    "\n",
    "If you do this from start to finish, the architecture stops being “mystical” and becomes a sequence of shape changes.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Ask “why” after “what”**\n",
    "\n",
    "Once you decode the structure:\n",
    "\n",
    "* **Why this downsampling rate?** (task might need detail vs abstraction)\n",
    "* **Why skip connections?** (gradient stability, detail preservation)\n",
    "* **Why so many channels in bottleneck?** (higher-level feature richness)\n",
    "\n",
    "---\n",
    "\n",
    "## **Example: Quick mental model**\n",
    "\n",
    "* **U-Net** – Think: *compress (encoder), store detail aside (skip), expand (decoder), stitch back detail.*\n",
    "* **ResNet** – Think: *standard CNN, but every block learns the *change* needed, not the full mapping.*\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
