{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a7c67e-69eb-4903-a632-a40c3ab3f78e",
   "metadata": {},
   "source": [
    "##  **1. Custom Dataset Class**\n",
    "\n",
    "```\n",
    "torch/\n",
    "    __init__.py\n",
    "    utils/\n",
    "        __init__.py\n",
    "        data/\n",
    "            __init__.py  # This is a crucial file that makes 'data' a Python module\n",
    "            dataset.py   # This file defines the base Dataset class and random_split\n",
    "            dataloader.py  # This file defines the DataLoader class\n",
    "            sampler.py\n",
    "```\n",
    "\n",
    "\n",
    "So, you can use: \n",
    "\n",
    "```python\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "```\n",
    "\n",
    "\n",
    "or \n",
    "\n",
    "```python\n",
    "import torch.utils.data.dataset as dataset\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "\n",
    "dataset.random_split()\n",
    "dataloader.DataLoader()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "You define your dataset by subclassing `torch.utils.data.Dataset` and overriding `__len__()` and `__getitem__()`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27788f3d-9559-4514-a68b-31189c2d868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset, Subset\n",
    "\n",
    "\n",
    "class MyCustomDataSet(Dataset):\n",
    "    def __init__(self, data, lables):\n",
    "        self.data = data\n",
    "        self.lables = lables\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.lables[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69386d8-18c5-46c5-93fd-84d5874c2f5f",
   "metadata": {},
   "source": [
    "##  **2. `random_split`** \n",
    "\n",
    "`torch.utils.data.random_split(dataset, lengths, generator=None)`: splits a dataset into non-overlapping new datasets of given lengths.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **2.1. Only Index-Based – No Data Copy**\n",
    "\n",
    "* `random_split` **does not copy** the underlying data.\n",
    "* It **wraps the original dataset** and uses internally shuffled indices to simulate subsets.\n",
    "* Memory usage is minimal because it's just a view via `Subset`.\n",
    "\n",
    "Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0cb5fae-6f40-4606-8068-965be038b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "sample_size = 100\n",
    "data = torch.randn(sample_size, 2)\n",
    "lables = torch.randint(0, 2, (sample_size,))\n",
    "\n",
    "dataset = MyCustomDataSet(data=data, lables=lables)\n",
    "\n",
    "train_size = int(0.75*len(dataset))\n",
    "val_size = int(0.15*len(dataset))\n",
    "test_size = len(dataset)-train_size-val_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5438d20-c333-4950-a9e6-6e2a130b2cfa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "####  **2.2. Reproducibility with Generator**\n",
    "\n",
    "To ensure reproducibility (same split every run), pass a seeded `torch.Generator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34b78021-8272-4cfd-bb86-b911b8772b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size], generator=generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6a7c2-2379-41ca-a4d2-917ef9820347",
   "metadata": {},
   "source": [
    "If you don't pass a generator, a random seed is used from the system, and results will vary across runs.\n",
    "\n",
    "---\n",
    "\n",
    "####  **2.3. How It Works Internally**\n",
    "\n",
    "* Internally, it:\n",
    "\n",
    "  * Shuffles indices using the generator (if given),\n",
    "  * Splits them into the specified sizes,\n",
    "  * Creates `Subset(dataset, indices)` for each split.\n",
    "\n",
    "---\n",
    "\n",
    "####  **2.4.Common Pitfalls**\n",
    "\n",
    "* **Don't modify the original dataset in-place** after splitting. The splits reference it.\n",
    "* Be careful with imbalanced class distributions — `random_split` does **not** preserve class ratios.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367aa8d3-b870-43d6-9b8d-7860c90cbe56",
   "metadata": {},
   "source": [
    "## **3.`Subset`**\n",
    "\n",
    "`Subset` creates a **view** of a dataset using a list of indices. It’s a wrapper that lets you work with just a portion of a dataset **without copying** the data.\n",
    "\n",
    "```python\n",
    "torch.utils.data.Subset(dataset, indices)\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41a21177-54ed-4289-9a54-e2170f7f01ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1.9269, 1.4873]), tensor(1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "subset = Subset(dataset, indices)\n",
    "\n",
    "print(dataset[0])\n",
    "\n",
    "subset.dataset   # Original dataset\n",
    "subset.indices   # List of indices used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b2ce91-b603-4091-aaf0-7f660264118b",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1. **No Data Copy**\n",
    "\n",
    "* Like `random_split`, `Subset` does **not duplicate data** — it just stores references (indices).\n",
    "* It’s memory-efficient and fast.\n",
    "\n",
    "#### 3.2. **How It Works**\n",
    "\n",
    "* Internally, `Subset` defines `__getitem__` like this:\n",
    "\n",
    "  ```python\n",
    "  def __getitem__(self, idx):\n",
    "      return self.dataset[self.indices[idx]]\n",
    "  ```\n",
    "* So each item access fetches from the original dataset using the provided index mapping.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3.3 Stratified Splits with scikit-learn**\n",
    "\n",
    "\n",
    "\n",
    "You can use `StratifiedShuffleSplit` to split based on labels and then wrap them in `Subset`:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "targets = dataset.targets  # Or dataset.labels depending on the dataset\n",
    "\n",
    "for train_idx, val_idx in sss.split(X=targets, y=targets):\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds = Subset(dataset, val_idx)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3f302-ac2b-49d7-ae96-5319dd5d76f0",
   "metadata": {},
   "source": [
    "##  **ImageFolder**\n",
    "\n",
    "\n",
    "In PyTorch, `torchvision.datasets.ImageFolder` is a utility class for loading image datasets arranged in a specific directory structure. It automatically assigns labels based on subdirectory names, making it ideal for classification tasks.\n",
    "\n",
    "---\n",
    "\n",
    "**Directory Structure**\n",
    "\n",
    "`ImageFolder` expects the dataset directory to be structured like this:\n",
    "\n",
    "```\n",
    "root/\n",
    "    class1/\n",
    "        img1.png\n",
    "        img2.png\n",
    "        ...\n",
    "    class2/\n",
    "        img3.png\n",
    "        img4.png\n",
    "        ...\n",
    "```\n",
    "\n",
    "* Each **subfolder** under `root` is treated as a class.\n",
    "* All images inside a class folder are treated as samples of that class.\n",
    "\n",
    "---\n",
    "\n",
    "**How It Works**\n",
    "\n",
    "```python\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define optional transforms (resizing, normalization, etc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(root='path/to/root', transform=transform)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Labels and Classes**\n",
    "\n",
    "* `dataset.classes`: list of class names (e.g., `['cat', 'dog']`)\n",
    "* `dataset.class_to_idx`: dict mapping class names to label indices (e.g., `{'cat': 0, 'dog': 1}`)\n",
    "* Each sample is a tuple: `(image_tensor, label)`\n",
    "\n",
    "You can access an image and its label like this:\n",
    "\n",
    "```python\n",
    "img, label = dataset[0]\n",
    "```\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
