{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a7c67e-69eb-4903-a632-a40c3ab3f78e",
   "metadata": {},
   "source": [
    "##  **1. Custom Dataset Class**\n",
    "\n",
    "You define your dataset by subclassing `torch.utils.data.Dataset` and overriding `__len__()` and `__getitem__()`.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data  # e.g., a NumPy array or tensor\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x, y\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69386d8-18c5-46c5-93fd-84d5874c2f5f",
   "metadata": {},
   "source": [
    "##  **2. `torch.utils.data.random_split`** \n",
    "\n",
    "`torch.utils.data.random_split(dataset, lengths, generator=None)`: splits a dataset into non-overlapping new datasets of given lengths.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "#### **2.1. Only Index-Based – No Data Copy**\n",
    "\n",
    "* `random_split` **does not copy** the underlying data.\n",
    "* It **wraps the original dataset** and uses internally shuffled indices to simulate subsets.\n",
    "* Memory usage is minimal because it's just a view via `Subset`.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_ds, val_ds = random_split(full_dataset, [8000, 2000])\n",
    "# `train_ds` and `val_ds` are `Subset` objects\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "####  **2.2. Reproducibility with Generator**\n",
    "\n",
    "To ensure reproducibility (same split every run), pass a seeded `torch.Generator`:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_ds, val_ds = random_split(full_dataset, [8000, 2000], generator=generator)\n",
    "```\n",
    "\n",
    "If you don't pass a generator, a random seed is used from the system, and results will vary across runs.\n",
    "\n",
    "---\n",
    "\n",
    "####  **2.3. How It Works Internally**\n",
    "\n",
    "* Internally, it:\n",
    "\n",
    "  * Shuffles indices using the generator (if given),\n",
    "  * Splits them into the specified sizes,\n",
    "  * Creates `Subset(dataset, indices)` for each split.\n",
    "\n",
    "---\n",
    "\n",
    "####  **2.4.Common Pitfalls**\n",
    "\n",
    "* **Don't modify the original dataset in-place** after splitting. The splits reference it.\n",
    "* Be careful with imbalanced class distributions — `random_split` does **not** preserve class ratios.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "dataset = CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "generator = torch.Generator().manual_seed(123)\n",
    "\n",
    "train_set, val_set = random_split(dataset, [45000, 5000], generator=generator)\n",
    "\n",
    "print(len(train_set), len(val_set))  # 45000 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367aa8d3-b870-43d6-9b8d-7860c90cbe56",
   "metadata": {},
   "source": [
    "## **3.`torch.utils.data.Subset`**\n",
    "\n",
    "`Subset` creates a **view** of a dataset using a list of indices. It’s a wrapper that lets you work with just a portion of a dataset **without copying** the data.\n",
    "\n",
    "```python\n",
    "torch.utils.data.Subset(dataset, indices)\n",
    "```\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "#### 3.1. **No Data Copy**\n",
    "\n",
    "* Like `random_split`, `Subset` does **not duplicate data** — it just stores references (indices).\n",
    "* It’s memory-efficient and fast.\n",
    "\n",
    "#### 3.2. **How It Works**\n",
    "\n",
    "* Internally, `Subset` defines `__getitem__` like this:\n",
    "\n",
    "  ```python\n",
    "  def __getitem__(self, idx):\n",
    "      return self.dataset[self.indices[idx]]\n",
    "  ```\n",
    "* So each item access fetches from the original dataset using the provided index mapping.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3.3 Use Cases**\n",
    "\n",
    "**Manual Splits**\n",
    "\n",
    "Useful if you want custom train/val/test splits:\n",
    "\n",
    "```python\n",
    "from torch.utils.data import Subset\n",
    "indices = list(range(len(dataset)))\n",
    "train_idx = indices[:8000]\n",
    "val_idx = indices[8000:]\n",
    "\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds = Subset(dataset, val_idx)\n",
    "```\n",
    "\n",
    "**Stratified Splits with scikit-learn**\n",
    "\n",
    "You can use `StratifiedShuffleSplit` to split based on labels and then wrap them in `Subset`:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "targets = dataset.targets  # Or dataset.labels depending on the dataset\n",
    "\n",
    "for train_idx, val_idx in sss.split(X=targets, y=targets):\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds = Subset(dataset, val_idx)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Accessing Original Dataset**\n",
    "\n",
    "You can still access the original dataset and indices:\n",
    "\n",
    "```python\n",
    "subset.dataset   # Original dataset\n",
    "subset.indices   # List of indices used\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Summary Comparison: `random_split` vs `Subset`**\n",
    "\n",
    "| Feature         | `random_split`                     | `Subset`                             |\n",
    "| --------------- | ---------------------------------- | ------------------------------------ |\n",
    "| Purpose         | Randomly divide dataset into parts | Create a view on dataset via indices |\n",
    "| Data Copy?      | ❌ No                               | ❌ No                                 |\n",
    "| Reproducibility | ✅ With `torch.Generator`           | ✅ If indices are controlled          |\n",
    "| Shuffling?      | ✅ Internally when splitting        | ❌ You provide indices                |\n",
    "| Use Cases       | Simple, fast random split          | Custom, stratified, or fixed split   |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3f302-ac2b-49d7-ae96-5319dd5d76f0",
   "metadata": {},
   "source": [
    "##  **ImageFolder**\n",
    "\n",
    "\n",
    "In PyTorch, `torchvision.datasets.ImageFolder` is a utility class for loading image datasets arranged in a specific directory structure. It automatically assigns labels based on subdirectory names, making it ideal for classification tasks.\n",
    "\n",
    "---\n",
    "\n",
    "**Directory Structure**\n",
    "\n",
    "`ImageFolder` expects the dataset directory to be structured like this:\n",
    "\n",
    "```\n",
    "root/\n",
    "    class1/\n",
    "        img1.png\n",
    "        img2.png\n",
    "        ...\n",
    "    class2/\n",
    "        img3.png\n",
    "        img4.png\n",
    "        ...\n",
    "```\n",
    "\n",
    "* Each **subfolder** under `root` is treated as a class.\n",
    "* All images inside a class folder are treated as samples of that class.\n",
    "\n",
    "---\n",
    "\n",
    "**How It Works**\n",
    "\n",
    "```python\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define optional transforms (resizing, normalization, etc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(root='path/to/root', transform=transform)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Labels and Classes**\n",
    "\n",
    "* `dataset.classes`: list of class names (e.g., `['cat', 'dog']`)\n",
    "* `dataset.class_to_idx`: dict mapping class names to label indices (e.g., `{'cat': 0, 'dog': 1}`)\n",
    "* Each sample is a tuple: `(image_tensor, label)`\n",
    "\n",
    "You can access an image and its label like this:\n",
    "\n",
    "```python\n",
    "img, label = dataset[0]\n",
    "```\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
