{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35fa91b-40d0-4d40-a0c8-0eb9afeb3b55",
   "metadata": {},
   "source": [
    "# What is nnU-Net?\n",
    "\n",
    "**nnU-Net** (no-new-U-Net) is a **fully automated deep-learning framework for biomedical image segmentation**.\n",
    "It is not just a model.\n",
    "It is a **system** that:\n",
    "\n",
    "* analyzes your dataset,\n",
    "* configures the entire pipeline automatically,\n",
    "* trains several models,\n",
    "* ensembles them,\n",
    "* and gives you a strong baseline without manual tuning.\n",
    "\n",
    "Its key idea:\n",
    "**Automate everything that experts usually design manually** (preprocessing, architecture, patch size, data augmentation, postprocessing, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "# Core Idea\n",
    "\n",
    "Given a new medical dataset (CT, MRI, multi-modal, anisotropic, 2D, 3D…), nnU-Net:\n",
    "\n",
    "1. **Reads dataset properties** (voxel spacing, anisotropy, image size, number of channels)\n",
    "2. **Chooses the architecture variant** (2D U-Net, 3D U-Net, 3D U-Net cascade)\n",
    "3. **Chooses patch size, batch size, number of filters**\n",
    "4. **Applies optimal preprocessing**\n",
    "5. **Applies powerful data augmentation**\n",
    "6. **Trains using standardized training rules**\n",
    "7. **Performs automatic postprocessing**\n",
    "8. **Ensembles all models**\n",
    "\n",
    "And it works extremely well across many medical challenges (Decathlon, KiTS, BraTS, PROMISE12, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "# Pipeline Overview\n",
    "\n",
    "## 1. Dataset Analysis (Automated)\n",
    "\n",
    "nnU-Net reads the dataset metadata:\n",
    "\n",
    "* image spacings\n",
    "* voxel anisotropy\n",
    "* image shapes\n",
    "* modalities (CT/MRI channels)\n",
    "* number of segmentation classes\n",
    "\n",
    "Based on this, it decides whether the dataset is:\n",
    "\n",
    "* best handled with **2D U-Net**\n",
    "* **3D full-resolution U-Net**\n",
    "* **3D low-resolution + cascade model**\n",
    "\n",
    "Example:\n",
    "If voxel spacing has large anisotropy (slice thickness ≫ in-plane resolution), nnU-Net favors **2D** or **3D large-spacing** models.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Automated Architecture Construction\n",
    "\n",
    "It builds a U-Net variant with:\n",
    "\n",
    "* number of stages chosen based on memory limits\n",
    "* convolution kernel sizes chosen based on anisotropy\n",
    "* dynamic number of feature maps\n",
    "* skip connections\n",
    "* instance normalization\n",
    "* leaky ReLU or GELU depending on version\n",
    "\n",
    "Key:\n",
    "Architecture is **not manually designed** – it adapts to dataset geometry and GPU memory.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Automated Preprocessing\n",
    "\n",
    "### a. Intensity Normalization\n",
    "\n",
    "* **Z-score** for MRI\n",
    "* **ct-clipping + normalization** for CT (based on HU)\n",
    "\n",
    "### b. Resampling\n",
    "\n",
    "All images are resampled to a **target spacing** chosen automatically.\n",
    "Preserves anatomical correctness.\n",
    "\n",
    "### c. Cropping / foreground detection\n",
    "\n",
    "Reduces empty space for faster training.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Automated Training Configuration\n",
    "\n",
    "nnU-Net chooses:\n",
    "\n",
    "* patch size\n",
    "* batch size\n",
    "* sampling strategy (foreground oversampling)\n",
    "* optimizer: **SGD with Nesterov**\n",
    "* learning rate schedule: **poly LR**\n",
    "\n",
    "$$ lr = lr_0 \\left(1 - \\frac{iter}{iter_{max}} \\right)^{0.9} $$\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Automated Data Augmentation\n",
    "\n",
    "A strong augmentation pipeline including:\n",
    "\n",
    "* elastic deformations\n",
    "* gamma transformations\n",
    "* gaussian noise\n",
    "* rotations & flipping\n",
    "* mirroring\n",
    "* scale & intensity shift\n",
    "\n",
    "Everything is selected depending on dimensionality (2D/3D).\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Model Types nnU-Net Trains\n",
    "\n",
    "nnU-Net trains **three models**:\n",
    "\n",
    "1. **2D U-Net**\n",
    "2. **3D full-resolution U-Net**\n",
    "3. **3D U-Net cascade** (coarse → fine)\n",
    "\n",
    "Not all datasets use all three.\n",
    "It chooses automatically.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Ensembling\n",
    "\n",
    "At inference time, predictions from the different models are **ensembled** to boost performance.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Automated Postprocessing\n",
    "\n",
    "nnU-Net looks at validation errors and decides:\n",
    "\n",
    "* removing small connected components,\n",
    "* class-wise postprocessing,\n",
    "* refining multi-organ predictions.\n",
    "\n",
    "---\n",
    "\n",
    "# Why nnU-Net Works So Well\n",
    "\n",
    "It removes manual guesswork and standardizes all components.\n",
    "\n",
    "Key aspects:\n",
    "\n",
    "1. **Universality** – works out of the box for almost any 3D/2D medical segmentation task.\n",
    "2. **Robust preprocessing** – automatic spacing/patch decisions.\n",
    "3. **Heavy augmentation** – prevents overfitting on small medical datasets.\n",
    "4. **Strong ensembling** – boosts performance.\n",
    "5. **No architecture-hacking needed** – prevents overengineering.\n",
    "\n",
    "---\n",
    "\n",
    "# Architecture Overview (U-Net Style)\n",
    "\n",
    "Prototype architecture:\n",
    "\n",
    "* Encoder:\n",
    "  Conv → Norm → Nonlinearity → Downsample\n",
    "* Decoder:\n",
    "  Upsample → Concatenate skip → Conv blocks\n",
    "* Output:\n",
    "  1×1 convolution to class logits\n",
    "\n",
    "But nnU-Net adjusts:\n",
    "\n",
    "* depth\n",
    "* number of filters\n",
    "* kernel sizes\n",
    "* spacing handling\n",
    "\n",
    "All from dataset analysis.\n",
    "\n",
    "---\n",
    "\n",
    "# When Should You Use nnU-Net?\n",
    "\n",
    "nnU-Net is ideal when:\n",
    "\n",
    "* You have limited data (typical medical imaging)\n",
    "* You want a **baseline** that is very strong\n",
    "* You want high performance without hyperparameter search\n",
    "* You work with CT, MRI, microscopy, 3D volumes\n",
    "* You want to avoid huge architecture engineering time\n",
    "\n",
    "You should NOT use it when:\n",
    "\n",
    "* You need non-U-Net architectures (transformers, SAM-style)\n",
    "* You need extremely low-latency inference\n",
    "* You must control every part of the pipeline manually\n",
    "\n",
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "**nnU-Net = automatic, adaptive, standardized biomedical segmentation system.**\n",
    "\n",
    "It configures:\n",
    "\n",
    "* preprocessing\n",
    "* architecture\n",
    "* training\n",
    "* augmentation\n",
    "* postprocessing\n",
    "* ensembling\n",
    "\n",
    "and provides **state-of-the-art** results on new datasets without manual tuning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
