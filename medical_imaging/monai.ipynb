{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8c079d-85f5-4bc7-96af-8c40578ab49a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# MONAI\n",
    "\n",
    "MONAI is useful whenever you deal with **medical images**, especially in formats and tasks common in hospitals and research labs (e.g., MRI, CT, PET, X-ray, Ultrasound).\n",
    "\n",
    "```bash\n",
    "pip install monai[all]\n",
    "```\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# 1. **Medical Image Segmentation** (most common use)\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Brain tumor segmentation (MRI)\n",
    "* Organ segmentation (liver, kidneys, heart, lungs)\n",
    "* Vessel segmentation\n",
    "* Lesion segmentation (COVID lung opacities, liver lesions)\n",
    "* Breast cancer segmentation (MRI, Ultrasound)\n",
    "\n",
    "Why MONAI helps:\n",
    "\n",
    "* Built-in 2D/3D U-Net, UNet++, UNETR (Transformer-based)\n",
    "* Medical-style augmentations (elastic deformation, intensity shifts, bias field, random cropping on label regions)\n",
    "* Patch-wise training for huge 3D scans\n",
    "* Metrics like Dice, Hausdorff\n",
    "\n",
    "---\n",
    "\n",
    "# 2. **Medical Image Classification**\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Classify chest X-rays into normal vs pneumonia\n",
    "* Detect diabetic retinopathy from fundus images\n",
    "* Classify MRI sequences (T1, T2, FLAIR)\n",
    "* Detect fractures in X-rays\n",
    "\n",
    "Why MONAI helps:\n",
    "\n",
    "* Easy data loading for DICOM/NIfTI\n",
    "* Medical-oriented transforms (windowing, orientation, spacing)\n",
    "* Pretrained 2D/3D models for medical images\n",
    "\n",
    "---\n",
    "\n",
    "# 3. **Medical Image Registration**\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Align MRI scans of the same patient (pre-op vs post-op)\n",
    "* CT–MRI multimodal registration\n",
    "* Template-to-subject alignment (e.g., brain atlas)\n",
    "\n",
    "Why MONAI helps:\n",
    "\n",
    "* Built-in registration networks (VNet, Global/Local registration)\n",
    "* SpatialTransformer layers based on VoxelMorph\n",
    "* Diffeomorphic warping tools\n",
    "\n",
    "---\n",
    "\n",
    "# 4. **Medical Image Detection**\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Detect lung nodules in CT\n",
    "* Detect lesions in mammography\n",
    "* Bounding-box detection for polyps in endoscopy\n",
    "\n",
    "Why MONAI helps:\n",
    "\n",
    "* Integrates with torchvision-style detectors\n",
    "* Handles 3D bounding boxes\n",
    "* 2D/3D detection models\n",
    "\n",
    "---\n",
    "\n",
    "# 5. **Medical Image Reconstruction**\n",
    "\n",
    "Examples:\n",
    "\n",
    "* MRI reconstruction from undersampled k-space\n",
    "* CT sparse-view reconstruction\n",
    "* Denoising & super-resolution for low-dose CT\n",
    "\n",
    "Why MONAI helps:\n",
    "\n",
    "* k-space transforms\n",
    "* Physics-informed neural networks\n",
    "* Integration with Total Variation losses\n",
    "\n",
    "---\n",
    "\n",
    "# 6. **Medical Image Preprocessing Pipelines**\n",
    "\n",
    "Even if you don’t use MONAI for the model, you can use it for:\n",
    "\n",
    "* Converting DICOM to tensors\n",
    "* Resampling to isotropic spacing\n",
    "* Normalizing Hounsfield units (HU)\n",
    "* Cropping around organs\n",
    "* Bias field correction\n",
    "* Histogram normalization\n",
    "\n",
    "This is a huge win compared to writing everything by hand.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. **End-to-End Medical AI Pipelines**\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Radiology triage system\n",
    "* Automated CT lung-analysis pipeline\n",
    "* Oncology tumor-tracking\n",
    "* Surgical navigation\n",
    "* Medical dataset cleaning and annotation tools\n",
    "* Federated learning across hospitals (MONAI FL)\n",
    "\n",
    "MONAI includes:\n",
    "\n",
    "* MONAI Core (models, transforms, utilities)\n",
    "* MONAI Label (annotation tool)\n",
    "* MONAI Deploy (building medical AI apps for hospitals)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b9c088-4d85-465f-b597-5c450e960c39",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 3. Core Concepts of MONAI\n",
    "\n",
    "MONAI is built around these pillars:\n",
    "\n",
    "## 3.1 Composables: `Transforms`\n",
    "\n",
    "Transforms are **deterministic or random operations composed into a pipeline**:\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "train_transforms = monai.transforms.Compose([\n",
    "    monai.transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    monai.transforms.AddChanneld(keys=[\"image\", \"label\"]),\n",
    "    monai.transforms.ScaleIntensityd(keys=[\"image\"]),\n",
    "    monai.transforms.RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=(96,96,96), random_size=False),\n",
    "    monai.transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "    monai.transforms.ToTensord(keys=[\"image\", \"label\"])\n",
    "])\n",
    "```\n",
    "\n",
    "These work naturally with **medical formats** (nii.gz, mhd, nrrd, dicom).\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2 Dataset types\n",
    "\n",
    "MONAI provides efficient dataset implementations:\n",
    "\n",
    "### **`CacheDataset`**\n",
    "\n",
    "* Caches transformed samples in memory\n",
    "* Faster training but uses RAM\n",
    "\n",
    "### **`SmartCacheDataset`**\n",
    "\n",
    "* Rotates cached items and improves RAM usage\n",
    "\n",
    "### **`Dataset`**\n",
    "\n",
    "* Basic, no caching\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "train_ds = monai.data.CacheDataset(\n",
    "    data=train_files, \n",
    "    transform=train_transforms,\n",
    "    cache_rate=1.0      # fully cache\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3.3 DataLoader (PyTorch)\n",
    "\n",
    "MONAI integrates with PyTorch DataLoader:\n",
    "\n",
    "```python\n",
    "train_loader = monai.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3.4 Models (Networks)\n",
    "\n",
    "Example UNet:\n",
    "\n",
    "```python\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128),\n",
    "    strides=(2, 2, 2),\n",
    ")\n",
    "```\n",
    "\n",
    "Other models available:\n",
    "\n",
    "* `UNETR`\n",
    "* `SwinUNETR`\n",
    "* `SegResNet`\n",
    "* `DynUNet`\n",
    "* `DenseNet`\n",
    "* `ViT`\n",
    "\n",
    "---\n",
    "\n",
    "## 3.5 Losses\n",
    "\n",
    "Designed for segmentation:\n",
    "\n",
    "```python\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "\n",
    "loss_fn = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3.6 Metrics\n",
    "\n",
    "Measuring segmentation quality:\n",
    "\n",
    "```python\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "```\n",
    "\n",
    "Internally, MONAI computes\n",
    "\n",
    "$$\n",
    "\\text{Dice} = \\frac{2 |\\text{Prediction} \\cap \\text{GroundTruth}|}{|\\text{Prediction}| + |\\text{GroundTruth}|}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## 4.2 Transforms\n",
    "\n",
    "```python\n",
    "from monai.transforms import (\n",
    "    LoadImaged, AddChanneld, ScaleIntensityd,\n",
    "    RandFlipd, RandRotate90d, ToTensord, Compose\n",
    ")\n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    AddChanneld(keys=[\"image\", \"label\"]),\n",
    "    ScaleIntensityd(keys=[\"image\"]),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, max_k=3),\n",
    "    ToTensord(keys=[\"image\", \"label\"])\n",
    "])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4.3 Dataset + DataLoader\n",
    "\n",
    "```python\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "\n",
    "train_ds = CacheDataset(train_files, train_transforms, cache_rate=1.0)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4.4 Model, Loss, Optimizer\n",
    "\n",
    "```python\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceCELoss\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128),\n",
    "    strides=(2, 2, 2)\n",
    ").to(device)\n",
    "\n",
    "loss_fn = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4.5 Training loop (clean version)\n",
    "\n",
    "```python\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        img = batch[\"image\"].to(device)\n",
    "        lab = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img)\n",
    "        loss = loss_fn(pred, lab)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss = {running_loss / len(train_loader)}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 5. How MONAI Differs From Standard PyTorch\n",
    "\n",
    "| Aspect                 | PyTorch        | MONAI                                         |\n",
    "| ---------------------- | -------------- | --------------------------------------------- |\n",
    "| Medical image IO       | None           | Yes (nifti, dicom, mhd, etc.)                 |\n",
    "| Complex transforms     | Manual         | Huge library (affine, spatial crop, patching) |\n",
    "| 3D UNets               | Write manually | Many pretrained models                        |\n",
    "| Patch-based training   | Manual         | Automated                                     |\n",
    "| Caching / SmartCache   | No             | Yes                                           |\n",
    "| Reproducible workflows | Must assemble  | Included patterns                             |\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Additional Useful Blocks\n",
    "\n",
    "## 6.1 Sliding window inference\n",
    "\n",
    "For big CT/MRI volumes:\n",
    "\n",
    "```python\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "pred = sliding_window_inference(\n",
    "    inputs=img,\n",
    "    roi_size=(96, 96, 96),\n",
    "    sw_batch_size=4,\n",
    "    predictor=model\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6.2 Save NIfTI results\n",
    "\n",
    "```python\n",
    "from monai.data import write_nifti\n",
    "\n",
    "write_nifti(pred.cpu(), \"prediction.nii.gz\", affine=np.eye(4))\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094e03b-f922-42c1-b1ca-4cbfa71bcde6",
   "metadata": {},
   "source": [
    "# Rule of Thumb\n",
    "\n",
    "* **Use MONAI losses, metrics, transforms** → because they are designed for medical segmentation and often outperform raw PyTorch equivalents.\n",
    "* **Use PyTorch optimizers, schedulers, AMP, gradients** → because MONAI does *not* replace these and PyTorch versions are standard.\n",
    "\n",
    "Below is the clean breakdown.\n",
    "\n",
    "---\n",
    "\n",
    "# 1. LOSS FUNCTIONS\n",
    "\n",
    "### Use MONAI versions (recommended)\n",
    "\n",
    "✔ Specialized for segmentation\n",
    "✔ Include softmax, one-hot, class weighting\n",
    "✔ Numerically stable\n",
    "✔ Handle 3D, multi-class, patch-based workflows\n",
    "\n",
    "Examples:\n",
    "\n",
    "```python\n",
    "from monai.losses import DiceLoss, DiceCELoss, FocalLoss\n",
    "```\n",
    "\n",
    "Why not plain PyTorch loss?\n",
    "\n",
    "PyTorch `CrossEntropyLoss` is fine for classification, but for segmentation you often need:\n",
    "\n",
    "* Dice\n",
    "* Dice + CE\n",
    "* Focal\n",
    "* Boundary losses\n",
    "* Generalized Dice\n",
    "\n",
    "These are **not** in PyTorch.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. OPTIMIZERS\n",
    "\n",
    "### Use standard PyTorch optimizers\n",
    "\n",
    "MONAI does **not** introduce optimizers.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "```\n",
    "\n",
    "This is the correct choice.\n",
    "\n",
    "---\n",
    "\n",
    "# 3. SCHEDULERS\n",
    "\n",
    "### Use PyTorch schedulers\n",
    "\n",
    "```python\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=100)\n",
    "```\n",
    "\n",
    "MONAI does not replace schedulers.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. BACKPROP, AMP, GRAD-SCALING\n",
    "\n",
    "### Use PyTorch AMP\n",
    "\n",
    "```python\n",
    "from torch.amp import autocast, GradScaler\n",
    "```\n",
    "\n",
    "MONAI integrates with it but does not replace it.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. METRICS\n",
    "\n",
    "### Use MONAI metrics for segmentation, classification, detection\n",
    "\n",
    "Examples:\n",
    "\n",
    "```python\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.metrics import HausdorffDistanceMetric\n",
    "from monai.metrics import ConfusionMatrixMetric\n",
    "```\n",
    "\n",
    "PyTorch does not provide medical segmentation metrics.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. MODELS\n",
    "\n",
    "### Use MONAI models\n",
    "\n",
    "Already covered earlier.\n",
    "\n",
    "---\n",
    "\n",
    "# 7. TRANSFORMS / DATASETS\n",
    "\n",
    "### Use MONAI\n",
    "\n",
    "PyTorch does not understand medical data formats (Nifti, DICOM, orientation, spacing, patch sampling).\n",
    "\n",
    "---\n",
    "\n",
    "# 8. FULL TRAINING LOOP — CORRECT MIX\n",
    "\n",
    "Here is the **ideal combination** (this is what almost all MONAI papers use):\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import Compose, LoadImaged, AddChanneld\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims=3, in_channels=1, out_channels=2,\n",
    "    channels=(16,32,64,128), strides=(2,2,2)\n",
    ").to(\"cuda\")\n",
    "\n",
    "loss_fn = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False)\n",
    "\n",
    "# inside training loop\n",
    "loss = loss_fn(pred, label)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "\n",
    "This is the **standard MONAI workflow**:\n",
    "\n",
    "* MONAI loss\n",
    "* MONAI metrics\n",
    "* PyTorch optimizer\n",
    "* PyTorch gradient updates\n",
    "* MONAI transforms\n",
    "* MONAI datasets\n",
    "* MONAI models\n",
    "\n",
    "---\n",
    "\n",
    "# 9. Why MONAI Doesn't Replace Optimizers / Schedulers\n",
    "\n",
    "Because:\n",
    "\n",
    "* Medical imaging research uses **standard PyTorch optimizers**\n",
    "* Community wants compatibility with existing PyTorch training code\n",
    "* No real advantage in re-implementing optimizers\n",
    "\n",
    "So MONAI only extends the parts specifically needed for medical imaging.\n",
    "\n",
    "---\n",
    "\n",
    "# 10. Quick Summary Table\n",
    "\n",
    "| Component        | Use PyTorch? | Use MONAI?    | Notes                          |\n",
    "| ---------------- | ------------ | ------------- | ------------------------------ |\n",
    "| Loss             | ✔ optional   | ✔ recommended | Use MONAI for segmentation     |\n",
    "| Optimizer        | ✔            | ❌             | Always use PyTorch             |\n",
    "| Scheduler        | ✔            | ❌             | Standard PyTorch               |\n",
    "| AMP / GradScaler | ✔            | ❌             | From PyTorch                   |\n",
    "| Transforms       | ❌            | ✔             | MONAI only                     |\n",
    "| Metrics          | ❌            | ✔             | MONAI medical metrics          |\n",
    "| Models           | ❌            | ✔             | MONAI UNet / UNETR / SwinUNETR |\n",
    "| Datasets         | ❌            | ✔             | CacheDataset, SmartCache       |\n",
    "| Inferers         | ❌            | ✔             | sliding window inference       |\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
