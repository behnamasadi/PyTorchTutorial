{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corresponding-beauty",
   "metadata": {},
   "source": [
    "# PyTorch Coding Conventions\n",
    "`PEP 8` style mostly applies to pytorch, so the followings are the conventions and guidelines.\n",
    "## Importing modules\n",
    "**Correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-tyler",
   "metadata": {},
   "source": [
    "**Wrong**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-desert",
   "metadata": {},
   "source": [
    "## Classes\n",
    "should normally use the CapWords convention., However, it still seems that builtin or extension types written\n",
    "in C are more likely to have lowercase names (e.g., numpy.array, not numpy.Array).\n",
    "\n",
    "## Package and Module Names\n",
    "Modules should have short, all-lowercase names.\n",
    "\n",
    "## Type Variable Names\n",
    "Names of type variables introduced use CapWords\n",
    "\n",
    "## Function and Variable Names\n",
    "Function names should be lowercase, with words separated by underscores as necessary to improve readability.\n",
    "\n",
    "## Constants\n",
    "Constants are usually defined on a module level and written in all capital letters with underscores\n",
    "separating words. Examples include MAX_OVERFLOW and TOTAL.\n",
    "\n",
    "Refs [1](https://www.python.org/dev/peps/pep-0008/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-coating",
   "metadata": {},
   "source": [
    "# Pytorch Modules (torch.nn) vs Functions  (torch.nn.functional)\n",
    "\n",
    "The modules in `torch.nn` can be added or connected to other layers or network models.\n",
    "\n",
    "The `torch.nn.Functional` contains some useful functions like some arithmetical operations, activation functions, convolution operations, etc. However, these are not full layers so if you want to specify a layer of any kind you should use `torch.nn.Module.` The functions in `torch.nn.functional` are not the layers which have trainable parameters such as weights and bias terms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-annex",
   "metadata": {},
   "source": [
    "\n",
    "# Modules (torch.nn.Module)\n",
    "List of modules:\n",
    "\n",
    "- torch.Tensor()\n",
    "- torch.nn.Conv2d()\n",
    "- torch.nn.ReLU()\n",
    "- torch.nn.Softmax()\n",
    "- torch.nn.Dropout()\n",
    "- torch.nn.Linear()\n",
    "\n",
    "# Functions (torch.nn.Functional)\n",
    "List of functions:\n",
    "\n",
    "- torch.tensor(data=[2,3], dtype=torch.float32, device=device , requires_grad=False)\n",
    "- torch.nn.functional.conv2d()\n",
    "- torch.nn.functional.relu()\n",
    "- torch.nn.functional.softmax()\n",
    "- torch.nn.functional.dropout()\n",
    "- torch.nn.functional.linear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-imperial",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "A `torch.Tensor` is a multi-dimensional matrix containing elements of a single data type. `torch.Tensor` is an alias for the default tensor type (`torch.FloatTensor`).\n",
    "\n",
    "## Pytorch Data types and Tensor types\n",
    "Listf of most important data types:\n",
    "\n",
    "   \n",
    "\n",
    "Data type            |dtype =torch.dtype            | CPU tensor=torch.tensortype | GPU tensor=torch.tensortype\n",
    "---                  |-----                         |-----                        |-----  \n",
    "32-bit floating point|torch.float32 or torch.float  |torch.FloatTensor            |torch.cuda.FloatTensor\n",
    "64-bit floating point|torch.float64 or torch.double |torch.DoubleTensor           |torch.cuda.DoubleTensor\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aware-murder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type (torch.tensortype):  torch.cuda.FloatTensor\n",
      "dtype (torch.dtype): torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "a=torch.tensor(data=[2.0,3.0])\n",
    "print(\"Data type (torch.tensortype): \",a.type())\n",
    "print(\"dtype (torch.dtype):\", a.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-perry",
   "metadata": {},
   "source": [
    "### Moving tensor to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "separated-proof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type:  torch.cuda.FloatTensor\n",
      "dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "a=a.to(device)\n",
    "print(\"Data type (torch.tensortype): \",a.type())\n",
    "print(\"dtype (torch.dtype):\", a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-hawaiian",
   "metadata": {},
   "source": [
    "### Creating tensor on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "supposed-supervisor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type:  torch.cuda.FloatTensor\n",
      "dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor(data=[2.0,3.0], dtype=torch.float32, device=device)\n",
    "print(\"Data type (torch.tensortype): \",a.type())\n",
    "print(\"dtype (torch.dtype):\", a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-pontiac",
   "metadata": {},
   "source": [
    "### Creating tensor on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "excessive-happiness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type (torch.tensortype):  torch.FloatTensor\n",
      "dtype (torch.dtype): torch.float32\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor(data=[2.0,3.0], dtype=torch.float32, device=torch.device('cpu'))\n",
    "print(\"Data type (torch.tensortype): \",a.type())\n",
    "print(\"dtype (torch.dtype):\", a.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-butter",
   "metadata": {},
   "source": [
    "### Tesnor vs tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alpha-night",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type:  torch.cuda.FloatTensor\n",
      "dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor is an alias for the default tensor type (torch.FloatTensor).\n",
    "a=torch.Tensor(data=[2.0,3.0])\n",
    "print(\"Data type: \",a.type())\n",
    "print(\"dtype\", a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-factory",
   "metadata": {},
   "source": [
    "### Settings default tensor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compound-notebook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type (torch.tensortype):  torch.cuda.FloatTensor\n",
      "dtype (torch.dtype): torch.float32\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "a=torch.tensor(data=[2.0,3.0] )\n",
    "print(\"Data type (torch.tensortype): \",a.type())\n",
    "print(\"dtype (torch.dtype):\", a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-student",
   "metadata": {},
   "source": [
    "[List of data types](https://pytorch.org/docs/master/tensors.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-sailing",
   "metadata": {},
   "source": [
    "## Named Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "outstanding-worth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('N', 'C', 'H', 'W')\n",
      "('N', 'C', 'height', 'width')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-f372d359699e>:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1616554788289/work/c10/core/TensorImpl.h:934.)\n",
      "  imgs = torch.randn(1, 2, 2, 3 , names=('N', 'C', 'H', 'W'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.6034, -5.5537,  0.0113], names=('X',))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = torch.randn(1, 2, 2, 3 , names=('N', 'C', 'H', 'W'))\n",
    "print(imgs.names)\n",
    "\n",
    "renamed_imgs = imgs.rename(H='height', W='width')\n",
    "print(renamed_imgs.names)\n",
    "\n",
    "imgs = torch.randn(1, 2, 2, 3 , names=(None, 'C', 'H', 'W'))\n",
    "\n",
    "# Two names match if they are equal (string equality) or if at least one is None\n",
    "\n",
    "x = torch.randn(3, names=('X',))\n",
    "y = torch.randn(3)\n",
    "z = torch.randn(3, names=('Z',))\n",
    "\n",
    "x + y\n",
    "# error\n",
    "#x + z\n",
    "x + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-rolling",
   "metadata": {},
   "source": [
    "Refs [1](https://pytorch.org/docs/stable/named_tensor.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-property",
   "metadata": {},
   "source": [
    "# CUDA/ GPU infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "raising-uruguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n",
      "cuda device count 1\n",
      "current device is: 0\n",
      "device name GeForce MX150\n",
      "nvcc version: \n",
      "nvidia-smi:\n"
     ]
    }
   ],
   "source": [
    "# Make Sure That Pytorch Using GPU To Compute\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "if(torch.cuda.is_available()):\n",
    "    print('cuda is available')\n",
    "    print('cuda device count',torch.cuda.device_count())\n",
    "    print('current device is:',torch.cuda.current_device())\n",
    "    print('device name',torch.cuda.get_device_name(0))\n",
    "    print('nvcc version: ')\n",
    "    os.system('nvcc --version')\n",
    "    print('nvidia-smi:')\n",
    "    os.system('nvidia-smi')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-metabolism",
   "metadata": {},
   "source": [
    "## Operation on Tensor\n",
    "### view()\n",
    "PyTorch allows a tensor to be a View of an existing tensor (sharing the same underlying data with its base tensor, avoids explicit data copy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "second-opening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7549)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(2,6)\n",
    "print(x[0][0])\n",
    "y=x.view(4,3)\n",
    "y[0][0]=1.0\n",
    "print(x[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-psychiatry",
   "metadata": {},
   "source": [
    "### transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "prostate-rabbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2405, -0.7458,  0.4639],\n",
      "        [-1.7821,  2.1286, -2.7806]])\n",
      "tensor([[-1.2405, -1.7821],\n",
      "        [-0.7458,  2.1286],\n",
      "        [ 0.4639, -2.7806]])\n",
      "tensor([[-1.2405, -1.7821],\n",
      "        [-0.7458,  2.1286],\n",
      "        [ 0.4639, -2.7806]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "print(x) \n",
    "\n",
    "print(torch.t(x)) \n",
    "\n",
    "print(torch.transpose(x, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-mexican",
   "metadata": {},
   "source": [
    "### contiguous()\n",
    "### is_contiguous()\n",
    "### expand()\n",
    "### narrow()\n",
    "### squeeze()\n",
    "### values() \n",
    "### detach()\n",
    "### is_pinned()\n",
    "### is_shared()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-situation",
   "metadata": {},
   "source": [
    "### item()\n",
    "Use t`orch.Tensor.item()` to get a Python number from a tensor containing a single value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-bankruptcy",
   "metadata": {},
   "source": [
    "Refs: [1](https://pytorch.org/docs/master/tensor_view.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
