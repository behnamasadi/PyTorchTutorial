{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd0ee5b-5da8-4cee-a117-9f9d04937845",
   "metadata": {},
   "source": [
    "# Running Your PyTorch Projects on RunPod Using a Single Docker Image and GHCR\n",
    "\n",
    "This guide explains how to prepare your machine-learning projects for RunPod GPU compute using:\n",
    "\n",
    "* One repository: `PyTorchTutorial`\n",
    "* Multiple projects stored under:\n",
    "  `/home/behnam/workspace/PyTorchTutorial/projects/`\n",
    "* One Dockerfile\n",
    "* One `requirements.txt`\n",
    "* GitHub Container Registry (GHCR)\n",
    "* Automatic dataset download via `kagglehub`\n",
    "\n",
    "The result is a clean, scalable setup where **one Docker image** can run **any** of your Kaggle and PyTorch projects on RunPod.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Directory structure\n",
    "\n",
    "The repository is:\n",
    "\n",
    "```\n",
    "/home/$USERNAME/workspace/PyTorchTutorial/\n",
    "```\n",
    "\n",
    "Inside it, the relevant content for RunPod is only:\n",
    "\n",
    "```\n",
    "PyTorchTutorial/\n",
    "‚îî‚îÄ‚îÄ projects/\n",
    "      ‚îú‚îÄ‚îÄ BrainCancer-MRI/\n",
    "      ‚îú‚îÄ‚îÄ brain-mri/\n",
    "      ‚îú‚îÄ‚îÄ CIFAR10/\n",
    "      ‚îú‚îÄ‚îÄ Lung_Disease_Dataset/\n",
    "      ‚îú‚îÄ‚îÄ MNIST/\n",
    "      ‚îú‚îÄ‚îÄ segmentation/\n",
    "      ‚îî‚îÄ‚îÄ visual_odometry/\n",
    "```\n",
    "\n",
    "Each project has its own:\n",
    "\n",
    "* `train.py`\n",
    "* dataset loaders\n",
    "* configuration files\n",
    "\n",
    "RunPod will use only this `/projects` directory.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Create a single `requirements.txt`\n",
    "\n",
    "This file contains Python dependencies used by **all** projects.\n",
    "\n",
    "Create:\n",
    "\n",
    "\n",
    "[/home/$USERNAME/workspace/PyTorchTutorial/requirements.txt](../environment.yml)\n",
    "\n",
    "\n",
    "\n",
    "This ensures:\n",
    "\n",
    "* kagglehub works inside the container\n",
    "* all ML/vision utilities are available\n",
    "* all projects can run without installing extra packages\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Create a single Dockerfile\n",
    "\n",
    "Create:\n",
    "\n",
    "[/home/$USERNAME/workspace/PyTorchTutorial/Dockerfile](../Dockerfile)\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Build the Docker image locally\n",
    "\n",
    "Navigate to your repo root:\n",
    "\n",
    "```bash\n",
    "cd /home/$USERNAME/workspace/PyTorchTutorial/\n",
    "```\n",
    "\n",
    "Build the Docker image:\n",
    "\n",
    "```bash\n",
    "docker build -t ghcr.io/behnamasadi/kaggle-projects:latest .\n",
    "```\n",
    "\n",
    "\n",
    "Inside the container, check the size of the projects directory:\n",
    "\n",
    "```\n",
    "cd /workspace/projects\n",
    "du -sh .  # Human-readable size of the current directory\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "You now have a local image ready for upload.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Login to GitHub Container Registry (GHCR)\n",
    "\n",
    "Generate a GitHub PAT (Personal Access Token) with:\n",
    "\n",
    "* read:packages\n",
    "* write:packages\n",
    "\n",
    "Then login safely:\n",
    "\n",
    "```bash\n",
    "echo YOUR_GITHUB_TOKEN | docker login ghcr.io -u behnamasadi --password-stdin\n",
    "```\n",
    "\n",
    "This avoids insecure plain-text warnings.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Push the image to GHCR\n",
    "\n",
    "Execute:\n",
    "\n",
    "```bash\n",
    "docker push ghcr.io/behnamasadi/kaggle-projects:latest\n",
    "```\n",
    "\n",
    "Your image is now available from anywhere (including RunPod).\n",
    "\n",
    "---\n",
    "\n",
    "## 7. RunPod Setup\n",
    "\n",
    "Go to:\n",
    "\n",
    "RunPod Dashboard ‚Üí GPU Cloud ‚Üí Deploy Pod\n",
    "\n",
    "Choose:\n",
    "\n",
    "* Container image:\n",
    "  `ghcr.io/behnamasadi/kaggle-projects:latest`\n",
    "* GPU type: RTX 4090 / RTX A6000 / A100 (depending on project)\n",
    "* Volume: optional (not required because kagglehub downloads automatically)\n",
    "\n",
    "\n",
    "set the Environment Variables:\n",
    "\n",
    " \n",
    "| Parameter | Value |\n",
    "| :--- | :--- |\n",
    "| **KAGGLE\\_USERNAME** | asadibehnam |\n",
    "| **KAGGLE\\_KEY** | xxxxxx |\n",
    "| **WANDB\\_API\\_KEY** | xxxxxxxx |\n",
    "| **HOME** | /workspace |\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "Launch the pod.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Inside the RunPod terminal\n",
    "\n",
    "When the pod is running:\n",
    "\n",
    "Open ‚Üí Web Terminal\n",
    "\n",
    "You will see the Docker working directory:\n",
    "\n",
    "```\n",
    "/workspace/projects/\n",
    "```\n",
    "\n",
    "You can now run any project.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Running individual projects\n",
    "\n",
    "#### Example: Lung Disease Dataset\n",
    "\n",
    "```bash\n",
    "cd /workspace/projects/Lung_Disease_Dataset\n",
    "python train.py\n",
    "```\n",
    "\n",
    "#### Example: BrainCancer MRI\n",
    "\n",
    "```bash\n",
    "cd /workspace/projects/BrainCancer-MRI\n",
    "python train.py\n",
    "```\n",
    "\n",
    "#### Example: CIFAR10\n",
    "\n",
    "```bash\n",
    "cd /workspace/projects/CIFAR10\n",
    "python train.py\n",
    "```\n",
    "\n",
    "Each project works independently using the same container.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Using kagglehub for automatic dataset download\n",
    "\n",
    "In each project's `train.py`, you can download datasets like:\n",
    "\n",
    "```python\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "dataset_path = kagglehub.dataset_download(\"khaleddev/lungs-disease-dataset-broken\")\n",
    "print(\"Dataset stored at:\", dataset_path)\n",
    "```\n",
    "\n",
    "This will store data in:\n",
    "\n",
    "```\n",
    "/root/.cache/kagglehub/datasets/<dataset-name>/versions/<version>/\n",
    "```\n",
    "\n",
    "Notes:\n",
    "\n",
    "* First run downloads the dataset.\n",
    "* Subsequent runs reuse cached versions.\n",
    "* No need to upload datasets to RunPod or Docker.\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Optional: project-level dataset symlink\n",
    "\n",
    "If you want a clean interface inside each project:\n",
    "\n",
    "```python\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "local_path = \"data/raw\"\n",
    "\n",
    "if not os.path.exists(local_path):\n",
    "    os.symlink(dataset_path, local_path)\n",
    "```\n",
    "\n",
    "Then your dataloader can always use:\n",
    "\n",
    "```\n",
    "data/raw/\n",
    "```\n",
    "\n",
    "No matter which Kaggle dataset you download.\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Logging with TensorBoard or W&B\n",
    "\n",
    "TensorBoard:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir logs --port 6006\n",
    "```\n",
    "\n",
    "Then expose port 6006 in RunPod settings.\n",
    "\n",
    "Weights & Biases:\n",
    "\n",
    "* Works automatically if you `wandb login`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ce25e-9330-4d46-90af-b2b590fe4e98",
   "metadata": {},
   "source": [
    "## 13. Download Artifacts from wandb\n",
    "\n",
    "```python\n",
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('behnamasadi/lung-disease-classification/run-ftbild81-last_model.pth:v0', type='unspecified')\n",
    "artifact_dir = artifact.download()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44bc6d-e5f6-48e1-8e14-c27d903bdd05",
   "metadata": {},
   "source": [
    "## 14. **Clean all Docker containers and images**\n",
    "Here are the commands to **clean all Docker containers and images** safely and completely.\n",
    "\n",
    "#### 1. Remove **all containers**\n",
    "\n",
    "First stop all running containers:\n",
    "\n",
    "```bash\n",
    "docker stop $(docker ps -aq)\n",
    "```\n",
    "\n",
    "Then remove all containers:\n",
    "\n",
    "```bash\n",
    "docker rm $(docker ps -aq)\n",
    "```\n",
    "\n",
    "#### 2. Remove **all images**\n",
    "\n",
    "```bash\n",
    "docker rmi $(docker images -aq)\n",
    "```\n",
    "\n",
    "#### 3. Remove **all volumes**\n",
    "\n",
    "```bash\n",
    "docker volume rm $(docker volume ls -q)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### 5. Clean everything with a single prune command\n",
    "\n",
    "This removes **containers, images, networks, build cache** etc.\n",
    "\n",
    "```bash\n",
    "docker system prune -a --volumes\n",
    "```\n",
    "\n",
    "This is the most complete cleanup.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b9f6d2-7ad3-4f43-be3b-766470d88123",
   "metadata": {},
   "source": [
    "## 15. RunPod CLI\n",
    "\n",
    "#### Download and install via wget\n",
    "```bash\n",
    "wget -qO- cli.runpod.net | sudo bash\n",
    "```\n",
    "\n",
    "\n",
    "#### Create a Key\n",
    "\n",
    "\n",
    "1. Go to [https://www.runpod.io/console/user/settings](https://www.runpod.io/console/user/settings)\n",
    "2. Create an API key\n",
    "3. Paste it in the command above\n",
    "\n",
    "Login:\n",
    "\n",
    "```bash\n",
    "runpodctl config --apiKey rpa_xxxxxxxxxxxxxxxxxxxx\n",
    "```\n",
    "\n",
    "will give you:\n",
    "\n",
    "```bash\n",
    "Configuration saved to file: /home/behnam/.runpod/config.toml\n",
    "```\n",
    "---\n",
    "\n",
    "#### **Download files from your pod**\n",
    "\n",
    "\n",
    "```bash\n",
    "runpodctl get pod\n",
    "ID            \tNAME                    \tGPU        \tIMAGE NAME                                \tSTATUS  \n",
    "ftwh601f8kb14e\tconceptual_blush_chicken\t1 RTX A6000\tghcr.io/behnamasadi/kaggle-projects:latest\tRUNNING\t\n",
    "```\n",
    "\n",
    "you have the pod ID:\n",
    "\n",
    "```\n",
    "ftwh601f8kb14e\n",
    "```\n",
    "\n",
    "And you want to download everything inside:\n",
    "\n",
    "```\n",
    "/workspace/projects/Lung_Disease_Dataset/checkpoints\n",
    "```\n",
    "\n",
    "You can download **the whole folder** or **specific files**.\n",
    "\n",
    "**Important:** `runpodctl receive` **does NOT take a pod-path directly.**\n",
    "It requires a **‚Äútransfer code‚Äù** that is generated **inside the pod** using `runpodctl send`.\n",
    "\n",
    "\n",
    "\n",
    "So here is the correct workflow:\n",
    "\n",
    "#### ‚úÖ Step 1 ‚Äî SSH into your pod\n",
    "\n",
    "```\n",
    "ssh <your_ssh_user>@ssh.runpod.io\n",
    "```\n",
    "\n",
    "Your prompt should now be inside the pod:\n",
    "\n",
    "```\n",
    "pod-user@<pod>:/workspace$\n",
    "```\n",
    "\n",
    "#### ‚úÖ Step 2 ‚Äî Inside the pod, generate a ‚Äúsend code‚Äù\n",
    "\n",
    "This will create a code that allows your **local machine** to download the file:\n",
    "\n",
    "```\n",
    "runpodctl send /workspace/projects/Lung_Disease_Dataset/checkpoints/best_model.pth\n",
    "```\n",
    "\n",
    "It will output something like:\n",
    "\n",
    "```\n",
    "runpodctl-receive: your code is:\n",
    "abc123-def456-ghi789\n",
    "```\n",
    "\n",
    "Copy that code.\n",
    "\n",
    "#### ‚úÖ Step 3 ‚Äî On your local machine, download using that code\n",
    "\n",
    "On your laptop:\n",
    "\n",
    "```\n",
    "runpodctl receive abc123-def456-ghi789=./best_model.pth\n",
    "```\n",
    "\n",
    "This **will download the file**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìå To download a whole folder\n",
    "\n",
    "Inside the pod:\n",
    "\n",
    "```\n",
    "cd /workspace/projects/Lung_Disease_Dataset\n",
    "runpodctl send checkpoints\n",
    "```\n",
    "\n",
    "It will output a code like:\n",
    "\n",
    "```\n",
    "runpodctl-receive: your code is:\n",
    "xyz111-uvw222-rst333\n",
    "```\n",
    "\n",
    "On your local machine:\n",
    "\n",
    "```\n",
    "runpodctl receive xyz111-uvw222-rst333=./checkpoints\n",
    "```\n",
    "\n",
    "It will download the entire folder recursively.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
