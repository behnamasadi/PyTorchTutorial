{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd0ee5b-5da8-4cee-a117-9f9d04937845",
   "metadata": {},
   "source": [
    "# Running Your PyTorch Projects on RunPod Using a Single Docker Image and GHCR\n",
    "\n",
    "This guide explains how to prepare your machine-learning projects for RunPod GPU compute using:\n",
    "\n",
    "* One repository: `PyTorchTutorial`\n",
    "* Multiple projects stored under:\n",
    "  `/home/behnam/workspace/PyTorchTutorial/projects/`\n",
    "* One Dockerfile\n",
    "* One `requirements.txt`\n",
    "* GitHub Container Registry (GHCR)\n",
    "* Automatic dataset download via `kagglehub`\n",
    "\n",
    "The result is a clean, scalable setup where **one Docker image** can run **any** of your Kaggle and PyTorch projects on RunPod.\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Directory structure\n",
    "\n",
    "The repository is:\n",
    "\n",
    "```\n",
    "/home/$USERNAME/workspace/PyTorchTutorial/\n",
    "```\n",
    "\n",
    "Inside it, the relevant content for RunPod is only:\n",
    "\n",
    "```\n",
    "PyTorchTutorial/\n",
    "└── projects/\n",
    "      ├── BrainCancer-MRI/\n",
    "      ├── brain-mri/\n",
    "      ├── CIFAR10/\n",
    "      ├── Lung_Disease_Dataset/\n",
    "      ├── MNIST/\n",
    "      ├── segmentation/\n",
    "      └── visual_odometry/\n",
    "```\n",
    "\n",
    "Each project has its own:\n",
    "\n",
    "* `train.py`\n",
    "* dataset loaders\n",
    "* configuration files\n",
    "\n",
    "RunPod will use only this `/projects` directory.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Create a single `requirements.txt`\n",
    "\n",
    "This file contains Python dependencies used by **all** projects.\n",
    "\n",
    "Create:\n",
    "\n",
    "```\n",
    "/home/$USERNAME/workspace/PyTorchTutorial/requirements.txt\n",
    "```\n",
    "\n",
    "Content:\n",
    "\n",
    "```\n",
    "torch\n",
    "torchvision\n",
    "torchaudio\n",
    "timm\n",
    "opencv-python\n",
    "numpy\n",
    "pandas\n",
    "pyyaml\n",
    "scikit-learn\n",
    "albumentations\n",
    "matplotlib\n",
    "tqdm\n",
    "tensorboard\n",
    "wandb\n",
    "kagglehub\n",
    "```\n",
    "\n",
    "This ensures:\n",
    "\n",
    "* kagglehub works inside the container\n",
    "* all ML/vision utilities are available\n",
    "* all projects can run without installing extra packages\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Create a single Dockerfile\n",
    "\n",
    "Create:\n",
    "\n",
    "```\n",
    "/home/$USERNAME/workspace/PyTorchTutorial/Dockerfile\n",
    "```\n",
    "\n",
    "Content:\n",
    "\n",
    "```dockerfile\n",
    "FROM pytorch/pytorch:2.2.0-cuda12.1-cudnn8-runtime\n",
    "\n",
    "ENV DEBIAN_FRONTEND=noninteractive\n",
    "\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    git wget unzip ffmpeg libgl1 libglib2.0-0 \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "WORKDIR /workspace\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Only copy the Kaggle projects folder\n",
    "COPY projects/ projects/\n",
    "\n",
    "CMD [\"bash\"]\n",
    "```\n",
    "\n",
    "Notes:\n",
    "\n",
    "* This image is lightweight.\n",
    "* Only the `projects/` directory is included in the image.\n",
    "* Default CMD is `bash`, allowing you to run any project manually.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Build the Docker image locally\n",
    "\n",
    "Navigate to your repo root:\n",
    "\n",
    "```bash\n",
    "cd /home/$USERNAME/workspace/PyTorchTutorial/\n",
    "```\n",
    "\n",
    "Build the Docker image:\n",
    "\n",
    "```bash\n",
    "docker build -t ghcr.io/behnamasadi/kaggle-projects:latest .\n",
    "```\n",
    "\n",
    "You now have a local image ready for upload.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Login to GitHub Container Registry (GHCR)\n",
    "\n",
    "Generate a GitHub PAT (Personal Access Token) with:\n",
    "\n",
    "* read:packages\n",
    "* write:packages\n",
    "\n",
    "Then login safely:\n",
    "\n",
    "```bash\n",
    "echo YOUR_GITHUB_TOKEN | docker login ghcr.io -u behnamasadi --password-stdin\n",
    "```\n",
    "\n",
    "This avoids insecure plain-text warnings.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. Push the image to GHCR\n",
    "\n",
    "Execute:\n",
    "\n",
    "```bash\n",
    "docker push ghcr.io/behnamasadi/kaggle-projects:latest\n",
    "```\n",
    "\n",
    "Your image is now available from anywhere (including RunPod).\n",
    "\n",
    "---\n",
    "\n",
    "# 7. RunPod Setup\n",
    "\n",
    "Go to:\n",
    "\n",
    "RunPod Dashboard → GPU Cloud → Deploy Pod\n",
    "\n",
    "Choose:\n",
    "\n",
    "* Container image:\n",
    "  `ghcr.io/behnamasadi/kaggle-projects:latest`\n",
    "* GPU type: RTX 4090 / A6000 / A100 (depending on project)\n",
    "* Volume: optional (not required because kagglehub downloads automatically)\n",
    "\n",
    "Launch the pod.\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Inside the RunPod terminal\n",
    "\n",
    "When the pod is running:\n",
    "\n",
    "Open → Web Terminal\n",
    "\n",
    "You will see the Docker working directory:\n",
    "\n",
    "```\n",
    "/workspace/projects/\n",
    "```\n",
    "\n",
    "You can now run any project.\n",
    "\n",
    "---\n",
    "\n",
    "# 9. Running individual projects\n",
    "\n",
    "### Example: Lung Disease Dataset\n",
    "\n",
    "```bash\n",
    "cd /workspace/projects/Lung_Disease_Dataset\n",
    "python train.py\n",
    "```\n",
    "\n",
    "### Example: BrainCancer MRI\n",
    "\n",
    "```bash\n",
    "cd /workspace/projects/BrainCancer-MRI\n",
    "python train.py\n",
    "```\n",
    "\n",
    "### Example: CIFAR10\n",
    "\n",
    "```bash\n",
    "cd /workspace/projects/CIFAR10\n",
    "python train.py\n",
    "```\n",
    "\n",
    "Each project works independently using the same container.\n",
    "\n",
    "---\n",
    "\n",
    "# 10. Using kagglehub for automatic dataset download\n",
    "\n",
    "In each project's `train.py`, you can download datasets like:\n",
    "\n",
    "```python\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "dataset_path = kagglehub.dataset_download(\"khaleddev/lungs-disease-dataset-broken\")\n",
    "print(\"Dataset stored at:\", dataset_path)\n",
    "```\n",
    "\n",
    "This will store data in:\n",
    "\n",
    "```\n",
    "/root/.cache/kagglehub/datasets/<dataset-name>/versions/<version>/\n",
    "```\n",
    "\n",
    "Notes:\n",
    "\n",
    "* First run downloads the dataset.\n",
    "* Subsequent runs reuse cached versions.\n",
    "* No need to upload datasets to RunPod or Docker.\n",
    "\n",
    "---\n",
    "\n",
    "# 11. Optional: project-level dataset symlink\n",
    "\n",
    "If you want a clean interface inside each project:\n",
    "\n",
    "```python\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "local_path = \"data/raw\"\n",
    "\n",
    "if not os.path.exists(local_path):\n",
    "    os.symlink(dataset_path, local_path)\n",
    "```\n",
    "\n",
    "Then your dataloader can always use:\n",
    "\n",
    "```\n",
    "data/raw/\n",
    "```\n",
    "\n",
    "No matter which Kaggle dataset you download.\n",
    "\n",
    "---\n",
    "\n",
    "# 12. Logging with TensorBoard or W&B\n",
    "\n",
    "TensorBoard:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir logs --port 6006\n",
    "```\n",
    "\n",
    "Then expose port 6006 in RunPod settings.\n",
    "\n",
    "Weights & Biases:\n",
    "\n",
    "* Works automatically if you `wandb login`.\n",
    "\n",
    "---\n",
    "\n",
    "# 13. Summary\n",
    "\n",
    "You now have:\n",
    "\n",
    "### One repository:\n",
    "\n",
    "`PyTorchTutorial`\n",
    "\n",
    "### One Docker image:\n",
    "\n",
    "```\n",
    "ghcr.io/behnamasadi/kaggle-projects:latest\n",
    "```\n",
    "\n",
    "### One dependency file:\n",
    "\n",
    "`requirements.txt`\n",
    "\n",
    "### One folder containing all Kaggle challenges:\n",
    "\n",
    "`projects/`\n",
    "\n",
    "### Automatic dataset download with:\n",
    "\n",
    "`kagglehub.dataset_download()`\n",
    "\n",
    "### Training on RunPod simply requires:\n",
    "\n",
    "```\n",
    "cd /workspace/projects/<project_name>\n",
    "python train.py\n",
    "```\n",
    "\n",
    "This setup is clean, scalable, and GPU-efficient. Perfect for solving many Kaggle challenges from one unified environment.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b24642-7aed-445a-9128-d80d83b6f62b",
   "metadata": {},
   "source": [
    "To verify that no training data slipped into `ghcr.io/behnamasadi/kaggle-projects:latest`, you can inspect the image in a few ways:\n",
    "\n",
    "1. **Check file sizes in the container:**\n",
    "   ```bash\n",
    "   docker run --rm -it ghcr.io/behnamasadi/kaggle-projects:latest bash\n",
    "   ```\n",
    "   Inside the container:\n",
    "   ```bash\n",
    "   du -sh /workspace/projects/* | sort -h\n",
    "   ```\n",
    "   Large entries usually mean data/checkpoints were copied.\n",
    "\n",
    "2. **Find suspicious directories:**\n",
    "   ```bash\n",
    "   find /workspace/projects -maxdepth 4 -type d \\( -name \"data\" -o -name \"datasets\" -o -name \"samples\" -o -name \"checkpoints\" \\)\n",
    "   ```\n",
    "   If these directories exist but should be empty, inspect or remove them.\n",
    "\n",
    "3. **Confirm `.dockerignore` rules:**\n",
    "   Ensure paths like `projects/**/data/**`, `projects/**/runs/**`, `projects/**/checkpoints/**`, etc. are ignored. This prevents train/val/test folders, wandb logs, mlruns, and similar artifacts from entering the build context.\n",
    "\n",
    "4. **Check `docker history`:**\n",
    "   ```bash\n",
    "   docker history ghcr.io/behnamasadi/kaggle-projects:latest\n",
    "   ```\n",
    "   Look for large layers that might indicate unintended file copies.\n",
    "\n",
    "If the `.dockerignore` rules are in place and you don’t see unexpectedly large directories inside `/workspace/projects`, you’re safe—only code/configs should be present. Let me know if you want a script to automate the inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44bc6d-e5f6-48e1-8e14-c27d903bdd05",
   "metadata": {},
   "source": [
    "Here are the commands to **clean all Docker containers and images** safely and completely.\n",
    "\n",
    "## 1. Remove **all containers**\n",
    "\n",
    "First stop all running containers:\n",
    "\n",
    "```bash\n",
    "docker stop $(docker ps -aq)\n",
    "```\n",
    "\n",
    "Then remove all containers:\n",
    "\n",
    "```bash\n",
    "docker rm $(docker ps -aq)\n",
    "```\n",
    "\n",
    "## 2. Remove **all images**\n",
    "\n",
    "```bash\n",
    "docker rmi $(docker images -aq)\n",
    "```\n",
    "\n",
    "## 3. Remove **all volumes**\n",
    "\n",
    "```bash\n",
    "docker volume rm $(docker volume ls -q)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## 5. Clean everything with a single prune command\n",
    "\n",
    "This removes **containers, images, networks, build cache** etc.\n",
    "\n",
    "```bash\n",
    "docker system prune -a --volumes\n",
    "```\n",
    "\n",
    "This is the most complete cleanup.\n",
    "\n",
    "---\n",
    "\n",
    "## If you want the shortest version\n",
    "\n",
    "### Clean EVERYTHING:\n",
    "\n",
    "```bash\n",
    "docker system prune -a --volumes\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d4a33a-2d51-4a30-8954-b77f6b0f0c7a",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Ensure `.dockerignore` excludes project data\n",
    "Your repo-level `.dockerignore` already has patterns such as `projects/**/data/**`, `projects/**/checkpoints/**`, etc. After accepting that file, the build context will skip every large folder inside each project (including `segmentation`). Double-check the file contains the block below (order matters so the excludes win):\n",
    "\n",
    "```\n",
    "*\n",
    "!projects/\n",
    "!projects/**\n",
    "!requirements.txt\n",
    "!Dockerfile\n",
    "!.dockerignore\n",
    "projects/**/checkpoints/**\n",
    "projects/**/runs/**\n",
    "projects/**/wandb/**\n",
    "projects/**/outputs/**\n",
    "projects/**/logs/**\n",
    "projects/**/artifacts/**\n",
    "projects/**/mlruns/**\n",
    "projects/**/mlartifacts/**\n",
    "projects/**/tensorboard/**\n",
    "projects/**/tb_logs/**\n",
    "projects/**/data/**\n",
    "projects/**/datasets/**\n",
    "projects/**/downloaded_data/**\n",
    "projects/**/kitti_dataset/**\n",
    "projects/**/samples/**\n",
    "```\n",
    "\n",
    "(Plus the re-inclusion lines for small config files.)\n",
    "\n",
    "### 2. Rebuild the image with a clean context\n",
    "Because the previous image was built before these ignore rules existed, you need a fresh build. From `/home/$USER/workspace/PyTorchTutorial`:\n",
    "\n",
    "```bash\n",
    "docker build --no-cache -t ghcr.io/behnamasadi/kaggle-projects:latest .\n",
    "docker push ghcr.io/behnamasadi/kaggle-projects:latest\n",
    "```\n",
    "\n",
    "### 3. Verify size in the new container\n",
    "After rebuilding, run the container and check:\n",
    "\n",
    "```bash\n",
    "docker run --rm -it ghcr.io/behnamasadi/kaggle-projects:latest bash\n",
    "du -sh /workspace/projects/* | sort -h\n",
    "```\n",
    "\n",
    "You should now see only code/config footprints—on the order of kilobytes or a few megabytes per project—not hundreds of MB. You can also spot-check:\n",
    "\n",
    "```bash\n",
    "find /workspace/projects/segmentation -maxdepth 2 -type d -name 'data' -o -name 'checkpoints' -o -name 'wandb'\n",
    "```\n",
    "\n",
    "Those directories should no longer exist inside the image.\n",
    "\n",
    "If you still notice large artifacts, let me know and we can add more targeted patterns (for example, if there’s a differently named data folder I missed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae69f29-e25c-455b-a6a5-41e74785a206",
   "metadata": {},
   "source": [
    "You can vet the image right after building it locally, before any push. Handy checks:\n",
    "\n",
    "- **Build (no push yet):**\n",
    "  ```\n",
    "  cd /home/$USER/workspace/PyTorchTutorial\n",
    "  docker build -t kaggle-projects:test .\n",
    "  ```\n",
    "\n",
    "- **Inspect size w/out running:**\n",
    "  ```\n",
    "  docker image inspect kaggle-projects:test --format='{{.Size}}'\n",
    "  docker history --no-trunc kaggle-projects:test\n",
    "  ```\n",
    "\n",
    "- **Open a shell inside the image:**\n",
    "  ```\n",
    "  docker run --rm -it kaggle-projects:test bash\n",
    "  ```\n",
    "\n",
    "- **Check project footprints:**\n",
    "  ```\n",
    "  du -sh /workspace/projects/* | sort -h\n",
    "  ```\n",
    "\n",
    "- **Look for stray data folders:**\n",
    "  ```\n",
    "  find /workspace/projects -maxdepth 4 -type d \\\n",
    "      \\( -name data -o -name datasets -o -name checkpoints -o -name runs -o -name wandb \\)\n",
    "  ```\n",
    "\n",
    "- **See whether `data` dirs are empty:**\n",
    "  ```\n",
    "  for d in $(find /workspace/projects -maxdepth 3 -type d -name data); do\n",
    "      echo \"$d\"; ls -al \"$d\";\n",
    "  done\n",
    "  ```\n",
    "\n",
    "If the `du` output stays in KB/MB and the targeted `find` commands return nothing (or only expected lightweight files), you’re safe. When satisfied, tag/push:\n",
    "\n",
    "```\n",
    "docker tag kaggle-projects:test ghcr.io/behnamasadi/kaggle-projects:latest\n",
    "docker push ghcr.io/behnamasadi/kaggle-projects:latest\n",
    "```\n",
    "\n",
    "This way you never push a bloated image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
