{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf89cb1b-c237-4732-b7c2-e478399aa3ff",
   "metadata": {},
   "source": [
    "# **Machine Learning Project Structure & Infrastructure Best Practices**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# **1. Why Project Structure Matters**\n",
    "\n",
    "Machine learning projects tend to become:\n",
    "\n",
    "* a mixture of scripts, notebooks, configs, logs, datasets\n",
    "* code called from different locations (VS Code, Jupyter, CLI, Slurm, Hydra, wandb)\n",
    "* full of fragile relative paths, duplicated logic, and ad-hoc scripts\n",
    "\n",
    "If you don’t impose structure early, the project turns into chaos.\n",
    "\n",
    "A well-designed structure ensures:\n",
    "\n",
    "* reproducibility\n",
    "* clarity and separation of responsibilities\n",
    "* stable paths regardless of where the interpreter is launched\n",
    "* easy packaging / deployment / dockerization\n",
    "* compatibility with MLFlow, wandb, hydra, DVC, and CI/CD\n",
    "* easier onboarding of collaborators\n",
    "\n",
    "Below is the structure used by professional teams.\n",
    "\n",
    "---\n",
    "\n",
    "# **2. The Recommended ML Project Layout (“src layout”)**\n",
    "\n",
    "This is the **modern, PyPA-endorsed, ML-industry standard**.\n",
    "\n",
    "```\n",
    "myproject/\n",
    "│\n",
    "├── pyproject.toml\n",
    "├── README.md\n",
    "├── LICENSE\n",
    "│\n",
    "├── src/\n",
    "│   └── myproject/\n",
    "│       ├── __init__.py\n",
    "│       ├── core/\n",
    "│       │   ├── training.py\n",
    "│       │   ├── evaluation.py\n",
    "│       │   └── model_builder.py\n",
    "│       │\n",
    "│       ├── data/\n",
    "│       │   ├── loaders.py\n",
    "│       │   └── dataset_utils.py\n",
    "│       │\n",
    "│       └── utils/\n",
    "│           ├── __init__.py\n",
    "│           └── paths.py\n",
    "│\n",
    "├── notebooks/\n",
    "│   └── experiments.ipynb\n",
    "│\n",
    "├── scripts/\n",
    "│   ├── train.py\n",
    "│   ├── evaluate.py\n",
    "│   ├── infer.py\n",
    "│   └── prepare_data.py\n",
    "│\n",
    "├── configs/\n",
    "│   ├── train.yaml\n",
    "│   ├── eval.yaml\n",
    "│   └── model.yaml\n",
    "│\n",
    "├── data/\n",
    "│   ├── raw/\n",
    "│   ├── processed/\n",
    "│   └── metadata/\n",
    "│\n",
    "├── checkpoints/\n",
    "└── logs/\n",
    "```\n",
    "\n",
    "This solves 99% of file-path issues and keeps everything clean and scalable.\n",
    "\n",
    "---\n",
    "\n",
    "# **3. What Each Folder Is For (Professional Explanation)**\n",
    "\n",
    "### **3.1 src/myproject/** — Your importable Python package\n",
    "\n",
    "Contains all reusable code.\n",
    "\n",
    "If someone runs:\n",
    "\n",
    "```python\n",
    "pip install .\n",
    "```\n",
    "\n",
    "this is the only folder that becomes importable.\n",
    "\n",
    "Inside:\n",
    "\n",
    "### **core/**\n",
    "\n",
    "Contains the *logic*:\n",
    "\n",
    "* training loop\n",
    "* evaluation / metrics\n",
    "* model builder\n",
    "* loss functions\n",
    "* augmentation pipeline\n",
    "\n",
    "### **data/**\n",
    "\n",
    "Contains:\n",
    "\n",
    "* dataset utilities\n",
    "* PyTorch DataLoaders\n",
    "* transforms\n",
    "* data preprocessing modules\n",
    "\n",
    "### **utils/**\n",
    "\n",
    "Contains utility functions:\n",
    "\n",
    "* stable `project_root()`\n",
    "* logging setup\n",
    "* reproducibility utilities\n",
    "* file/resource handling\n",
    "* argument parsing\n",
    "\n",
    "Never mix ML logic with utilities.\n",
    "\n",
    "---\n",
    "\n",
    "### **3.2 scripts/**\n",
    "\n",
    "Contains *executable scripts* only:\n",
    "\n",
    "* train.py\n",
    "* evaluate.py\n",
    "* infer.py\n",
    "* hyperparameter search\n",
    "* data preparation\n",
    "\n",
    "Scripts should:\n",
    "\n",
    "* be short\n",
    "* only orchestrate\n",
    "* never define logic\n",
    "* call functions from `src/myproject/**`\n",
    "\n",
    "---\n",
    "\n",
    "### **3.3 configs/**\n",
    "\n",
    "All configurations live here:\n",
    "\n",
    "* hyperparameters\n",
    "* model architecture names\n",
    "* dataset paths\n",
    "* optimizer settings\n",
    "* experiment metadata\n",
    "\n",
    "Even without Hydra, YAML configs are crucial for reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "### **3.4 data/**\n",
    "\n",
    "Organized datasets:\n",
    "\n",
    "```\n",
    "data/raw/\n",
    "data/processed/\n",
    "data/metadata/\n",
    "```\n",
    "\n",
    "NEVER check in large raw datasets to GitHub.\n",
    "Use `.gitignore`.\n",
    "\n",
    "---\n",
    "\n",
    "### **3.5 notebooks/**\n",
    "\n",
    "Keep notebooks separate from scripts.\n",
    "\n",
    "Rules:\n",
    "\n",
    "* notebooks explore, scripts run\n",
    "* never import notebooks from code\n",
    "* never put logic inside notebooks\n",
    "* notebooks should call functions from `src/myproject`\n",
    "\n",
    "---\n",
    "\n",
    "### **3.6 checkpoints/**\n",
    "\n",
    "Saved model weights.\n",
    "\n",
    "Rules:\n",
    "\n",
    "* never commit them to GitHub\n",
    "* use checkpoints with timestamps\n",
    "* optionally integrate with DVC or wandb.artifacts\n",
    "\n",
    "---\n",
    "\n",
    "### **3.7 logs/**\n",
    "\n",
    "Training logs, MLFlow, wandb outputs.\n",
    "\n",
    "Not version controlled.\n",
    "\n",
    "---\n",
    "\n",
    "# **4. The Most Important Utility in ML Projects: Stable Paths**\n",
    "\n",
    "You **must not** depend on:\n",
    "\n",
    "* the current working directory\n",
    "* where VS Code launched the Python file\n",
    "* where a Jupyter kernel was started\n",
    "* how Hydra changed your cwd\n",
    "\n",
    "You always resolve paths using code relative to the repository root.\n",
    "\n",
    "A professional utility module:\n",
    "\n",
    "### `src/myproject/utils/paths.py`\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "import importlib.resources as ir\n",
    "import sys\n",
    "\n",
    "_MARKERS = [\"pyproject.toml\", \".git\"]\n",
    "\n",
    "def project_root() -> Path:\n",
    "    here = Path(__file__).resolve()\n",
    "    for p in (here, *here.parents):\n",
    "        if any((p / m).exists() for m in _MARKERS):\n",
    "            return p\n",
    "    return here.parent\n",
    "\n",
    "def entry_script_dir() -> Path | None:\n",
    "    try:\n",
    "        p = Path(sys.argv[0]).resolve()\n",
    "        return p.parent if p.exists() else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def resource_path(*parts: str) -> Path:\n",
    "    root = project_root()\n",
    "    return root.joinpath(*parts)\n",
    "```\n",
    "\n",
    "This solves everything.\n",
    "\n",
    "---\n",
    "\n",
    "# **5. Best Practices for ML Code Structure**\n",
    "\n",
    "## **5.1 Training code best practices**\n",
    "\n",
    "Training code lives in:\n",
    "\n",
    "```\n",
    "src/myproject/core/training.py\n",
    "```\n",
    "\n",
    "Training scripts:\n",
    "\n",
    "```\n",
    "scripts/train.py\n",
    "```\n",
    "\n",
    "Call the training logic like:\n",
    "\n",
    "```python\n",
    "from myproject.core.training import train\n",
    "from myproject.utils import resource_path\n",
    "import yaml\n",
    "\n",
    "cfg = yaml.safe_load(open(resource_path(\"configs\", \"train.yaml\")))\n",
    "train(cfg)\n",
    "```\n",
    "\n",
    "Your script remains small and orchestrational.\n",
    "\n",
    "---\n",
    "\n",
    "## **5.2 Evaluation code**\n",
    "\n",
    "* Evaluate only by loading a model + dataset\n",
    "* Keep clean separation between training and evaluation logic\n",
    "* Put all metrics in `evaluation.py`\n",
    "\n",
    "---\n",
    "\n",
    "## **5.3 Model builder pattern**\n",
    "\n",
    "Files like:\n",
    "\n",
    "```\n",
    "src/myproject/core/model_builder.py\n",
    "```\n",
    "\n",
    "Provide a function:\n",
    "\n",
    "```python\n",
    "def build_model(cfg):\n",
    "    name = cfg[\"name\"]\n",
    "    num_classes = cfg[\"num_classes\"]\n",
    "    ...\n",
    "```\n",
    "\n",
    "This keeps `train.py` clean.\n",
    "\n",
    "---\n",
    "\n",
    "## **5.4 Config files**\n",
    "\n",
    "Use YAML for hyperparameters.\n",
    "\n",
    "Example:\n",
    "\n",
    "`configs/train.yaml`:\n",
    "\n",
    "```yaml\n",
    "model:\n",
    "  name: resnet18\n",
    "  num_classes: 10\n",
    "\n",
    "training:\n",
    "  epochs: 30\n",
    "  lr: 0.001\n",
    "\n",
    "data:\n",
    "  batch_size: 32\n",
    "  train_dir: data/raw/train\n",
    "  val_dir: data/raw/val\n",
    "```\n",
    "\n",
    "Configs make experiments reproducible.\n",
    "\n",
    "---\n",
    "\n",
    "## **5.5 Use logging, not print()**\n",
    "\n",
    "Create:\n",
    "\n",
    "```\n",
    "src/myproject/utils/logger.py\n",
    "```\n",
    "\n",
    "Use python’s `logging` with a timestamp format.\n",
    "\n",
    "---\n",
    "\n",
    "## **5.6 Reproducibility utilities**\n",
    "\n",
    "```\n",
    "src/myproject/utils/reproducibility.py\n",
    "```\n",
    "\n",
    "Set:\n",
    "\n",
    "```python\n",
    "def set_seed(seed=42):\n",
    "    import random, numpy as np, torch\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# **6. Best Practices for ML Infrastructure**\n",
    "\n",
    "## **6.1 Version control (Git)**\n",
    "\n",
    "Do not commit:\n",
    "\n",
    "```\n",
    "data/\n",
    "checkpoints/\n",
    "logs/\n",
    "__pycache__/\n",
    ".ipynb_checkpoints/\n",
    "```\n",
    "\n",
    "Use `.gitignore`.\n",
    "\n",
    "---\n",
    "\n",
    "## **6.2 Experiment tracking**\n",
    "\n",
    "Industry-standard tools:\n",
    "\n",
    "* wandb\n",
    "* MLFlow\n",
    "* TensorBoard\n",
    "\n",
    "Prefer MLFlow or wandb.\n",
    "\n",
    "---\n",
    "\n",
    "## **6.3 Dataset versioning (DVC)**\n",
    "\n",
    "If you have large datasets:\n",
    "\n",
    "```\n",
    "pip install dvc\n",
    "```\n",
    "\n",
    "Track data versions.\n",
    "\n",
    "---\n",
    "\n",
    "## **6.4 Environment management**\n",
    "\n",
    "Use one of:\n",
    "\n",
    "* conda\n",
    "* poetry\n",
    "* pyenv + uv\n",
    "\n",
    "My recommendation: **Poetry** or **UV**.\n",
    "\n",
    "---\n",
    "\n",
    "## **6.5 Virtual environment inside project**\n",
    "\n",
    "Standard layout:\n",
    "\n",
    "```\n",
    "myproject/.venv/\n",
    "```\n",
    "\n",
    "Avoid global conda environments.\n",
    "\n",
    "---\n",
    "\n",
    "## **6.6 Use a lightweight Dockerfile**\n",
    "\n",
    "If deploying:\n",
    "\n",
    "```\n",
    "FROM python:3.11-slim\n",
    "COPY . /app\n",
    "WORKDIR /app\n",
    "RUN pip install .\n",
    "CMD [\"python\", \"scripts/train.py\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **6.7 Continuous Integration**\n",
    "\n",
    "GitHub Actions for:\n",
    "\n",
    "* lint\n",
    "* tests\n",
    "* style\n",
    "* packaging\n",
    "\n",
    "---\n",
    "\n",
    "# **7. How VS Code Should Be Configured**\n",
    "\n",
    "## **7.1 Set the workspace root**\n",
    "\n",
    "Your VS Code workspace root should be:\n",
    "\n",
    "```\n",
    "myproject/\n",
    "```\n",
    "\n",
    "## **7.2 Set Python path**\n",
    "\n",
    "In `.vscode/settings.json`:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"python.autoComplete.extraPaths\": [\"./src\"]\n",
    "}\n",
    "```\n",
    "\n",
    "This instantly fixes all import issues.\n",
    "\n",
    "## **7.3 Configure debugging**\n",
    "\n",
    "Create:\n",
    "\n",
    "`.vscode/launch.json`:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"version\": \"0.2.0\",\n",
    "  \"configurations\": [\n",
    "    {\n",
    "      \"name\": \"Train\",\n",
    "      \"type\": \"python\",\n",
    "      \"request\": \"launch\",\n",
    "      \"program\": \"scripts/train.py\",\n",
    "      \"env\": { \"PYTHONPATH\": \"${workspaceFolder}/src\" }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "This guarantees correct imports.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This structure is used by:\n",
    "\n",
    "* Google Brain\n",
    "* Meta FAIR\n",
    "* HuggingFace\n",
    "* PyTorch Lightning\n",
    "* NVIDIA NeMo\n",
    "* OpenAI academic projects\n",
    "* University research labs\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
