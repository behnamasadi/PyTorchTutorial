{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d56e40-811c-4c2d-8e59-b35d1ca201ff",
   "metadata": {},
   "source": [
    "## 1. What is MBConv?\n",
    "\n",
    "**MBConv (Mobile Inverted Bottleneck Convolution)** was introduced in **MobileNetV2** and reused in **EfficientNet**.\n",
    "\n",
    "It’s called *inverted* because:\n",
    "\n",
    "* A normal bottleneck first **reduces** channels, then applies convolution.\n",
    "* MBConv first **expands** channels, does computation, and then **projects back** to fewer channels.\n",
    "\n",
    "---\n",
    "\n",
    "### MBConv block structure\n",
    "\n",
    "1. **Expansion (1×1 convolution)**\n",
    "   Expands from input channels $C_{in}$ to $t \\times C_{in}$, where $t$ is the **expansion factor** (usually 6).\n",
    "\n",
    "   $$\n",
    "   X_{expand} = \\text{ReLU6}(\\text{BN}(\\text{Conv}_{1\\times1}(X_{in})))\n",
    "   $$\n",
    "\n",
    "2. **Depthwise convolution (3×3 convolution per channel)**\n",
    "   Applies spatial convolution **independently** for each channel.\n",
    "\n",
    "   $$\n",
    "   X_{depth} = \\text{ReLU6}(\\text{BN}(\\text{ConvDepthwise}_{3\\times3}(X_{expand})))\n",
    "   $$\n",
    "\n",
    "3. **Projection (1×1 convolution)**\n",
    "   Reduces back to $C_{out}$ channels.\n",
    "\n",
    "   $$\n",
    "   X_{out} = \\text{BN}(\\text{Conv}_{1\\times1}(X_{depth}))\n",
    "   $$\n",
    "\n",
    "4. **Skip connection (optional)**\n",
    "   If stride = 1 and $C_{in} = C_{out}$:\n",
    "   $$\n",
    "   Y = X_{in} + X_{out}\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "**MBConv = Expansion (1×1) → Depthwise (3×3) → Projection (1×1)**\n",
    "\n",
    "\n",
    "**Depthwise Separable = Depthwise (3×3) → Pointwise (1×1)**\n",
    "\n",
    "So MBConv is a **generalized and more expressive** version of Depthwise Separable Conv.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Numerical Example\n",
    "\n",
    "Let’s take a **tiny example** to see the shapes.\n",
    "\n",
    "| Parameter        | Symbol       | Value |\n",
    "| ---------------- | ------------ | ----- |\n",
    "| Input size       | $H \\times W$ | 8 × 8 |\n",
    "| Input channels   | $C_{in}$     | 4     |\n",
    "| Output channels  | $C_{out}$    | 4     |\n",
    "| Expansion factor | $t$          | 6     |\n",
    "| Kernel size      | $k$          | 3     |\n",
    "| Stride           | 1            |       |\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 1: Expansion (1×1 conv)\n",
    "\n",
    "$$\n",
    "C_{expand} = t \\times C_{in} = 6 \\times 4 = 24\n",
    "$$\n",
    "\n",
    "Output tensor shape:\n",
    "$$\n",
    "[8, 8, 24]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2: Depthwise 3×3 conv\n",
    "\n",
    "Each of the 24 channels gets its own 3×3 filter → no channel mixing.\n",
    "\n",
    "Output tensor shape:\n",
    "$$\n",
    "[8, 8, 24]\n",
    "$$\n",
    "\n",
    "(assuming padding = 1, stride = 1)\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3: Projection (1×1 conv)\n",
    "\n",
    "Reduces back to 4 channels:\n",
    "\n",
    "$$\n",
    "[8, 8, 24] \\xrightarrow{\\text{Conv1×1}} [8, 8, 4]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 4: Skip connection\n",
    "\n",
    "Since stride = 1 and input/output channels are the same (4), we add:\n",
    "\n",
    "$$\n",
    "Y = X_{in} + X_{out}\n",
    "$$\n",
    "\n",
    "Final output shape:\n",
    "$$\n",
    "[8, 8, 4]\n",
    "$$\n",
    "\n",
    "<img src=\"images/mbconv.png\"  height=\"30%\" width=\"30%\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aa6ec2-448c-44cb-a528-0ef4dee7c27c",
   "metadata": {},
   "source": [
    "#### Python Code\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "input = torch.randn(1, 4, 8, 8)  # [B, Cin, H, W]\n",
    "expansion_factor = 6\n",
    "```\n",
    "\n",
    "#### 1. Expansion (1×1 convolution)\n",
    "\n",
    "```python\n",
    "conv1x1 = torch.nn.Conv2d(in_channels=4,\n",
    "                          out_channels=expansion_factor * 4,  # 24\n",
    "                          kernel_size=1,\n",
    "                          stride=1)\n",
    "output_expanded = conv1x1(input)\n",
    "print(output_expanded.shape)  # [1, 24, 8, 8]\n",
    "```\n",
    "\n",
    "This expands the number of channels:\n",
    "$$\n",
    "C_{out} = t \\times C_{in} = 6 \\times 4 = 24\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Depthwise convolution (3×3)\n",
    "\n",
    "```python\n",
    "conv_depthwise = torch.nn.Conv2d(in_channels=expansion_factor * 4,\n",
    "                                 out_channels=expansion_factor * 4,\n",
    "                                 kernel_size=3,\n",
    "                                 stride=1,\n",
    "                                 padding=1,          # keep size same\n",
    "                                 groups=expansion_factor * 4)  # depthwise\n",
    "output_depthwise = conv_depthwise(output_expanded)\n",
    "print(output_depthwise.shape)  # [1, 24, 8, 8]\n",
    "```\n",
    "\n",
    "Each channel is convolved **independently** (since `groups=in_channels`).\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Projection (1×1 convolution)\n",
    "\n",
    "```python\n",
    "conv_projection = torch.nn.Conv2d(in_channels=expansion_factor * 4,\n",
    "                                  out_channels=4,\n",
    "                                  kernel_size=1,\n",
    "                                  stride=1)\n",
    "output_projected = conv_projection(output_depthwise)\n",
    "print(output_projected.shape)  # [1, 4, 8, 8]\n",
    "```\n",
    "\n",
    "This projects back down to the original number of channels.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Optional skip connection\n",
    "\n",
    "If stride = 1 and `C_in == C_out`, you can add:\n",
    "\n",
    "```python\n",
    "output = input + output_projected\n",
    "print(output.shape)  # [1, 4, 8, 8]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Summary of shapes\n",
    "\n",
    "| Stage      | Operation | Input shape   | Output shape  | Parameters     |\n",
    "| ---------- | --------- | ------------- | ------------- | -------------- |\n",
    "| Expansion  | 1×1 conv  | [1, 4, 8, 8]  | [1, 24, 8, 8] | 4×24×1×1 = 96  |\n",
    "| Depthwise  | 3×3 conv  | [1, 24, 8, 8] | [1, 24, 8, 8] | 24×3×3 = 216   |\n",
    "| Projection | 1×1 conv  | [1, 24, 8, 8] | [1, 4, 8, 8]  | 24×4×1×1 = 96  |\n",
    "| **Total**  |           |               |               | **408 params** |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf5f9a2-619c-45ac-8348-4d2dc1d374d2",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Parameter Comparison\n",
    "\n",
    "Let’s roughly compare MBConv vs Depthwise-Separable Conv for the same example.\n",
    "\n",
    "| Layer type                         | Parameters                       |\n",
    "| ---------------------------------- | -------------------------------- |\n",
    "| Expansion 1×1 conv                 | $1×1×4×24 = 96$                  |\n",
    "| Depthwise 3×3 conv                 | $3×3×24 = 216$                   |\n",
    "| Projection 1×1 conv                | $1×1×24×4 = 96$                  |\n",
    "| **Total MBConv**                   | **408**                          |\n",
    "| Depthwise-separable (no expansion) | $3×3×4 + 1×1×4×4 = 36 + 16 = 52$ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023643b-88c0-4c89-bd69-66fff7176496",
   "metadata": {},
   "source": [
    "## **Inverted Residual Structure vs Encoder–Decoder**\n",
    "\n",
    "\n",
    "#### 1. Usual Intuition (VAE, U-Net)\n",
    "\n",
    "In most architectures like VAEs, U-Nets, or traditional CNNs:\n",
    "\n",
    "* We **shrink** (downsample or reduce channels) to form a **compact representation** — a *latent code*.\n",
    "* Then we **expand** back (via upsampling or transposed conv) to reconstruct or segment.\n",
    "\n",
    "The idea is to **compress information**, forcing the network to **learn meaningful global features**.\n",
    "\n",
    "That’s useful when your goal is *generation* or *reconstruction*, i.e., turning an input into something larger or richer (like an image output).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. In MobileNetV2 — the Goal is Different\n",
    "\n",
    "MobileNetV2 is **not a generative model**, but a **feature extractor for classification or detection**.\n",
    "\n",
    "Its purpose is not to compress the entire image into a low-dimensional latent space,\n",
    "but rather to **transform and refine features efficiently** while keeping information flow stable.\n",
    "\n",
    "So the expansion–shrink operation is **not an encoder–decoder**, but a **local feature transformation trick** that balances *expressiveness* and *efficiency*.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. The Core Idea — “Inverted Residual”\n",
    "\n",
    "Let’s recall a **residual block** from ResNet:\n",
    "\n",
    "$$\n",
    "y = F(x) + x\n",
    "$$\n",
    "\n",
    "Here, $ F(x) $ is usually **wide** — lots of channels — so adding ( x ) directly would be expensive.\n",
    "ResNet typically **compresses (1×1 conv)** → **processes (3×3 conv)** → **expands (1×1 conv)**.\n",
    "\n",
    "**MobileNetV2 does the opposite:**\n",
    "\n",
    "$$\n",
    "\\text{Expand (1×1)} \\rightarrow \\text{Depthwise (3×3)} \\rightarrow \\text{Project (1×1)}\n",
    "$$\n",
    "\n",
    "and keeps the *skip connection* between the **narrow (bottleneck)** tensors.\n",
    "\n",
    "That’s why it’s called **“inverted residual”** — the *shortcut* connects narrow layers, not wide ones.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Why Expand First?\n",
    "\n",
    "Because **depthwise convolutions** (used for efficiency) operate *independently* on each channel —\n",
    "they can’t mix information across channels.\n",
    "\n",
    "If the input has few channels, the depthwise conv has *very limited capacity*.\n",
    "\n",
    "#### So:\n",
    "\n",
    "1. **Expand (1×1 conv)** — project to a higher-dimensional space (e.g., ×6 wider).\n",
    "   This allows richer combinations of features.\n",
    "2. **Depthwise Conv (3×3)** — spatial filtering per channel (cheap, local spatial context).\n",
    "3. **Project back (1×1 conv)** — compress to fewer channels again to save memory and computation.\n",
    "\n",
    "Formally, expansion provides **a wider feature space** for non-linear transformations.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Why Shrink Again?\n",
    "\n",
    "The projection (shrink) step serves two purposes:\n",
    "\n",
    "* **Efficiency**: reduces the number of channels to keep the next layer lightweight.\n",
    "* **Linear bottleneck**: after non-linear transformations (ReLU6), projection back to a smaller space *without non-linearity* preserves information that would otherwise be destroyed by clipping in ReLU6.\n",
    "\n",
    "Hence the name **Linear Bottleneck** — linear projection back to compact form.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. Intuitive Analogy\n",
    "\n",
    "Think of it like working in **a higher-dimensional workspace to manipulate data more flexibly**, then compressing it back.\n",
    "\n",
    "* In low dimension (few channels): limited capacity to separate or combine patterns.\n",
    "* In high dimension (expanded): easier to apply non-linear transforms (like ReLU) without losing structure.\n",
    "* After processing: you bring it back down to a compact form to continue efficiently.\n",
    "\n",
    "It’s conceptually similar to what happens in transformers or kernels in SVMs:\n",
    "\n",
    "> Project into a higher-dimensional feature space → perform simple operations → project back.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "#### 7. Why It Works So Well\n",
    "\n",
    "* Keeps **parameter count low** (thanks to depthwise + projection).\n",
    "* Maintains **gradient flow** through the narrow residual path.\n",
    "* Enables **non-linear expressiveness** in expanded space.\n",
    "* Prevents **information loss** with the linear bottleneck.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360f370c-4bed-4412-9ccb-ee66fd2874d5",
   "metadata": {},
   "source": [
    "## **Numerical Example**\n",
    "Let’s go through a **tiny tensor** step by step to see exactly how **MobileNetV2’s inverted residual block** works.\n",
    "\n",
    "We’ll simulate the shapes and operations — no need for an actual image file — so you can *visualize* what happens numerically.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Setup\n",
    "\n",
    "Let’s say we have an **input tensor** from some previous layer:\n",
    "\n",
    "$$\n",
    "X \\in \\mathbb{R}^{4 \\times 4 \\times 8}\n",
    "$$\n",
    "\n",
    "That is:\n",
    "\n",
    "* Height = 4\n",
    "* Width = 4\n",
    "* Channels = 8 (a “narrow” representation)\n",
    "\n",
    "We’ll use:\n",
    "\n",
    "* **Expansion factor** $ t = 6 $\n",
    "* **Output channels** $ c_{\\text{out}} = 8 $\n",
    "* **Stride = 1**\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Step 1 — Expansion (1×1 convolution)\n",
    "\n",
    "We apply a **1×1 convolution** to increase the number of channels by the factor $ t = 6 $:\n",
    "\n",
    "$$\n",
    "\\text{Conv}_{1×1}^{expand}: 8 \\rightarrow 48\n",
    "$$\n",
    "\n",
    "So the tensor becomes:\n",
    "\n",
    "$$\n",
    "X_{expand} \\in \\mathbb{R}^{4 \\times 4 \\times 48}\n",
    "$$\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "* Each pixel location (4×4 = 16 total) now has **48 features** instead of 8.\n",
    "* This gives the model more “room” to apply non-linear transformations (ReLU6).\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Step 2 — Depthwise Convolution (3×3)\n",
    "\n",
    "Next, we apply a **depthwise 3×3 convolution**, one filter per channel:\n",
    "\n",
    "$$\n",
    "\\text{Conv}_{3×3}^{dw}: 48 \\text{ filters, each on 1 channel}\n",
    "$$\n",
    "\n",
    "Output stays the same size (since stride=1, padding=1):\n",
    "\n",
    "$$\n",
    "X_{dw} \\in \\mathbb{R}^{4 \\times 4 \\times 48}\n",
    "$$\n",
    "\n",
    "Key point:\n",
    "\n",
    "* Each channel is filtered *independently*, capturing spatial context (edges, corners, etc.)\n",
    "* No mixing between channels yet.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Step 3 — Projection (1×1 convolution)\n",
    "\n",
    "Now we use another **1×1 convolution** to compress channels back:\n",
    "\n",
    "$$\n",
    "\\text{Conv}_{1×1}^{project}: 48 \\rightarrow 8\n",
    "$$\n",
    "\n",
    "So the tensor becomes:\n",
    "\n",
    "$$\n",
    "X_{proj} \\in \\mathbb{R}^{4 \\times 4 \\times 8}\n",
    "$$\n",
    "\n",
    "This projection is **linear** (no activation).\n",
    "It re-combines the 48 feature maps into a compact 8-channel representation.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Step 4 — Residual Connection\n",
    "\n",
    "Since stride=1 and the input/output channel counts are the same (8),\n",
    "we can add the residual connection:\n",
    "\n",
    "$$\n",
    "Y = X_{proj} + X\n",
    "$$\n",
    "\n",
    "The output has the same shape as the input:\n",
    "\n",
    "$$\n",
    "Y \\in \\mathbb{R}^{4 \\times 4 \\times 8}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. What Happened Intuitively\n",
    "\n",
    "| Step         | Operation | Channels | Spatial | Comment                |\n",
    "| ------------ | --------- | -------- | ------- | ---------------------- |\n",
    "| Input        | —         | 8        | 4×4     | narrow, compressed     |\n",
    "| Expand       | 1×1 Conv  | 48       | 4×4     | rich, high-dimensional |\n",
    "| Depthwise    | 3×3 Conv  | 48       | 4×4     | local spatial mixing   |\n",
    "| Project      | 1×1 Conv  | 8        | 4×4     | compact again          |\n",
    "| Residual Add | +         | 8        | 4×4     | information shortcut   |\n",
    "\n",
    "So the block **transforms information in a high-dimensional space** (48 channels),\n",
    "but **stores and connects through a low-dimensional bottleneck** (8 channels).\n",
    "\n",
    "---\n",
    "\n",
    "#### 7. Why It’s “Inverted Residual”\n",
    "\n",
    "In **ResNet**, you’d have:\n",
    "\n",
    "```\n",
    "Input (wide)\n",
    " → 1×1 conv (reduce)\n",
    " → 3×3 conv\n",
    " → 1×1 conv (expand)\n",
    " → Add\n",
    "```\n",
    "\n",
    "In **MobileNetV2**, you invert that:\n",
    "\n",
    "```\n",
    "Input (narrow)\n",
    " → 1×1 conv (expand)\n",
    " → 3×3 depthwise conv\n",
    " → 1×1 conv (project)\n",
    " → Add\n",
    "```\n",
    "\n",
    "Hence: **“Inverted residual”**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 8. Optional: Visual Intuition (Grid)\n",
    "\n",
    "```\n",
    "Before expansion:\n",
    "  4×4 pixels × 8 channels  → compact info\n",
    "\n",
    "After expansion:\n",
    "  4×4 pixels × 48 channels → high-dimensional workspace\n",
    "\n",
    "After projection:\n",
    "  4×4 pixels × 8 channels  → compact again, ready for next block\n",
    "```\n",
    "\n",
    "You can think of it as a **temporary workspace explosion** —\n",
    "you blow up the feature space, do useful operations in it,\n",
    "and then compress it back efficiently.\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
